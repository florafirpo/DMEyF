{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e652414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMILLAS = [550007, 550019, 550031, 550033, 550047]\n",
    "\n",
    "mes_train = 202103, 202102, 202101\n",
    "mes_test = 202104\n",
    "mes_kaggle = 202106\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39165b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que archivos son? esos meses seleccionados SIN SLOPE\n",
    "#df_train.write_csv(\"data/df_train_01_02_03.csv\")\n",
    "#df_test.write_csv(\"data/df_test_04.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a3b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv(\"data/df_train_fe.csv\")\n",
    "df_test = pd.read_csv(\"data/competencia_04_dl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470c4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/competencia_01_02_03_dl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8cf600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486791, 530)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31260188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163418, 530)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los meses deseados\n",
    "# df_train = df_train[\n",
    "#     (df_train[\"clase_ternaria\"] == \"BAJA+1\") | (df_train[\"clase_ternaria\"] == \"BAJA+2\")\n",
    "# ]\n",
    "\n",
    "\n",
    "# #Guardar en CSV\n",
    "# df_train.to_csv(\"df_train_c12.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2aebea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liberar memoria antes de empezar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ab0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv(\"data/competencia_06_dl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36daa60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#tiene mi df_train la columna \"clase_ternaria\"?\n",
    "print(\"clase_ternaria\" in df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38450efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['clase_peso'] = 1.0\n",
    "\n",
    "# df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "# df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a08b7d",
   "metadata": {},
   "source": [
    "##Optimizaci√≥n con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cc7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (340753, 802) (340753,) (340753,)\n",
      "Validation: (146038, 802) (146038,) (146038,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar X e y\n",
    "X = df_train.drop([\"clase_ternaria\", \"clase_peso\"], axis=1)  # ‚úÖ Sacamos tambi√©n clase_peso\n",
    "y = df_train[\"clase_ternaria\"]\n",
    "pesos = df_train[\"clase_peso\"]  # ‚úÖ Guardamos los pesos\n",
    "\n",
    "# Binarizar y\n",
    "y_binaria = (y != \"CONTINUA\").astype(int)\n",
    "\n",
    "# Split 70/30 (ahora incluimos los pesos)\n",
    "X_train, X_val, y_train, y_val, pesos_train, pesos_val = train_test_split(\n",
    "    X, y_binaria, pesos,  # ‚úÖ Separamos X, y Y pesos\n",
    "    train_size=0.7,\n",
    "    random_state=42,\n",
    "    stratify=y_binaria\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape, pesos_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape, pesos_val.shape)\n",
    "\n",
    "# Ahora en el Dataset:\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train,\n",
    "                          weight=pesos_train  # ‚úÖ Usamos los pesos del train\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f3d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia_prob(y_pred, data):\n",
    "  weight = data.get_weight()\n",
    "  ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "  ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "  ganancia = np.cumsum(ganancia)  # ‚úÖ Bien\n",
    "  return 'gan_eval', np.max(ganancia), True\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7157293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:41:37,005] Using an existing study with name 'exp_301_lgbm' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.1) # mas bajo, m√°s iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 300, 1000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': SEMILLAS[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train, # eligir la clase\n",
    "                              weight=pesos_train\n",
    "                              )\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100, # modificar, subit y subir... y descomentar la l√≠nea inferior\n",
    "        # early_stopping_rounds= int(50 + 5 / learning_rate),\n",
    "        feval=ganancia_prob,\n",
    "        stratified=True,\n",
    "        nfold=3,\n",
    "        seed=SEMILLAS[0],\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=int(50 + 5/learning_rate), verbose=False),\n",
    "                lgb.log_evaluation(period=200),\n",
    "                ]\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteraci√≥n del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 3\n",
    "# Al final de objective()\n",
    "gc.collect()\n",
    "\n",
    "#guardar el archivo en mi carpeta data\n",
    "storage_name = \"sqlite:///data/optimization_lgbm.db\"\n",
    "\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1bddf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:43:25,676] Trial 15 finished with value: 824520000.0 and parameters: {'num_leaves': 13, 'learning_rate': 0.032922995753811045, 'min_data_in_leaf': 964, 'feature_fraction': 0.2632501067072054, 'bagging_fraction': 0.28635017212034686}. Best is trial 15 with value: 824520000.0.\n",
      "[I 2025-10-09 16:45:32,227] Trial 16 finished with value: 1027440000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.07720399027065392, 'min_data_in_leaf': 658, 'feature_fraction': 0.39718138159387195, 'bagging_fraction': 0.3601895736680899}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:47:35,837] Trial 17 finished with value: 791800000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.007962520110203843, 'min_data_in_leaf': 895, 'feature_fraction': 0.4706483103904118, 'bagging_fraction': 0.4298206201719591}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:49:25,185] Trial 18 finished with value: 834300000.0 and parameters: {'num_leaves': 12, 'learning_rate': 0.03261502081092614, 'min_data_in_leaf': 774, 'feature_fraction': 0.36228252699876873, 'bagging_fraction': 0.825135708172798}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:51:26,330] Trial 19 finished with value: 928600000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.028124073101017433, 'min_data_in_leaf': 814, 'feature_fraction': 0.9765401489774953, 'bagging_fraction': 0.4846954588315372}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:54:54,050] Trial 20 finished with value: 1045140000.0 and parameters: {'num_leaves': 99, 'learning_rate': 0.09456799616712813, 'min_data_in_leaf': 786, 'feature_fraction': 0.8505712193448408, 'bagging_fraction': 0.8614072845471961}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 16:57:34,715] Trial 21 finished with value: 775520000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.007609236921035897, 'min_data_in_leaf': 889, 'feature_fraction': 0.7305930553144344, 'bagging_fraction': 0.9836295817863161}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:01:10,065] Trial 22 finished with value: 954580000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.03551299900057091, 'min_data_in_leaf': 776, 'feature_fraction': 0.4412506615972879, 'bagging_fraction': 0.8249568481060399}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:04:17,342] Trial 23 finished with value: 1021120000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.07102526431761932, 'min_data_in_leaf': 627, 'feature_fraction': 0.6362852893242957, 'bagging_fraction': 0.5861891002072817}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:07:59,799] Trial 24 finished with value: 948820000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.03213507857167837, 'min_data_in_leaf': 593, 'feature_fraction': 0.4209847747251586, 'bagging_fraction': 0.8759373701900635}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:10:24,713] Trial 25 finished with value: 1020900000.0 and parameters: {'num_leaves': 41, 'learning_rate': 0.09837336279295872, 'min_data_in_leaf': 415, 'feature_fraction': 0.919985830000466, 'bagging_fraction': 0.6011415449734407}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:13:15,576] Trial 26 finished with value: 1042800000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.08971976862027427, 'min_data_in_leaf': 452, 'feature_fraction': 0.8004895206314104, 'bagging_fraction': 0.157399876107364}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:16:05,448] Trial 27 finished with value: 1041060000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09870571178017513, 'min_data_in_leaf': 304, 'feature_fraction': 0.7863358253073632, 'bagging_fraction': 0.143315819961042}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:18:44,054] Trial 28 finished with value: 988340000.0 and parameters: {'num_leaves': 35, 'learning_rate': 0.07967321744531922, 'min_data_in_leaf': 496, 'feature_fraction': 0.8331819030261377, 'bagging_fraction': 0.10049671000519919}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:21:55,902] Trial 29 finished with value: 1009480000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.059718706457130004, 'min_data_in_leaf': 473, 'feature_fraction': 0.6533961039909946, 'bagging_fraction': 0.6984548668779926}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:23:54,589] Trial 30 finished with value: 1038200000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.08644030887259865, 'min_data_in_leaf': 692, 'feature_fraction': 0.836083790915367, 'bagging_fraction': 0.23667657929031638}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:25:40,690] Trial 31 finished with value: 1008940000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.061646110241254506, 'min_data_in_leaf': 307, 'feature_fraction': 0.5863285753747938, 'bagging_fraction': 0.6550701621302726}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:27:04,579] Trial 32 finished with value: 987940000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.08586284689560453, 'min_data_in_leaf': 546, 'feature_fraction': 0.15114689197161174, 'bagging_fraction': 0.7505533727463403}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:29:31,762] Trial 33 finished with value: 1025200000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.08959332026481266, 'min_data_in_leaf': 399, 'feature_fraction': 0.9956552869925159, 'bagging_fraction': 0.9974691830589215}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:32:11,459] Trial 34 finished with value: 978580000.0 and parameters: {'num_leaves': 27, 'learning_rate': 0.06817794197927785, 'min_data_in_leaf': 733, 'feature_fraction': 0.7198370209233466, 'bagging_fraction': 0.44295744885045657}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:34:49,166] Trial 35 finished with value: 976720000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.042933801441912944, 'min_data_in_leaf': 835, 'feature_fraction': 0.891006619841911, 'bagging_fraction': 0.32299584653205415}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:36:25,181] Trial 36 finished with value: 1044240000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09846796120949375, 'min_data_in_leaf': 323, 'feature_fraction': 0.7638527968919089, 'bagging_fraction': 0.12449291434137111}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:38:04,491] Trial 37 finished with value: 1031280000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09294504641854785, 'min_data_in_leaf': 349, 'feature_fraction': 0.743768290949119, 'bagging_fraction': 0.1934407976564106}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:39:33,464] Trial 38 finished with value: 1043220000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.09962439914117481, 'min_data_in_leaf': 379, 'feature_fraction': 0.874385258914073, 'bagging_fraction': 0.20343112783227624}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:41:52,148] Trial 39 finished with value: 1058480000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09904281706673441, 'min_data_in_leaf': 370, 'feature_fraction': 0.9029799021041279, 'bagging_fraction': 0.5198907300236562}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:44:49,323] Trial 40 finished with value: 1030960000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.08107008652265753, 'min_data_in_leaf': 524, 'feature_fraction': 0.9383670803546833, 'bagging_fraction': 0.4830700758107635}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:47:17,770] Trial 41 finished with value: 1020620000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.07266488061473086, 'min_data_in_leaf': 586, 'feature_fraction': 0.5215037690611719, 'bagging_fraction': 0.9050163759026926}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:48:59,114] Trial 42 finished with value: 992500000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.0528325423839046, 'min_data_in_leaf': 353, 'feature_fraction': 0.7129192006043963, 'bagging_fraction': 0.7455389623682458}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:50:30,355] Trial 43 finished with value: 1025340000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09310169546870133, 'min_data_in_leaf': 447, 'feature_fraction': 0.6425588211916933, 'bagging_fraction': 0.3912379704690329}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:53:27,143] Trial 44 finished with value: 1033920000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.08349184716726239, 'min_data_in_leaf': 985, 'feature_fraction': 0.8662105529858758, 'bagging_fraction': 0.2779711201466693}. Best is trial 39 with value: 1058480000.0.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=30) # subir subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b7d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Obtener los mejores 10 trials\n",
    "best_trials = study.trials_dataframe().sort_values('value', ascending=False).head(10)\n",
    "\n",
    "# Opci√≥n 1: Guardar como lista de diccionarios (m√°s completo)\n",
    "mejores_params = []\n",
    "for i, trial in enumerate(study.best_trials[:10] if len(study.best_trials) >= 10 else study.best_trials):\n",
    "    mejores_params.append({\n",
    "        'rank': i + 1,\n",
    "        'trial_number': trial.number,\n",
    "        'value': trial.value,\n",
    "        'params': trial.params,\n",
    "        'best_iter': trial.user_attrs.get('best_iter', None)\n",
    "    })\n",
    "\n",
    "# Guardar en JSON\n",
    "with open('data/mejores_hiperparametros.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mejores_params, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f180540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARANDO DATOS TRAIN\n",
      "============================================================\n",
      "Creando pesos...\n",
      "Convirtiendo a numpy (float32)...\n",
      "X_train: (486791, 529), dtype: float32\n",
      "y_train_binaria: (486791,), dtype: int8\n",
      "Clase positiva: 5,284\n",
      "Clase negativa: 481,507\n",
      "Liberando df_train de memoria...\n",
      "‚úÖ Datos TRAIN preparados y df_train liberado\n",
      "\n",
      "============================================================\n",
      "PREPARANDO DATOS TEST\n",
      "============================================================\n",
      "X_test: (163418, 529), dtype: float32\n",
      "y_test: (163418,)\n",
      "Liberando df_test de memoria...\n",
      "‚úÖ Datos TEST preparados\n",
      "\n",
      "============================================================\n",
      "ENTRENAMIENTO CON TRAIN\n",
      "============================================================\n",
      "\n",
      "Cargando hiperpar√°metros desde data/mejores_hiperparametros.json...\n",
      "Trial 39\n",
      "Ganancia esperada en CV: $1,058,480,000\n",
      "\n",
      "Par√°metros del modelo:\n",
      "  objective: binary\n",
      "  metric: custom\n",
      "  boosting_type: gbdt\n",
      "  first_metric_only: True\n",
      "  boost_from_average: True\n",
      "  feature_pre_filter: False\n",
      "  max_bin: 31\n",
      "  num_leaves: 91\n",
      "  learning_rate: 0.09904281706673441\n",
      "  min_data_in_leaf: 370\n",
      "  feature_fraction: 0.9029799021041279\n",
      "  bagging_fraction: 0.5198907300236562\n",
      "  seed: 550007\n",
      "  verbose: 1\n",
      "\n",
      "Creando dataset con X_train: (486791, 529)\n",
      "Entrenando modelo con 100 iteraciones...\n",
      "[LightGBM] [Info] Number of positive: 5284, number of negative: 481507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.324407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13326\n",
      "[LightGBM] [Info] Number of data points in the train set: 486791, number of used features: 529\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.010855 -> initscore=-4.512222\n",
      "[LightGBM] [Info] Start training from score -4.512222\n",
      "‚úÖ Modelo entrenado exitosamente\n",
      "\n",
      "============================================================\n",
      "EVALUANDO EN TEST\n",
      "============================================================\n",
      "Generando predicciones en X_test: (163418, 529)\n",
      "Calculando ganancia acumulada...\n",
      "\n",
      "üìä RESULTADOS EN TEST:\n",
      "  Ganancia m√°xima: $363,400,000\n",
      "  N¬∞ de env√≠os √≥ptimo: 9,590\n",
      "  Threshold √≥ptimo: 0.033705\n",
      "  % de la base: 5.87%\n",
      "\n",
      "üìà GANANCIA POR CANTIDAD DE ENV√çOS:\n",
      "  Top 1.0% (1,634 env√≠os): $192,920,000\n",
      "  Top 2.5% (4,085 env√≠os): $305,500,000\n",
      "  Top 5.0% (8,170 env√≠os): $358,200,000\n",
      "  Top 10.0% (16,341 env√≠os): $324,380,000\n",
      "\n",
      "üéØ CAPTURA DE BAJA+2:\n",
      "  Total BAJA+2: 1,131\n",
      "  Capturados: 694\n",
      "  Tasa: 61.36%\n",
      "\n",
      "‚úÖ Resultados guardados\n",
      "‚úÖ Modelo guardado\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS DE TRAIN - OPTIMIZADO PARA MEMORIA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DATOS TRAIN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear pesos en df_train\n",
    "print(\"Creando pesos...\")\n",
    "df_train['clase_peso'] = 1.0\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 2. Convertir a numpy inmediatamente (m√°s eficiente en memoria)\n",
    "print(\"Convirtiendo a numpy (float32)...\")\n",
    "X_train = df_train.drop([\"clase_ternaria\", \"clase_peso\"], axis=1).to_numpy().astype('float32')\n",
    "y_train = df_train[\"clase_ternaria\"].to_numpy()\n",
    "pesos_train = df_train[\"clase_peso\"].to_numpy().astype('float32')\n",
    "\n",
    "# Binarizar\n",
    "y_train_binaria = (y_train != \"CONTINUA\").astype('int8')\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train_binaria: {y_train_binaria.shape}, dtype: {y_train_binaria.dtype}\")\n",
    "print(f\"Clase positiva: {y_train_binaria.sum():,}\")\n",
    "print(f\"Clase negativa: {(y_train_binaria == 0).sum():,}\")\n",
    "\n",
    "# Liberar df_train de la memoria\n",
    "print(\"Liberando df_train de memoria...\")\n",
    "del df_train, y_train\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Datos TRAIN preparados y df_train liberado\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS DE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARANDO DATOS TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_test = df_test.drop(\"clase_ternaria\", axis=1).to_numpy().astype('float32')\n",
    "y_test = df_test[\"clase_ternaria\"].to_numpy()\n",
    "\n",
    "print(f\"X_test: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Liberar df_test si no lo necesit√°s m√°s\n",
    "print(\"Liberando df_test de memoria...\")\n",
    "del df_test\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Datos TEST preparados\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR M√âTRICA PERSONALIZADA DE GANANCIA\n",
    "# ============================================================\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "def ganancia_lgb(y_pred, data):\n",
    "    \"\"\"M√©trica personalizada de ganancia para LightGBM.\"\"\"\n",
    "    weight = data.get_weight()\n",
    "    \n",
    "    # Calcular ganancia para cada predicci√≥n\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - costo_estimulo\n",
    "    \n",
    "    # Ordenar por predicci√≥n descendente\n",
    "    indices = np.argsort(-y_pred)\n",
    "    ganancia_ordenada = ganancia[indices]\n",
    "    \n",
    "    # Calcular ganancia acumulada m√°xima\n",
    "    ganancia_acum = np.cumsum(ganancia_ordenada)\n",
    "    max_ganancia = np.max(ganancia_acum)\n",
    "    \n",
    "    return 'ganancia', max_ganancia, True\n",
    "\n",
    "# ============================================================\n",
    "# ENTRENAR CON TRAIN Y EVALUAR EN TEST\n",
    "# ============================================================\n",
    "\n",
    "def entrenar_modelo_test(mejores_params_path='data/mejores_hiperparametros.json'):\n",
    "    \"\"\"Entrena el modelo con df_train usando la m√©trica de ganancia.\"\"\"\n",
    "    \n",
    "    print(f\"\\nCargando hiperpar√°metros desde {mejores_params_path}...\")\n",
    "    with open(mejores_params_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    config = data[0] if isinstance(data, list) else data\n",
    "    \n",
    "    print(f\"Trial {config['trial_number']}\")\n",
    "    print(f\"Ganancia esperada en CV: ${config['value']:,.0f}\")\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': config['params']['num_leaves'],\n",
    "        'learning_rate': config['params']['learning_rate'],\n",
    "        'min_data_in_leaf': config['params']['min_data_in_leaf'],\n",
    "        'feature_fraction': config['params']['feature_fraction'],\n",
    "        'bagging_fraction': config['params']['bagging_fraction'],\n",
    "        'seed': SEMILLAS[0],\n",
    "        'verbose': 1\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPar√°metros del modelo:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Crear dataset (free_raw_data=True para ahorrar memoria)\n",
    "    print(f\"\\nCreando dataset con X_train: {X_train.shape}\")\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=y_train_binaria,\n",
    "                             weight=pesos_train,\n",
    "                             free_raw_data=False)  # Cambiar a True si sigue fallando\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(f\"Entrenando modelo con {config['best_iter']} iteraciones...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=config['best_iter'],\n",
    "        feval=ganancia_lgb,\n",
    "        callbacks=[lgb.log_evaluation(period=50)]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Modelo entrenado exitosamente\")\n",
    "    \n",
    "    # Liberar train_data\n",
    "    del train_data\n",
    "    gc.collect()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "\n",
    "def calcular_ganancia_test(model, X_test, y_test):\n",
    "    \"\"\"Calcula la ganancia en TEST y encuentra el umbral √≥ptimo.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUANDO EN TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Generando predicciones en X_test: {X_test.shape}\")\n",
    "    y_test_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    indices_ordenados = np.argsort(-y_test_pred_prob)\n",
    "    y_test_sorted = y_test[indices_ordenados]\n",
    "    \n",
    "    print(\"Calculando ganancia acumulada...\")\n",
    "    ganancia_cum = np.cumsum([\n",
    "        (ganancia_acierto if y == \"BAJA+2\" else -costo_estimulo)\n",
    "        for y in y_test_sorted\n",
    "    ])\n",
    "    \n",
    "    max_ganancia_idx = np.argmax(ganancia_cum)\n",
    "    max_ganancia = ganancia_cum[max_ganancia_idx]\n",
    "    n_envios_optimo = max_ganancia_idx + 1\n",
    "    threshold_optimo = y_test_pred_prob[indices_ordenados[max_ganancia_idx]]\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS EN TEST:\")\n",
    "    print(f\"  Ganancia m√°xima: ${max_ganancia:,.0f}\")\n",
    "    print(f\"  N¬∞ de env√≠os √≥ptimo: {n_envios_optimo:,}\")\n",
    "    print(f\"  Threshold √≥ptimo: {threshold_optimo:.6f}\")\n",
    "    print(f\"  % de la base: {n_envios_optimo / len(y_test) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\nüìà GANANCIA POR CANTIDAD DE ENV√çOS:\")\n",
    "    for percentil in [0.01, 0.025, 0.05, 0.10]:\n",
    "        n = int(len(y_test) * percentil)\n",
    "        ganancia_n = ganancia_cum[n-1] if n > 0 else 0\n",
    "        print(f\"  Top {percentil*100:.1f}% ({n:,} env√≠os): ${ganancia_n:,.0f}\")\n",
    "    \n",
    "    n_baja2_total = (y_test == \"BAJA+2\").sum()\n",
    "    n_baja2_capturados = (y_test_sorted[:n_envios_optimo] == \"BAJA+2\").sum()\n",
    "    print(f\"\\nüéØ CAPTURA DE BAJA+2:\")\n",
    "    print(f\"  Total BAJA+2: {n_baja2_total:,}\")\n",
    "    print(f\"  Capturados: {n_baja2_capturados:,}\")\n",
    "    print(f\"  Tasa: {n_baja2_capturados / n_baja2_total * 100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'ganancia_maxima': max_ganancia,\n",
    "        'n_envios_optimo': n_envios_optimo,\n",
    "        'threshold_optimo': threshold_optimo,\n",
    "        'ganancia_acumulada': ganancia_cum,\n",
    "        'probabilidades_ordenadas': y_test_pred_prob[indices_ordenados],\n",
    "        'y_test_sorted': y_test_sorted,\n",
    "        'n_baja2_capturados': n_baja2_capturados,\n",
    "        'n_baja2_total': n_baja2_total\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FLUJO COMPLETO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO CON TRAIN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_test, config = entrenar_modelo_test('data/mejores_hiperparametros.json')\n",
    "\n",
    "resultados_test = calcular_ganancia_test(model_test, X_test, y_test)\n",
    "\n",
    "with open('data/resultados_test.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'ganancia_maxima': float(resultados_test['ganancia_maxima']),\n",
    "        'n_envios_optimo': int(resultados_test['n_envios_optimo']),\n",
    "        'threshold_optimo': float(resultados_test['threshold_optimo']),\n",
    "        'n_baja2_capturados': int(resultados_test['n_baja2_capturados']),\n",
    "        'n_baja2_total': int(resultados_test['n_baja2_total'])\n",
    "    }, f, indent=4)\n",
    "\n",
    "print(\"\\n‚úÖ Resultados guardados\")\n",
    "\n",
    "model_test.save_model('data/modelo_train_test2.txt')\n",
    "print(\"‚úÖ Modelo guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73bd47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "107                          ctrx_quarter    0.048973\n",
      "365                      ctrx_quarter_max    0.045724\n",
      "364                      ctrx_quarter_min    0.034558\n",
      "252                      cpayroll_trx_min    0.033572\n",
      "18                           mcaja_ahorro    0.032253\n",
      "173                   mpasivos_margen_max    0.032014\n",
      "52                               mpayroll    0.031691\n",
      "254                          mpayroll_min    0.028546\n",
      "11                        mpasivos_margen    0.027750\n",
      "51                           cpayroll_trx    0.027207\n",
      "253                      cpayroll_trx_max    0.019877\n",
      "28                  mtarjeta_visa_consumo    0.019612\n",
      "186                      mcaja_ahorro_min    0.018973\n",
      "172                   mpasivos_margen_min    0.018673\n",
      "187                      mcaja_ahorro_max    0.017311\n",
      "255                          mpayroll_max    0.017055\n",
      "195                    mcuentas_saldo_max    0.015716\n",
      "22                         mcuentas_saldo    0.015674\n",
      "25                          mautoservicio    0.015595\n",
      "199     ctarjeta_debito_transacciones_max    0.015442\n",
      "206             mtarjeta_visa_consumo_min    0.014418\n",
      "24          ctarjeta_debito_transacciones    0.014350\n",
      "138                      Visa_msaldopesos    0.013054\n",
      "137                      Visa_msaldototal    0.013000\n",
      "201                     mautoservicio_max    0.012123\n",
      "27            ctarjeta_visa_transacciones    0.010852\n",
      "147                      Visa_mpagospesos    0.010591\n",
      "421                  Visa_msaldototal_max    0.008991\n",
      "200                     mautoservicio_min    0.008690\n",
      "595  mcomisiones_mantenimiento_diff_prev2    0.008158\n",
      "204       ctarjeta_visa_transacciones_min    0.008073\n",
      "423                  Visa_msaldopesos_max    0.007895\n",
      "198     ctarjeta_debito_transacciones_min    0.007839\n",
      "205       ctarjeta_visa_transacciones_max    0.007837\n",
      "594   mcomisiones_mantenimiento_diff_prev    0.007496\n",
      "216             mprestamos_personales_min    0.007437\n",
      "440                  Visa_mpagospesos_min    0.007399\n",
      "73                      ccomisiones_otras    0.007130\n",
      "207             mtarjeta_visa_consumo_max    0.007008\n",
      "194                    mcuentas_saldo_min    0.006986\n",
      "319          cextraccion_autoservicio_max    0.006977\n",
      "593  ccomisiones_mantenimiento_diff_prev2    0.005807\n",
      "33                  mprestamos_personales    0.005749\n",
      "453                  Visa_mpagominimo_max    0.005447\n",
      "321          mextraccion_autoservicio_max    0.005405\n",
      "422                  Visa_msaldopesos_min    0.005121\n",
      "750     Visa_cadelantosefectivo_diff_prev    0.004944\n",
      "32                  cprestamos_personales    0.004810\n",
      "153                      Visa_mpagominimo    0.004774\n",
      "415                       Visa_status_max    0.004755\n",
      "420                  Visa_msaldototal_min    0.004738\n",
      "143                   Visa_madelantopesos    0.004650\n",
      "217             mprestamos_personales_max    0.004388\n",
      "728       Visa_mconsumosdolares_diff_prev    0.004314\n",
      "293         ccomisiones_mantenimiento_max    0.004271\n",
      "554                    mpayroll_diff_prev    0.004228\n",
      "214             cprestamos_personales_min    0.004015\n",
      "296                 ccomisiones_otras_min    0.004013\n",
      "81              mtransferencias_recibidas    0.003983\n",
      "592   ccomisiones_mantenimiento_diff_prev    0.003917\n"
     ]
    }
   ],
   "source": [
    "#lista de feature importances y porcentajes \n",
    "\n",
    "importances = model_opt.feature_importances_\n",
    "feature_names = X.columns   \n",
    "# Crear un DataFrame para visualizar las importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "print(importance_df.sort_values(by='Importance', ascending=False).head(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b860e",
   "metadata": {},
   "source": [
    "## Canaritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de0fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326527, 955)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Canaritos rf en mes train\n",
    "#uso esta semilla para los canaritos\n",
    "# np.random.seed(102191)\n",
    "\n",
    "# # Agregar 200 columnas aleatorias uniformes entre 0 y 1\n",
    "# for i in range(1, 201):\n",
    "#     df_filtrado = df_filtrado.with_columns(\n",
    "#         pl.Series(f\"canarito_{i}\", np.random.rand(df_filtrado.height))\n",
    "#     )\n",
    "\n",
    "# df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtrar train\n",
    "# X = df_filtrado.filter(pl.col(\"foto_mes\") == mes_train)\n",
    "# y = X[\"clase_ternaria\"]\n",
    "# X = X.drop(\"clase_ternaria\")\n",
    "\n",
    "# # Filtrar validaci√≥n/futuro\n",
    "# X_futuro = df_filtrado.filter(pl.col(\"foto_mes\") == mes_test)\n",
    "# y_futuro = X_futuro[\"clase_ternaria\"]\n",
    "# X_futuro = X_futuro.drop(\"clase_ternaria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancia de modelo Opt: 294620000.0\n"
     ]
    }
   ],
   "source": [
    "# #Parametros optimizados\n",
    "# param_opt = {'criterion': 'entropy',\n",
    "#              'n_estimators': 100,\n",
    "#              'max_depth': 20,\n",
    "#              'min_samples_split': 80,\n",
    "#              'min_samples_leaf': 40,\n",
    "#              'max_leaf_nodes': 13}\n",
    "\n",
    "# model_opt = RandomForestClassifier(random_state=SEMILLAS[0], **param_opt)\n",
    "\n",
    "# model_opt.fit(X, y)\n",
    "# y_pred_opt = model_opt.predict_proba(X_futuro)\n",
    "# print(f\"Ganancia de modelo Opt: {ganancia_prob(y_pred_opt, y_futuro)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Feature  Importance\n",
      "187                  mcaja_ahorro_max    0.049571\n",
      "107                      ctrx_quarter    0.041316\n",
      "364                  ctrx_quarter_min    0.036957\n",
      "18                       mcaja_ahorro    0.032666\n",
      "52                           mpayroll    0.031583\n",
      "..                                ...         ...\n",
      "516   mprestamos_personales_diff_prev    0.000556\n",
      "465          mrentabilidad_diff_prev2    0.000524\n",
      "732     Visa_madelantopesos_diff_prev    0.000523\n",
      "507  mtarjeta_visa_consumo_diff_prev2    0.000517\n",
      "715            Visa_status_diff_prev2    0.000507\n",
      "\n",
      "[160 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# #lista de feature importances y porcentajes \n",
    "\n",
    "# importances = model_opt.feature_importances_\n",
    "# feature_names = X.columns   \n",
    "# # Crear un DataFrame para visualizar las importancias\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Importance': importances\n",
    "# })\n",
    "# print(importance_df.sort_values(by='Importance', ascending=False).head(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec84b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de variables 'canarito' en el Top 160: 13\n"
     ]
    }
   ],
   "source": [
    "# # Tomamos las 160 variables m√°s importantes\n",
    "# top_features = importance_df.head(400)\n",
    "\n",
    "# # Contar cu√°ntas tienen el prefijo 'canarito'\n",
    "# canarito_count = top_features['Feature'].str.startswith(\"canarito\").sum()\n",
    "\n",
    "# print(f\"Cantidad de variables 'canarito' en el Top 160: {canarito_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posici√≥n media de los canaritos: 816.92\n"
     ]
    }
   ],
   "source": [
    "# # Asegurar que est√° ordenado por importancia descendente\n",
    "# importance_df = importance_df.sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# # Agregar columna con la posici√≥n\n",
    "# importance_df[\"Rank\"] = importance_df.index + 1\n",
    "\n",
    "# # Filtrar solo las variables 'canarito'\n",
    "# canaritos = importance_df[importance_df[\"Feature\"].str.startswith(\"canarito\")]\n",
    "\n",
    "# # Calcular posici√≥n media\n",
    "# pos_media_canaritos = canaritos[\"Rank\"].mean()\n",
    "\n",
    "# print(f\"Posici√≥n media de los canaritos: {pos_media_canaritos:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ad455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posici√≥n media de las variables 'canarito': 816.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Gr√°fico\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(canaritos[\"Rank\"], bins=20)\n",
    "# plt.axvline(pos_media_canaritos, color='red', linestyle='--', label=f\"Media: {pos_media_canaritos:.1f}\")\n",
    "# plt.title(\"Distribuci√≥n de las posiciones de variables 'canarito' en el ranking de importancia\")\n",
    "# plt.xlabel(\"Posici√≥n (1 = m√°s importante)\")\n",
    "# plt.ylabel(\"Cantidad de canaritos\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Posici√≥n media de las variables 'canarito': {pos_media_canaritos:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138f472",
   "metadata": {},
   "source": [
    "#Ganancia modelo clase 211 MARS sin nada\n",
    "Ganancia modelo optimizaod ac√°, 331 mars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a435b72",
   "metadata": {},
   "source": [
    "## Entrenar Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo entrenado s√≥lo con 1 2 y 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa252171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo guardado...\n",
      "‚úÖ Modelo cargado exitosamente\n",
      "\n",
      "============================================================\n",
      "PREDICCIONES PARA KAGGLE\n",
      "============================================================\n",
      "Cargando n√∫mero √≥ptimo de env√≠os...\n",
      "N√∫mero √≥ptimo de env√≠os: 11,403\n",
      "\n",
      "Preparando datos de Kaggle...\n",
      "Datos de Kaggle: (164313, 802)\n",
      "Generando predicciones...\n",
      "Seleccionando top 11,403 clientes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json \n",
    "# ============================================================\n",
    "# CARGAR MODELO GUARDADO\n",
    "# ============================================================\n",
    "\n",
    "print(\"Cargando modelo guardado...\")\n",
    "model_test = lgb.Booster(model_file='data/modelo_train_test.txt')\n",
    "print(\"‚úÖ Modelo cargado exitosamente\")\n",
    "\n",
    "# ============================================================\n",
    "# PREDECIR EN KAGGLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICCIONES PARA KAGGLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar el n√∫mero √≥ptimo de env√≠os\n",
    "print(\"Cargando n√∫mero √≥ptimo de env√≠os...\")\n",
    "with open('data/resultados_test.json', 'r') as f:\n",
    "    resultados_test = json.load(f)\n",
    "\n",
    "n_envios_optimo = resultados_test['n_envios_optimo']\n",
    "print(f\"N√∫mero √≥ptimo de env√≠os: {n_envios_optimo:,}\")\n",
    "\n",
    "# Preparar datos de Kaggle\n",
    "print(\"\\nPreparando datos de Kaggle...\")\n",
    "X_kaggle = df_kaggle.drop(\"clase_ternaria\", axis=1).to_numpy().astype('float32')\n",
    "clientes_kaggle = df_kaggle[\"numero_de_cliente\"].to_numpy()\n",
    "\n",
    "print(f\"Datos de Kaggle: {X_kaggle.shape}\")\n",
    "\n",
    "# Predicciones probabil√≠sticas\n",
    "print(\"Generando predicciones...\")\n",
    "y_pred_prob = model_test.predict(X_kaggle)\n",
    "\n",
    "# Seleccionar top N clientes\n",
    "print(f\"Seleccionando top {n_envios_optimo:,} clientes...\")\n",
    "indices_top = np.argsort(-y_pred_prob)[:n_envios_optimo]\n",
    "\n",
    "# Crear predicci√≥n binaria\n",
    "y_pred_bin = np.zeros(len(y_pred_prob), dtype=int)\n",
    "y_pred_bin[indices_top] = 1\n",
    "\n",
    "# Crear submission\n",
    "submission = pd.DataFrame({\n",
    "    \"numero_de_cliente\": clientes_kaggle,\n",
    "    \"Predicted\": y_pred_bin\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eafd001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Archivo guardado: 'data/predicciones_kaggle.csv'\n",
      "Total registros: 164,313\n",
      "Predicciones positivas (1): 11,403\n",
      "Predicciones negativas (0): 152,910\n",
      "\n",
      "üìÑ Primeras filas:\n",
      "   numero_de_cliente  Predicted\n",
      "0          433987585          0\n",
      "1          434200463          0\n",
      "2          434285203          0\n",
      "3          434436672          0\n",
      "4          434468833          0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar\n",
    "submission.to_csv(\"data/predicciones_kaggle.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Archivo guardado: 'data/predicciones_kaggle.csv'\")\n",
    "print(f\"Total registros: {len(submission):,}\")\n",
    "print(f\"Predicciones positivas (1): {y_pred_bin.sum():,}\")\n",
    "print(f\"Predicciones negativas (0): {(y_pred_bin == 0).sum():,}\")\n",
    "\n",
    "print(\"\\nüìÑ Primeras filas:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e2cad",
   "metadata": {},
   "source": [
    "## Modelo entrenado con 01..04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35c7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARANDO DATOS: TRAIN + TEST COMBINADOS\n",
      "============================================================\n",
      "Creando pesos en df_train...\n",
      "Creando pesos en df_test...\n",
      "Concatenando df_train y df_test...\n",
      "df_train: (5284, 804)\n",
      "df_test: (163418, 804)\n",
      "df_full: (168702, 804)\n",
      "\n",
      "Convirtiendo a numpy (float32)...\n",
      "X_full: (168702, 801), dtype: float32\n",
      "y_full_binaria: (168702,), dtype: int8\n",
      "Clase positiva: 7,369\n",
      "Clase negativa: 161,333\n",
      "\n",
      "Liberando df_train, df_test, df_full de memoria...\n",
      "‚úÖ Datos preparados\n",
      "\n",
      "============================================================\n",
      "ENTRENAMIENTO MODELO FINAL (TRAIN + TEST)\n",
      "============================================================\n",
      "Cargando hiperpar√°metros...\n",
      "Trial 39\n",
      "Ganancia esperada: $1,058,480,000\n",
      "Iteraciones: 100\n",
      "\n",
      "Par√°metros del modelo:\n",
      "  objective: binary\n",
      "  metric: custom\n",
      "  boosting_type: gbdt\n",
      "  first_metric_only: True\n",
      "  boost_from_average: True\n",
      "  feature_pre_filter: False\n",
      "  max_bin: 31\n",
      "  num_leaves: 91\n",
      "  learning_rate: 0.09904281706673441\n",
      "  min_data_in_leaf: 370\n",
      "  feature_fraction: 0.9029799021041279\n",
      "  bagging_fraction: 0.5198907300236562\n",
      "  seed: 550007\n",
      "  verbose: 1\n",
      "\n",
      "Creando dataset con X_full: (168702, 801)\n",
      "Entrenando modelo final con 100 iteraciones...\n",
      "[LightGBM] [Info] Number of positive: 7369, number of negative: 161333\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20463\n",
      "[LightGBM] [Info] Number of data points in the train set: 168702, number of used features: 801\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.043681 -> initscore=-3.086173\n",
      "[LightGBM] [Info] Start training from score -3.086173\n",
      "‚úÖ Modelo final entrenado exitosamente\n",
      "‚úÖ Modelo guardado en 'data/modelo_final_train_test.txt'\n",
      "\n",
      "============================================================\n",
      "PREDICCIONES PARA KAGGLE\n",
      "============================================================\n",
      "\n",
      "Leyendo df_kaggle...\n",
      "df_kaggle: (164313, 803)\n",
      "Tipo de numero_de_cliente: int64\n",
      "clientes_kaggle: dtype=int64\n",
      "X_kaggle: (164313, 801), dtype=float32\n",
      "\n",
      "Generando predicciones...\n",
      "Predicciones generadas: 164,313\n",
      "Seleccionando top 12,000 clientes...\n",
      "\n",
      "Tipos en submission:\n",
      "  numero_de_cliente: int64\n",
      "  Predicted: int8\n",
      "\n",
      "‚úÖ Archivo guardado: 'data/predicciones_kaggle_final.csv'\n",
      "\n",
      "üìä RESUMEN:\n",
      "  Total registros: 164,313\n",
      "  Predicciones positivas (1): 12,000\n",
      "  Predicciones negativas (0): 152,313\n",
      "  % positivos: 7.30%\n",
      "\n",
      "üìÑ Primeras filas:\n",
      "   numero_de_cliente  Predicted\n",
      "0          433987585          0\n",
      "1          434200463          1\n",
      "2          434285203          0\n",
      "3          434436672          0\n",
      "4          434468833          1\n",
      "5          434500404          0\n",
      "6          434626792          0\n",
      "7          434672369          0\n",
      "8          434687467          0\n",
      "9          434694905          0\n",
      "\n",
      "Verificaci√≥n de IDs (primeros 5):\n",
      "0    433987585\n",
      "1    434200463\n",
      "2    434285203\n",
      "3    434436672\n",
      "4    434468833\n",
      "Name: numero_de_cliente, dtype: int64\n",
      "\n",
      "üéâ Modelo final entrenado y predicciones listas para Kaggle!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS: TRAIN + TEST COMBINADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DATOS: TRAIN + TEST COMBINADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear pesos en df_train\n",
    "print(\"Creando pesos en df_train...\")\n",
    "df_train['clase_peso'] = 1.0\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 2. Crear pesos en df_test\n",
    "print(\"Creando pesos en df_test...\")\n",
    "df_test['clase_peso'] = 1.0\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 3. Concatenar df_train y df_test\n",
    "print(\"Concatenando df_train y df_test...\")\n",
    "df_full = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")\n",
    "print(f\"df_full: {df_full.shape}\")\n",
    "\n",
    "# 4. Convertir a numpy (optimizado) - SIN numero_de_cliente\n",
    "print(\"\\nConvirtiendo a numpy (float32)...\")\n",
    "X_full = df_full.drop([\"clase_ternaria\", \"clase_peso\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "y_full = df_full[\"clase_ternaria\"].to_numpy()\n",
    "pesos_full = df_full[\"clase_peso\"].to_numpy().astype('float32')\n",
    "\n",
    "# Binarizar\n",
    "y_full_binaria = (y_full != \"CONTINUA\").astype('int8')\n",
    "\n",
    "print(f\"X_full: {X_full.shape}, dtype: {X_full.dtype}\")\n",
    "print(f\"y_full_binaria: {y_full_binaria.shape}, dtype: {y_full_binaria.dtype}\")\n",
    "print(f\"Clase positiva: {y_full_binaria.sum():,}\")\n",
    "print(f\"Clase negativa: {(y_full_binaria == 0).sum():,}\")\n",
    "\n",
    "# Liberar memoria\n",
    "print(\"\\nLiberando df_train, df_test, df_full de memoria...\")\n",
    "del df_train, df_test, df_full, y_full\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Datos preparados\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR M√âTRICA PERSONALIZADA DE GANANCIA\n",
    "# ============================================================\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "def ganancia_lgb(y_pred, data):\n",
    "    \"\"\"M√©trica personalizada de ganancia para LightGBM.\"\"\"\n",
    "    weight = data.get_weight()\n",
    "    \n",
    "    # Calcular ganancia para cada predicci√≥n\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - costo_estimulo\n",
    "    \n",
    "    # Ordenar por predicci√≥n descendente\n",
    "    indices = np.argsort(-y_pred)\n",
    "    ganancia_ordenada = ganancia[indices]\n",
    "    \n",
    "    # Calcular ganancia acumulada m√°xima\n",
    "    ganancia_acum = np.cumsum(ganancia_ordenada)\n",
    "    max_ganancia = np.max(ganancia_acum)\n",
    "    \n",
    "    return 'ganancia', max_ganancia, True\n",
    "\n",
    "# ============================================================\n",
    "# ENTRENAR MODELO FINAL CON TRAIN + TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO MODELO FINAL (TRAIN + TEST)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar mejores hiperpar√°metros\n",
    "print(\"Cargando hiperpar√°metros...\")\n",
    "with open('data/mejores_hiperparametros.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "config = data[0] if isinstance(data, list) else data\n",
    "\n",
    "print(f\"Trial {config['trial_number']}\")\n",
    "print(f\"Ganancia esperada: ${config['value']:,.0f}\")\n",
    "print(f\"Iteraciones: {config['best_iter']}\")\n",
    "\n",
    "# Configurar par√°metros\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'custom',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': config['params']['num_leaves'],\n",
    "    'learning_rate': config['params']['learning_rate'],\n",
    "    'min_data_in_leaf': config['params']['min_data_in_leaf'],\n",
    "    'feature_fraction': config['params']['feature_fraction'],\n",
    "    'bagging_fraction': config['params']['bagging_fraction'],\n",
    "    'seed': SEMILLAS[0],\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "print(\"\\nPar√°metros del modelo:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Crear dataset completo\n",
    "print(f\"\\nCreando dataset con X_full: {X_full.shape}\")\n",
    "full_data = lgb.Dataset(X_full,\n",
    "                        label=y_full_binaria,\n",
    "                        weight=pesos_full)\n",
    "\n",
    "# Entrenar modelo final\n",
    "print(f\"Entrenando modelo final con {config['best_iter']} iteraciones...\")\n",
    "model_final = lgb.train(\n",
    "    params,\n",
    "    full_data,\n",
    "    num_boost_round=config['best_iter'],\n",
    "    feval=ganancia_lgb,\n",
    "    callbacks=[lgb.log_evaluation(period=50)]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modelo final entrenado exitosamente\")\n",
    "\n",
    "# Guardar modelo final\n",
    "model_final.save_model('data/predicciones/modelo_final_train_test.txt')\n",
    "print(\"‚úÖ Modelo guardado en 'data/modelo_final_train_test.txt'\")\n",
    "\n",
    "# Liberar memoria\n",
    "del full_data, X_full, y_full_binaria, pesos_full\n",
    "gc.collect()\n",
    "\n",
    "# ============================================================\n",
    "# PREDECIR EN KAGGLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICCIONES PARA KAGGLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar n√∫mero √≥ptimo de env√≠os\n",
    "# with open('data/resultados_test.json', 'r') as f:\n",
    "#     resultados_test = json.load(f)\n",
    "\n",
    "# n_envios_optimo = resultados_test['n_envios_optimo']\n",
    "n_envios_optimo = 12000  # Valor fijo \n",
    "# print(f\"N√∫mero √≥ptimo de env√≠os: {n_envios_optimo:,}\")\n",
    "\n",
    "\n",
    "# Leer df_kaggle con tipos optimizados\n",
    "print(\"\\nLeyendo df_kaggle...\")\n",
    "# Primero identificar las columnas\n",
    "columnas = pd.read_csv(\"data/df_kaggle.csv\", nrows=0).columns.tolist()\n",
    "\n",
    "# Crear diccionario de tipos: float32 para todas EXCEPTO numero_de_cliente\n",
    "dtypes = {col: 'float32' for col in columnas if col not in ['numero_de_cliente', 'clase_ternaria']}\n",
    "# numero_de_cliente se mantiene como int64/float64 por defecto\n",
    "\n",
    "df_kaggle = pd.read_csv(\n",
    "    \"data/df_kaggle.csv\",\n",
    "    dtype=dtypes,\n",
    "    low_memory=True\n",
    ")\n",
    "\n",
    "print(f\"df_kaggle: {df_kaggle.shape}\")\n",
    "print(f\"Tipo de numero_de_cliente: {df_kaggle['numero_de_cliente'].dtype}\")\n",
    "\n",
    "# Preparar datos - GUARDAMOS numero_de_cliente SIN convertir\n",
    "clientes_kaggle = df_kaggle[\"numero_de_cliente\"].values  # Mantiene tipo original\n",
    "X_kaggle = df_kaggle.drop([\"clase_ternaria\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "\n",
    "print(f\"clientes_kaggle: dtype={clientes_kaggle.dtype}\")\n",
    "print(f\"X_kaggle: {X_kaggle.shape}, dtype={X_kaggle.dtype}\")\n",
    "\n",
    "del df_kaggle\n",
    "gc.collect()\n",
    "\n",
    "# Predecir\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "y_pred_prob = model_final.predict(X_kaggle)\n",
    "\n",
    "print(f\"Predicciones generadas: {len(y_pred_prob):,}\")\n",
    "\n",
    "# Seleccionar top N clientes\n",
    "print(f\"Seleccionando top {n_envios_optimo:,} clientes...\")\n",
    "indices_top = np.argsort(-y_pred_prob)[:n_envios_optimo]\n",
    "\n",
    "# Crear predicci√≥n binaria\n",
    "y_pred_bin = np.zeros(len(y_pred_prob), dtype='int8')\n",
    "y_pred_bin[indices_top] = 1\n",
    "\n",
    "# Crear submission - numero_de_cliente mantiene su tipo original\n",
    "submission = pd.DataFrame({\n",
    "    \"numero_de_cliente\": clientes_kaggle,  # Tipo original preservado\n",
    "    \"Predicted\": y_pred_bin\n",
    "})\n",
    "\n",
    "# Verificar tipos\n",
    "print(f\"\\nTipos en submission:\")\n",
    "print(f\"  numero_de_cliente: {submission['numero_de_cliente'].dtype}\")\n",
    "print(f\"  Predicted: {submission['Predicted'].dtype}\")\n",
    "\n",
    "# Guardar\n",
    "submission.to_csv(\"data/predicciones_kaggle_final.csv\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Archivo guardado: 'data/predicciones_kaggle_final.csv'\")\n",
    "print(f\"\\nüìä RESUMEN:\")\n",
    "print(f\"  Total registros: {len(submission):,}\")\n",
    "print(f\"  Predicciones positivas (1): {y_pred_bin.sum():,}\")\n",
    "print(f\"  Predicciones negativas (0): {(y_pred_bin == 0).sum():,}\")\n",
    "print(f\"  % positivos: {y_pred_bin.sum() / len(submission) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nüìÑ Primeras filas:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Verificar que los IDs se mantienen correctos\n",
    "print(\"\\nVerificaci√≥n de IDs (primeros 5):\")\n",
    "print(submission['numero_de_cliente'].head())\n",
    "\n",
    "print(\"\\nüéâ Modelo final entrenado y predicciones listas para Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831d497",
   "metadata": {},
   "source": [
    "## -4k era entrenado con 01..03 y predecir 06 con los mejores hiperparametros de mi primer corrida (30) con metric ganancia\n",
    "## -3k simil anterior pero modelo reentrenado con 01..04 con metric AUC \n",
    "## -3 K simil anterior pero modelo reentrenado con 01..04 con metric custom\n",
    "## -2 umbral fijo de 12k \n",
    "## 0 de 01 02 y 03 s√≥lo los baja+1/2. \n",
    "\n",
    "## voy a probar con slopes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
