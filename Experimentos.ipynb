{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "330051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e652414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMILLAS = [550007, 550019, 550031, 550033, 550047]\n",
    "\n",
    "mes_train = 202103, 202102, 202101\n",
    "mes_test = 202104\n",
    "mes_kaggle = 202106\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39165b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que archivos son? esos meses seleccionados SIN SLOPE\n",
    "#df_train.write_csv(\"data/df_train_01_02_03.csv\")\n",
    "#df_test.write_csv(\"data/df_test_04.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2a3b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv(\"data/df_train_fe.csv\")\n",
    "df_test = pd.read_csv(\"data/df_test_04.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "470c4533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/df_train_c12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "734a6cab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_train_03_continua = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/df_train_03_continua.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "df_train_03_continua = pd.read_csv(\"data/df_train_03_continua.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69b35734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = pd.concat([df_train, df_train_03_continua], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8cf600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 803)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31260188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163418, 803)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37906fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_03_continua = pd.read_csv(\"data/df_train_01_02_03.csv\")\n",
    "# #Selecciono solo las 202103 en foto_es y continua en clase_ternaria\n",
    "# df_train_03_continua = df_train_03_continua[(df_train_03_continua['foto_mes'] == 202103) & (df_train_03_continua['clase_ternaria'] == 'CONTINUA')]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar en csv\n",
    "#df_train_03_continua.to_csv(\"data/df_train_03_continua.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los meses deseados\n",
    "# df_train = df_trainc\n",
    "\n",
    "\n",
    "# #Guardar en CSV\n",
    "# df_train.to_csv(\"df_train_c12.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd2aebea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liberar memoria antes de empezar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ab0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv(\"data/df_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36daa60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#tiene mi df_train la columna \"clase_ternaria\"?\n",
    "print(\"clase_ternaria\" in df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38450efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flor\\AppData\\Local\\Temp\\ipykernel_2764\\1594840123.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train['clase_peso'] = 1.0\n"
     ]
    }
   ],
   "source": [
    "df_train['clase_peso'] = 1.0\n",
    "\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a08b7d",
   "metadata": {},
   "source": [
    "##Optimización con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8cc7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (116484, 802) (116484,) (116484,)\n",
      "Validation: (49922, 802) (49922,) (49922,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar X e y\n",
    "X = df_train.drop([\"clase_ternaria\", \"clase_peso\"], axis=1)  # ✅ Sacamos también clase_peso\n",
    "y = df_train[\"clase_ternaria\"]\n",
    "pesos = df_train[\"clase_peso\"]  # ✅ Guardamos los pesos\n",
    "\n",
    "# Binarizar y\n",
    "y_binaria = (y != \"CONTINUA\").astype(int)\n",
    "\n",
    "# Split 70/30 (ahora incluimos los pesos)\n",
    "X_train, X_val, y_train, y_val, pesos_train, pesos_val = train_test_split(\n",
    "    X, y_binaria, pesos,  # ✅ Separamos X, y Y pesos\n",
    "    train_size=0.7,\n",
    "    random_state=42,\n",
    "    stratify=y_binaria\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape, pesos_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape, pesos_val.shape)\n",
    "\n",
    "# Ahora en el Dataset:\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train,\n",
    "                          weight=pesos_train  # ✅ Usamos los pesos del train\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f3d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia_prob(y_pred, data):\n",
    "  weight = data.get_weight()\n",
    "  ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "  ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "  ganancia = np.cumsum(ganancia)  # ✅ Bien\n",
    "  return 'gan_eval', np.max(ganancia), True\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7157293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 10:44:12,897] Using an existing study with name 'exp_301_lgbm' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.1) # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 300, 1500)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': SEMILLAS[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train, # eligir la clase\n",
    "                              weight=pesos_train\n",
    "                              )\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100, # modificar, subit y subir... y descomentar la línea inferior\n",
    "        # early_stopping_rounds= int(50 + 5 / learning_rate),\n",
    "        feval=ganancia_prob,\n",
    "        stratified=True,\n",
    "        nfold=4,\n",
    "        seed=SEMILLAS[0],\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=int(50 + 5/learning_rate), verbose=False),\n",
    "                lgb.log_evaluation(period=200),\n",
    "                ]\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 4\n",
    "# Al final de objective()\n",
    "gc.collect()\n",
    "\n",
    "#guardar el archivo en mi carpeta data\n",
    "storage_name = \"sqlite:///data/optimization_lgbm.db\"\n",
    "\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1bddf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 20:28:24,149] Trial 55 finished with value: 1217920000.0 and parameters: {'num_leaves': 61, 'learning_rate': 0.09465354518859136, 'min_data_in_leaf': 1186, 'feature_fraction': 0.8516610829503432, 'bagging_fraction': 0.3754628529986752}. Best is trial 55 with value: 1217920000.0.\n",
      "[I 2025-10-10 20:28:57,415] Trial 56 finished with value: 1218800000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.094578826057412, 'min_data_in_leaf': 1139, 'feature_fraction': 0.8527856410643342, 'bagging_fraction': 0.3704426793205404}. Best is trial 56 with value: 1218800000.0.\n",
      "[I 2025-10-10 20:29:32,411] Trial 57 finished with value: 1221400000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09473864724945882, 'min_data_in_leaf': 1142, 'feature_fraction': 0.8407871119103238, 'bagging_fraction': 0.4909641862861174}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:30:08,505] Trial 58 finished with value: 1211420000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.08890322319491181, 'min_data_in_leaf': 1166, 'feature_fraction': 0.8416342736081581, 'bagging_fraction': 0.48251933237128086}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:30:42,522] Trial 59 finished with value: 1219480000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.08903960511870229, 'min_data_in_leaf': 1176, 'feature_fraction': 0.9415124635489165, 'bagging_fraction': 0.5008436241375853}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:31:19,165] Trial 60 finished with value: 1220980000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.08840853877660722, 'min_data_in_leaf': 1178, 'feature_fraction': 0.9626829391745482, 'bagging_fraction': 0.4812296837883115}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:31:49,551] Trial 61 finished with value: 1219060000.0 and parameters: {'num_leaves': 43, 'learning_rate': 0.08224056538872468, 'min_data_in_leaf': 1288, 'feature_fraction': 0.9523502077144502, 'bagging_fraction': 0.3775769030727549}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:32:24,808] Trial 62 finished with value: 1215380000.0 and parameters: {'num_leaves': 42, 'learning_rate': 0.08307979166714946, 'min_data_in_leaf': 1390, 'feature_fraction': 0.9538869836962048, 'bagging_fraction': 0.44818451542085314}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:32:57,081] Trial 63 finished with value: 1214660000.0 and parameters: {'num_leaves': 40, 'learning_rate': 0.07519177980716955, 'min_data_in_leaf': 1215, 'feature_fraction': 0.9356249217209471, 'bagging_fraction': 0.40386194940286685}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:33:32,685] Trial 64 finished with value: 1219240000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.07967104069174298, 'min_data_in_leaf': 1101, 'feature_fraction': 0.9735358797332677, 'bagging_fraction': 0.5078976037541437}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:34:05,392] Trial 65 finished with value: 1214940000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.07918380080258051, 'min_data_in_leaf': 1280, 'feature_fraction': 0.999103549984517, 'bagging_fraction': 0.5971532284201964}. Best is trial 57 with value: 1221400000.0.\n",
      "[I 2025-10-10 20:34:38,334] Trial 66 finished with value: 1221820000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.08819549438592612, 'min_data_in_leaf': 1077, 'feature_fraction': 0.9614150587803477, 'bagging_fraction': 0.5165036793987392}. Best is trial 66 with value: 1221820000.0.\n",
      "[I 2025-10-10 20:35:09,719] Trial 67 finished with value: 1222760000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.0863711907945781, 'min_data_in_leaf': 1055, 'feature_fraction': 0.9648137097916736, 'bagging_fraction': 0.5127745735943776}. Best is trial 67 with value: 1222760000.0.\n",
      "[I 2025-10-10 20:35:46,532] Trial 68 finished with value: 1222400000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.0878952674338346, 'min_data_in_leaf': 1031, 'feature_fraction': 0.9171946729562711, 'bagging_fraction': 0.5125702235861666}. Best is trial 67 with value: 1222760000.0.\n",
      "[I 2025-10-10 20:36:22,719] Trial 69 finished with value: 1223180000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.08817518074445546, 'min_data_in_leaf': 1015, 'feature_fraction': 0.9250245732464026, 'bagging_fraction': 0.5681785078191248}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:36:53,879] Trial 70 finished with value: 1216320000.0 and parameters: {'num_leaves': 35, 'learning_rate': 0.08597747522083918, 'min_data_in_leaf': 1010, 'feature_fraction': 0.9084993954639704, 'bagging_fraction': 0.5694169056268594}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:37:35,364] Trial 71 finished with value: 1212480000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.0710402892529631, 'min_data_in_leaf': 1045, 'feature_fraction': 0.8216059081620146, 'bagging_fraction': 0.631177560305851}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:38:09,051] Trial 72 finished with value: 1200540000.0 and parameters: {'num_leaves': 60, 'learning_rate': 0.04234893865939092, 'min_data_in_leaf': 941, 'feature_fraction': 0.9085327780662623, 'bagging_fraction': 0.46663884282613366}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:38:40,788] Trial 73 finished with value: 1219600000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.08802567572120086, 'min_data_in_leaf': 1075, 'feature_fraction': 0.9993726130043474, 'bagging_fraction': 0.5253693739808769}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:39:06,549] Trial 74 finished with value: 1127620000.0 and parameters: {'num_leaves': 37, 'learning_rate': 0.014345958708266, 'min_data_in_leaf': 1254, 'feature_fraction': 0.12261621904785508, 'bagging_fraction': 0.633924684553479}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:39:47,967] Trial 75 finished with value: 1215360000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.07511104095416246, 'min_data_in_leaf': 951, 'feature_fraction': 0.3580142869951239, 'bagging_fraction': 0.5711464564701633}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:40:22,240] Trial 76 finished with value: 1220220000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.0893008713643601, 'min_data_in_leaf': 1106, 'feature_fraction': 0.9719868209028788, 'bagging_fraction': 0.5290155443291761}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:41:05,541] Trial 77 finished with value: 1219040000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09071792913203527, 'min_data_in_leaf': 1101, 'feature_fraction': 0.968070079787488, 'bagging_fraction': 0.45039050659087587}. Best is trial 69 with value: 1223180000.0.\n",
      "[I 2025-10-10 20:41:42,459] Trial 78 finished with value: 1224300000.0 and parameters: {'num_leaves': 59, 'learning_rate': 0.09590732799167846, 'min_data_in_leaf': 1029, 'feature_fraction': 0.9232543597093975, 'bagging_fraction': 0.5449210935573476}. Best is trial 78 with value: 1224300000.0.\n",
      "[I 2025-10-10 20:42:19,513] Trial 79 finished with value: 1219320000.0 and parameters: {'num_leaves': 59, 'learning_rate': 0.09576635646991372, 'min_data_in_leaf': 1029, 'feature_fraction': 0.9233184872241963, 'bagging_fraction': 0.6082950443230366}. Best is trial 78 with value: 1224300000.0.\n",
      "[I 2025-10-10 20:42:54,220] Trial 80 finished with value: 1217620000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.08386461107410019, 'min_data_in_leaf': 1348, 'feature_fraction': 0.8828533397453284, 'bagging_fraction': 0.42058646360919616}. Best is trial 78 with value: 1224300000.0.\n",
      "[I 2025-10-10 20:43:28,149] Trial 81 finished with value: 1229580000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.09625117828322796, 'min_data_in_leaf': 987, 'feature_fraction': 0.9252352451805027, 'bagging_fraction': 0.6889400213537696}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:44:06,737] Trial 82 finished with value: 1218060000.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.09677292257811534, 'min_data_in_leaf': 926, 'feature_fraction': 0.7756831388091106, 'bagging_fraction': 0.6774878281083121}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:44:42,860] Trial 83 finished with value: 1222100000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09301508543368003, 'min_data_in_leaf': 999, 'feature_fraction': 0.9190740570361863, 'bagging_fraction': 0.7258024249691499}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:45:19,228] Trial 84 finished with value: 1219180000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.09165087639107877, 'min_data_in_leaf': 989, 'feature_fraction': 0.9218096229114616, 'bagging_fraction': 0.7456429715319765}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:45:56,066] Trial 85 finished with value: 1223720000.0 and parameters: {'num_leaves': 60, 'learning_rate': 0.08473380952543935, 'min_data_in_leaf': 1054, 'feature_fraction': 0.8870105717454693, 'bagging_fraction': 0.6987284182263538}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:46:35,757] Trial 86 finished with value: 1220200000.0 and parameters: {'num_leaves': 62, 'learning_rate': 0.08508082303710053, 'min_data_in_leaf': 1062, 'feature_fraction': 0.8763471537003821, 'bagging_fraction': 0.8093965246571384}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:47:18,229] Trial 87 finished with value: 1223240000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09620975484686069, 'min_data_in_leaf': 865, 'feature_fraction': 0.8915141581709488, 'bagging_fraction': 0.7234994717048617}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:48:00,812] Trial 88 finished with value: 1226760000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.09137568931402851, 'min_data_in_leaf': 867, 'feature_fraction': 0.89513773678705, 'bagging_fraction': 0.7088676835404695}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:48:43,467] Trial 89 finished with value: 1218700000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09631519967999207, 'min_data_in_leaf': 845, 'feature_fraction': 0.8072943534024135, 'bagging_fraction': 0.7923430260063016}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:49:21,297] Trial 90 finished with value: 1223980000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.09158987063965068, 'min_data_in_leaf': 875, 'feature_fraction': 0.8831443883477021, 'bagging_fraction': 0.703980493525114}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:49:59,592] Trial 91 finished with value: 1224620000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.09147924658793975, 'min_data_in_leaf': 870, 'feature_fraction': 0.888616182741499, 'bagging_fraction': 0.7923680385521499}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:50:37,663] Trial 92 finished with value: 1229180000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.0968984057779594, 'min_data_in_leaf': 783, 'feature_fraction': 0.8836184604349976, 'bagging_fraction': 0.7025079560483733}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:51:15,351] Trial 93 finished with value: 1227580000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.0976349035609074, 'min_data_in_leaf': 802, 'feature_fraction': 0.861551395182461, 'bagging_fraction': 0.705832885006271}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:52:00,339] Trial 94 finished with value: 1224400000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.09197747076350847, 'min_data_in_leaf': 785, 'feature_fraction': 0.4785170462078497, 'bagging_fraction': 0.7748307838714851}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:52:47,011] Trial 95 finished with value: 1217940000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.09199328964370741, 'min_data_in_leaf': 798, 'feature_fraction': 0.4494094370957038, 'bagging_fraction': 0.8533816395784073}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:53:38,226] Trial 96 finished with value: 1216800000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.0925903482698554, 'min_data_in_leaf': 756, 'feature_fraction': 0.5109774680484563, 'bagging_fraction': 0.7660864796286222}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:54:24,755] Trial 97 finished with value: 1216100000.0 and parameters: {'num_leaves': 65, 'learning_rate': 0.09698844256736307, 'min_data_in_leaf': 716, 'feature_fraction': 0.49614656617985425, 'bagging_fraction': 0.7009485797852039}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:55:07,913] Trial 98 finished with value: 1218960000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09994737532446628, 'min_data_in_leaf': 873, 'feature_fraction': 0.4027023966186182, 'bagging_fraction': 0.7761653788375886}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:55:50,408] Trial 99 finished with value: 1218300000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.05637312890210832, 'min_data_in_leaf': 808, 'feature_fraction': 0.8613754251078103, 'bagging_fraction': 0.8362599573140056}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:56:29,522] Trial 100 finished with value: 1215380000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.09141089288214205, 'min_data_in_leaf': 913, 'feature_fraction': 0.8224948512055431, 'bagging_fraction': 0.7137942165048111}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:57:10,527] Trial 101 finished with value: 1224740000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09462709708171738, 'min_data_in_leaf': 764, 'feature_fraction': 0.7972776869706423, 'bagging_fraction': 0.8936130645289165}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:57:47,683] Trial 102 finished with value: 1221100000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09726604958401992, 'min_data_in_leaf': 684, 'feature_fraction': 0.6702663122824644, 'bagging_fraction': 0.9006015189137054}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:58:31,298] Trial 103 finished with value: 1223260000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09458109934239217, 'min_data_in_leaf': 787, 'feature_fraction': 0.8631056418006882, 'bagging_fraction': 0.6754974341529196}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 20:59:14,969] Trial 104 finished with value: 1223320000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.09776165531685778, 'min_data_in_leaf': 754, 'feature_fraction': 0.7968807797230144, 'bagging_fraction': 0.9291130929179423}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:00:03,522] Trial 105 finished with value: 1224220000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.08146833175311748, 'min_data_in_leaf': 827, 'feature_fraction': 0.5581583099654589, 'bagging_fraction': 0.8021919051769276}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:00:43,341] Trial 106 finished with value: 1221860000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09441503362358354, 'min_data_in_leaf': 832, 'feature_fraction': 0.5984265841132062, 'bagging_fraction': 0.9656777080859063}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:01:29,645] Trial 107 finished with value: 1217860000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09093028327872692, 'min_data_in_leaf': 887, 'feature_fraction': 0.45920493446860233, 'bagging_fraction': 0.8012940220899482}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:02:01,119] Trial 108 finished with value: 1206080000.0 and parameters: {'num_leaves': 62, 'learning_rate': 0.08188356531143902, 'min_data_in_leaf': 773, 'feature_fraction': 0.1956931375782509, 'bagging_fraction': 0.82607266638199}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:02:47,766] Trial 109 finished with value: 1222600000.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.09989259570409365, 'min_data_in_leaf': 821, 'feature_fraction': 0.47591423741238026, 'bagging_fraction': 0.7650411990309234}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:03:26,887] Trial 110 finished with value: 1217180000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.09040656547815408, 'min_data_in_leaf': 973, 'feature_fraction': 0.3628100457448197, 'bagging_fraction': 0.6754982255546707}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:04:13,888] Trial 111 finished with value: 1188880000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.025962353219512194, 'min_data_in_leaf': 708, 'feature_fraction': 0.5471701225224653, 'bagging_fraction': 0.8547074066468674}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:04:53,426] Trial 112 finished with value: 1221880000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09345429613575329, 'min_data_in_leaf': 636, 'feature_fraction': 0.6111857965351841, 'bagging_fraction': 0.7411501790867846}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:05:30,610] Trial 113 finished with value: 1225060000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09781981762634015, 'min_data_in_leaf': 861, 'feature_fraction': 0.8291098244849108, 'bagging_fraction': 0.7829971948116465}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:06:14,050] Trial 114 finished with value: 1224900000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09744484696603758, 'min_data_in_leaf': 687, 'feature_fraction': 0.4274963035272082, 'bagging_fraction': 0.8784772312661594}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:06:55,519] Trial 115 finished with value: 1220560000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09830489116438947, 'min_data_in_leaf': 608, 'feature_fraction': 0.4278131384867909, 'bagging_fraction': 0.8781366075401307}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:07:35,258] Trial 116 finished with value: 1219040000.0 and parameters: {'num_leaves': 61, 'learning_rate': 0.09567511922068256, 'min_data_in_leaf': 752, 'feature_fraction': 0.34215301054253233, 'bagging_fraction': 0.8798103844725174}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:08:13,062] Trial 117 finished with value: 1224520000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09790119402453486, 'min_data_in_leaf': 912, 'feature_fraction': 0.7339543667724326, 'bagging_fraction': 0.781090915315621}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:08:50,456] Trial 118 finished with value: 1220120000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09772469202543697, 'min_data_in_leaf': 666, 'feature_fraction': 0.774388931154283, 'bagging_fraction': 0.6278682951042728}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:09:30,079] Trial 119 finished with value: 1212620000.0 and parameters: {'num_leaves': 62, 'learning_rate': 0.09393952277880133, 'min_data_in_leaf': 917, 'feature_fraction': 0.7481146495940929, 'bagging_fraction': 0.7846909612824006}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:10:06,524] Trial 120 finished with value: 1227940000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09534375318764353, 'min_data_in_leaf': 859, 'feature_fraction': 0.8285260467235547, 'bagging_fraction': 0.8226326748527295}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:10:41,688] Trial 121 finished with value: 1214440000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.08694746862297201, 'min_data_in_leaf': 856, 'feature_fraction': 0.8335181521130466, 'bagging_fraction': 0.8411629717588366}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:11:23,472] Trial 122 finished with value: 1223260000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09818889433201955, 'min_data_in_leaf': 896, 'feature_fraction': 0.7226254314020157, 'bagging_fraction': 0.8241771544970798}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:12:03,730] Trial 123 finished with value: 1206500000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.0424911830664705, 'min_data_in_leaf': 735, 'feature_fraction': 0.8209114087757436, 'bagging_fraction': 0.7587891245547427}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:12:40,288] Trial 124 finished with value: 1211140000.0 and parameters: {'num_leaves': 65, 'learning_rate': 0.04827897664954107, 'min_data_in_leaf': 771, 'feature_fraction': 0.8521758905172105, 'bagging_fraction': 0.9422465095923804}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:13:19,174] Trial 125 finished with value: 1219320000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.09345636944331742, 'min_data_in_leaf': 965, 'feature_fraction': 0.7931480259584148, 'bagging_fraction': 0.8936710569227359}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:13:53,392] Trial 126 finished with value: 1226760000.0 and parameters: {'num_leaves': 59, 'learning_rate': 0.09607244736689871, 'min_data_in_leaf': 942, 'feature_fraction': 0.8982351392092441, 'bagging_fraction': 0.7817574737225903}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:14:29,078] Trial 127 finished with value: 1223220000.0 and parameters: {'num_leaves': 59, 'learning_rate': 0.09569740083627665, 'min_data_in_leaf': 947, 'feature_fraction': 0.9003799133868494, 'bagging_fraction': 0.7373304122361449}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:15:05,888] Trial 128 finished with value: 1223260000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09974019057440887, 'min_data_in_leaf': 852, 'feature_fraction': 0.8349742792213243, 'bagging_fraction': 0.8087716096674441}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:15:44,300] Trial 129 finished with value: 1215660000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.08982914578060022, 'min_data_in_leaf': 1496, 'feature_fraction': 0.8703629392091858, 'bagging_fraction': 0.7791560683891736}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:16:24,705] Trial 130 finished with value: 1220060000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.0948876309684487, 'min_data_in_leaf': 807, 'feature_fraction': 0.7063373756098079, 'bagging_fraction': 0.8666011278366599}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:16:59,768] Trial 131 finished with value: 1220060000.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.09746764702657396, 'min_data_in_leaf': 930, 'feature_fraction': 0.9389046130638505, 'bagging_fraction': 0.8228590250967094}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:17:39,238] Trial 132 finished with value: 1223220000.0 and parameters: {'num_leaves': 61, 'learning_rate': 0.09253086777156586, 'min_data_in_leaf': 690, 'feature_fraction': 0.39443137620293106, 'bagging_fraction': 0.7229787377104377}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:18:18,182] Trial 133 finished with value: 1218600000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.0901023519220118, 'min_data_in_leaf': 907, 'feature_fraction': 0.7670863277948652, 'bagging_fraction': 0.6556047749714746}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:18:39,510] Trial 134 finished with value: 1198520000.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.09596773377370714, 'min_data_in_leaf': 784, 'feature_fraction': 0.807748189084692, 'bagging_fraction': 0.7685989340156426}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:19:16,522] Trial 135 finished with value: 1229460000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.09990685055539003, 'min_data_in_leaf': 568, 'feature_fraction': 0.8517220216754993, 'bagging_fraction': 0.6866411111829062}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:20:01,531] Trial 136 finished with value: 1227440000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.09870642628712885, 'min_data_in_leaf': 529, 'feature_fraction': 0.8604332011140073, 'bagging_fraction': 0.6828427241669223}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:20:42,731] Trial 137 finished with value: 1222900000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09893288850469378, 'min_data_in_leaf': 496, 'feature_fraction': 0.8557333500011928, 'bagging_fraction': 0.6773151146308402}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:21:20,828] Trial 138 finished with value: 1226900000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.09729923785869264, 'min_data_in_leaf': 513, 'feature_fraction': 0.8959133034483284, 'bagging_fraction': 0.6873080222079221}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:22:01,596] Trial 139 finished with value: 1224520000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.0945524646699118, 'min_data_in_leaf': 573, 'feature_fraction': 0.8970608704999374, 'bagging_fraction': 0.6421448061582069}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:22:40,036] Trial 140 finished with value: 1222580000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09993435439003935, 'min_data_in_leaf': 486, 'feature_fraction': 0.8429939130893672, 'bagging_fraction': 0.6891858698201002}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:23:18,832] Trial 141 finished with value: 1224700000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09660846079511043, 'min_data_in_leaf': 535, 'feature_fraction': 0.8761977400151324, 'bagging_fraction': 0.6610820200528222}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:24:01,404] Trial 142 finished with value: 1227280000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09679605559670025, 'min_data_in_leaf': 539, 'feature_fraction': 0.8760006219751647, 'bagging_fraction': 0.6607659619808947}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:24:36,885] Trial 143 finished with value: 1229440000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.0942324238283732, 'min_data_in_leaf': 565, 'feature_fraction': 0.9392757890382557, 'bagging_fraction': 0.7088173217478247}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:25:13,435] Trial 144 finished with value: 1229300000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09706966746861483, 'min_data_in_leaf': 431, 'feature_fraction': 0.9376175589649179, 'bagging_fraction': 0.6911589339497601}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:25:57,887] Trial 145 finished with value: 1224560000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09350700355522298, 'min_data_in_leaf': 422, 'feature_fraction': 0.9418057829322428, 'bagging_fraction': 0.6074684065205652}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:26:34,038] Trial 146 finished with value: 1227300000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09719566633655831, 'min_data_in_leaf': 571, 'feature_fraction': 0.9023943861395358, 'bagging_fraction': 0.7082367669430589}. Best is trial 81 with value: 1229580000.0.\n",
      "[I 2025-10-10 21:27:13,544] Trial 147 finished with value: 1232780000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09985497129192984, 'min_data_in_leaf': 562, 'feature_fraction': 0.9078934051671221, 'bagging_fraction': 0.7139706715853614}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:27:50,640] Trial 148 finished with value: 1220600000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.0999658160903535, 'min_data_in_leaf': 557, 'feature_fraction': 0.9838839520443713, 'bagging_fraction': 0.70421168012215}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:28:33,925] Trial 149 finished with value: 1222420000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09579656765812616, 'min_data_in_leaf': 515, 'feature_fraction': 0.9125753356666255, 'bagging_fraction': 0.7315477076558068}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:29:13,120] Trial 150 finished with value: 1227660000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09302556750308075, 'min_data_in_leaf': 603, 'feature_fraction': 0.9467033698502272, 'bagging_fraction': 0.7140118816738706}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:29:53,167] Trial 151 finished with value: 1224280000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.092554043269589, 'min_data_in_leaf': 599, 'feature_fraction': 0.9444859314396159, 'bagging_fraction': 0.6910951193170464}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:30:32,546] Trial 152 finished with value: 1224580000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09845158315053186, 'min_data_in_leaf': 460, 'feature_fraction': 0.927272975585301, 'bagging_fraction': 0.709821004422357}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:31:08,718] Trial 153 finished with value: 1227320000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.08943281598632838, 'min_data_in_leaf': 561, 'feature_fraction': 0.9622910871704412, 'bagging_fraction': 0.6480852707949242}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:31:49,182] Trial 154 finished with value: 1223660000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.08886355246208413, 'min_data_in_leaf': 560, 'feature_fraction': 0.9593825329257321, 'bagging_fraction': 0.6228030396348063}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:32:26,367] Trial 155 finished with value: 1225940000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09394565808177219, 'min_data_in_leaf': 615, 'feature_fraction': 0.9785439616293872, 'bagging_fraction': 0.6551778672231567}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:33:07,685] Trial 156 finished with value: 1226380000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.0957851937448729, 'min_data_in_leaf': 527, 'feature_fraction': 0.9071271789142781, 'bagging_fraction': 0.6663129236565581}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:33:46,785] Trial 157 finished with value: 1225840000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09094561772772827, 'min_data_in_leaf': 582, 'feature_fraction': 0.9337699692575494, 'bagging_fraction': 0.6437833415280922}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:34:22,902] Trial 158 finished with value: 1226680000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.0972364341480845, 'min_data_in_leaf': 510, 'feature_fraction': 0.8750642508910549, 'bagging_fraction': 0.689873052145767}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:35:01,269] Trial 159 finished with value: 1221640000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.06247109757891966, 'min_data_in_leaf': 542, 'feature_fraction': 0.9518213490669355, 'bagging_fraction': 0.7472794697020877}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:35:39,652] Trial 160 finished with value: 1226480000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09297645753540675, 'min_data_in_leaf': 469, 'feature_fraction': 0.9120145877562283, 'bagging_fraction': 0.7134624467585289}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:36:20,969] Trial 161 finished with value: 1224760000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.08719920051997812, 'min_data_in_leaf': 431, 'feature_fraction': 0.8886310196515445, 'bagging_fraction': 0.6875720536308816}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:37:08,193] Trial 162 finished with value: 1221280000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09871841322210058, 'min_data_in_leaf': 641, 'feature_fraction': 0.8638680665670052, 'bagging_fraction': 0.7222406471182193}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:37:44,787] Trial 163 finished with value: 1229620000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.0999574650535564, 'min_data_in_leaf': 566, 'feature_fraction': 0.9858116899005114, 'bagging_fraction': 0.6674447957397013}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:38:25,338] Trial 164 finished with value: 1230420000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09953725416673208, 'min_data_in_leaf': 586, 'feature_fraction': 0.9959184863622096, 'bagging_fraction': 0.6196089663257577}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:39:01,661] Trial 165 finished with value: 1223940000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09954859297436636, 'min_data_in_leaf': 572, 'feature_fraction': 0.9907525558513592, 'bagging_fraction': 0.5964052997512621}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:39:38,914] Trial 166 finished with value: 1224740000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09714445734337909, 'min_data_in_leaf': 623, 'feature_fraction': 0.9607796209335416, 'bagging_fraction': 0.6426928100006012}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:40:16,857] Trial 167 finished with value: 1224640000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.09496346414934916, 'min_data_in_leaf': 593, 'feature_fraction': 0.9986106342935338, 'bagging_fraction': 0.6187819373396031}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:41:00,506] Trial 168 finished with value: 1225680000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09978744768591748, 'min_data_in_leaf': 551, 'feature_fraction': 0.9340468174699139, 'bagging_fraction': 0.5800756400559461}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:41:36,939] Trial 169 finished with value: 1222640000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09695613863744816, 'min_data_in_leaf': 492, 'feature_fraction': 0.9814010651068116, 'bagging_fraction': 0.6696742689087352}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:42:20,130] Trial 170 finished with value: 1224680000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09518498876546032, 'min_data_in_leaf': 661, 'feature_fraction': 0.9672339836846814, 'bagging_fraction': 0.6826411734738991}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:42:59,940] Trial 171 finished with value: 1222220000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.09780600759164963, 'min_data_in_leaf': 530, 'feature_fraction': 0.9261174358792684, 'bagging_fraction': 0.654681158049719}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:43:37,181] Trial 172 finished with value: 1222500000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09366024256445223, 'min_data_in_leaf': 589, 'feature_fraction': 0.9510352759781777, 'bagging_fraction': 0.6990312879140796}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:44:12,691] Trial 173 finished with value: 1221300000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.09811824695100971, 'min_data_in_leaf': 513, 'feature_fraction': 0.975007992489921, 'bagging_fraction': 0.7387525811339963}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:44:52,824] Trial 174 finished with value: 1223660000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.0959497789076862, 'min_data_in_leaf': 398, 'feature_fraction': 0.9108020988890693, 'bagging_fraction': 0.6694822860779928}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:45:35,586] Trial 175 finished with value: 1176480000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.009929025890741086, 'min_data_in_leaf': 555, 'feature_fraction': 0.8506009629215574, 'bagging_fraction': 0.6201285888707542}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:46:20,164] Trial 176 finished with value: 1227060000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09234870858441974, 'min_data_in_leaf': 576, 'feature_fraction': 0.8978615963466083, 'bagging_fraction': 0.7233237701760886}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:46:58,378] Trial 177 finished with value: 1230580000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09999116564264457, 'min_data_in_leaf': 574, 'feature_fraction': 0.8792772957922169, 'bagging_fraction': 0.7190286222510962}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:47:42,709] Trial 178 finished with value: 1226420000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09417982931853447, 'min_data_in_leaf': 610, 'feature_fraction': 0.873260515907308, 'bagging_fraction': 0.724255541125552}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:48:22,527] Trial 179 finished with value: 1225220000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09995988642651653, 'min_data_in_leaf': 572, 'feature_fraction': 0.9382235884791351, 'bagging_fraction': 0.7515824889272544}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:49:04,882] Trial 180 finished with value: 1222220000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09032845124292176, 'min_data_in_leaf': 644, 'feature_fraction': 0.9170053122082167, 'bagging_fraction': 0.7114750548706311}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:49:41,897] Trial 181 finished with value: 1224940000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09274259185867653, 'min_data_in_leaf': 542, 'feature_fraction': 0.8867858371892582, 'bagging_fraction': 0.6435872600843839}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:50:17,260] Trial 182 finished with value: 1226260000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.09557375179629085, 'min_data_in_leaf': 623, 'feature_fraction': 0.9554271852679723, 'bagging_fraction': 0.6959159455697299}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:50:53,323] Trial 183 finished with value: 1220660000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09979994757770265, 'min_data_in_leaf': 584, 'feature_fraction': 0.8587915480487159, 'bagging_fraction': 0.6679351486240985}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:51:33,610] Trial 184 finished with value: 1209000000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.03952076787000657, 'min_data_in_leaf': 463, 'feature_fraction': 0.9271461891791382, 'bagging_fraction': 0.7302338303596535}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:52:15,177] Trial 185 finished with value: 1224580000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09800222512319129, 'min_data_in_leaf': 601, 'feature_fraction': 0.9820077532135878, 'bagging_fraction': 0.7130240222203934}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:52:56,592] Trial 186 finished with value: 1224540000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09648983138670633, 'min_data_in_leaf': 499, 'feature_fraction': 0.8951969250459195, 'bagging_fraction': 0.6840510268445377}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:53:37,193] Trial 187 finished with value: 1229100000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09744212145240055, 'min_data_in_leaf': 529, 'feature_fraction': 0.8780921866207723, 'bagging_fraction': 0.6546497018336246}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:54:18,693] Trial 188 finished with value: 1227220000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.09439181107284272, 'min_data_in_leaf': 560, 'feature_fraction': 0.8419600941056744, 'bagging_fraction': 0.6585323520050874}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:54:57,909] Trial 189 finished with value: 1218060000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.09999508500242911, 'min_data_in_leaf': 536, 'feature_fraction': 0.839592231896386, 'bagging_fraction': 0.6521972999478689}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:55:39,242] Trial 190 finished with value: 1223760000.0 and parameters: {'num_leaves': 69, 'learning_rate': 0.09435031323030757, 'min_data_in_leaf': 554, 'feature_fraction': 0.8156260423203746, 'bagging_fraction': 0.6367589987719461}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:56:17,396] Trial 191 finished with value: 1222560000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09809815525038632, 'min_data_in_leaf': 481, 'feature_fraction': 0.8576427712329749, 'bagging_fraction': 0.6795916996431011}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:56:53,625] Trial 192 finished with value: 1225560000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09484645144200303, 'min_data_in_leaf': 525, 'feature_fraction': 0.876089279222847, 'bagging_fraction': 0.597287504215116}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:57:34,820] Trial 193 finished with value: 1225380000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.09662360565051509, 'min_data_in_leaf': 564, 'feature_fraction': 0.8338870632065642, 'bagging_fraction': 0.6643055113707019}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:58:11,482] Trial 194 finished with value: 1227020000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09800781446286477, 'min_data_in_leaf': 334, 'feature_fraction': 0.9445641224962786, 'bagging_fraction': 0.6329249797010318}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:58:46,924] Trial 195 finished with value: 1225600000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09660185167832744, 'min_data_in_leaf': 624, 'feature_fraction': 0.99791845270484, 'bagging_fraction': 0.706352294619811}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 21:59:28,419] Trial 196 finished with value: 1226360000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09316822266918232, 'min_data_in_leaf': 579, 'feature_fraction': 0.9054100392375272, 'bagging_fraction': 0.7524417996986611}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:00:06,707] Trial 197 finished with value: 1225100000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09222186226836615, 'min_data_in_leaf': 593, 'feature_fraction': 0.8605233002587421, 'bagging_fraction': 0.6949519556001409}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:00:47,064] Trial 198 finished with value: 1224820000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09025013420278247, 'min_data_in_leaf': 665, 'feature_fraction': 0.8796870451603713, 'bagging_fraction': 0.7322018712578354}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:01:26,479] Trial 199 finished with value: 1229520000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09541005492342039, 'min_data_in_leaf': 557, 'feature_fraction': 0.9193913587050405, 'bagging_fraction': 0.6678505617367437}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:02:10,095] Trial 200 finished with value: 1224560000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09559695519988647, 'min_data_in_leaf': 543, 'feature_fraction': 0.9236818224699074, 'bagging_fraction': 0.6572691672538128}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:02:49,306] Trial 201 finished with value: 1228520000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09804870293696966, 'min_data_in_leaf': 505, 'feature_fraction': 0.9537580445097206, 'bagging_fraction': 0.614805017830808}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:03:25,772] Trial 202 finished with value: 1219220000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09994226191541364, 'min_data_in_leaf': 496, 'feature_fraction': 0.9630431716642935, 'bagging_fraction': 0.6285202433737395}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:03:49,863] Trial 203 finished with value: 1209240000.0 and parameters: {'num_leaves': 19, 'learning_rate': 0.09803122492797355, 'min_data_in_leaf': 441, 'feature_fraction': 0.9449628135270594, 'bagging_fraction': 0.6984762119611042}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:04:25,572] Trial 204 finished with value: 1223880000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09834204738430273, 'min_data_in_leaf': 514, 'feature_fraction': 0.9765611595266277, 'bagging_fraction': 0.6179298044939534}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:05:10,875] Trial 205 finished with value: 1222520000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.096474867368039, 'min_data_in_leaf': 470, 'feature_fraction': 0.914156118135594, 'bagging_fraction': 0.6774339196024096}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:05:46,221] Trial 206 finished with value: 1226080000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.09448837240281935, 'min_data_in_leaf': 561, 'feature_fraction': 0.9319792052141789, 'bagging_fraction': 0.6612040118329422}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:06:20,571] Trial 207 finished with value: 1228020000.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.09559814013806976, 'min_data_in_leaf': 537, 'feature_fraction': 0.9641387017678591, 'bagging_fraction': 0.6497030753439377}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:06:58,221] Trial 208 finished with value: 1223260000.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.09819174336420852, 'min_data_in_leaf': 531, 'feature_fraction': 0.9694938746517305, 'bagging_fraction': 0.6417764652971282}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:07:34,720] Trial 209 finished with value: 1226380000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09619978272499166, 'min_data_in_leaf': 602, 'feature_fraction': 0.9584079581856977, 'bagging_fraction': 0.5575203400563556}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:08:19,596] Trial 210 finished with value: 1226060000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.09803386650573685, 'min_data_in_leaf': 523, 'feature_fraction': 0.9457961443328464, 'bagging_fraction': 0.6095327332038623}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:08:53,736] Trial 211 finished with value: 1198840000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.029210639377441408, 'min_data_in_leaf': 494, 'feature_fraction': 0.9057650270657873, 'bagging_fraction': 0.6789468494531249}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:09:32,951] Trial 212 finished with value: 1226100000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.09607807766354247, 'min_data_in_leaf': 540, 'feature_fraction': 0.9971406699047498, 'bagging_fraction': 0.5921706370530705}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:10:09,401] Trial 213 finished with value: 1230040000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09980400647157504, 'min_data_in_leaf': 581, 'feature_fraction': 0.9241721144821157, 'bagging_fraction': 0.7109875094158116}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:10:46,183] Trial 214 finished with value: 1225980000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09963789369016351, 'min_data_in_leaf': 619, 'feature_fraction': 0.9227676342745434, 'bagging_fraction': 0.7121084175638206}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:11:21,149] Trial 215 finished with value: 1225800000.0 and parameters: {'num_leaves': 68, 'learning_rate': 0.09979027717419635, 'min_data_in_leaf': 597, 'feature_fraction': 0.9740855029471119, 'bagging_fraction': 0.6996805572072826}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:12:00,132] Trial 216 finished with value: 1226260000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.0969744246702654, 'min_data_in_leaf': 570, 'feature_fraction': 0.8815963187920893, 'bagging_fraction': 0.675527891207112}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:12:38,098] Trial 217 finished with value: 1224820000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.0951511632172529, 'min_data_in_leaf': 551, 'feature_fraction': 0.9434674993944767, 'bagging_fraction': 0.7384831218204995}. Best is trial 147 with value: 1232780000.0.\n",
      "[I 2025-10-10 22:13:16,918] Trial 218 finished with value: 1235980000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.0982712435048071, 'min_data_in_leaf': 573, 'feature_fraction': 0.8936142331074993, 'bagging_fraction': 0.6498337910529549}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:13:49,452] Trial 219 finished with value: 1227960000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09840248656687403, 'min_data_in_leaf': 585, 'feature_fraction': 0.9119210288025238, 'bagging_fraction': 0.6903523627050202}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:14:23,483] Trial 220 finished with value: 1226040000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09843267857008572, 'min_data_in_leaf': 633, 'feature_fraction': 0.9323903610909211, 'bagging_fraction': 0.6386050716238738}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:14:58,405] Trial 221 finished with value: 1222460000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.06701900773310152, 'min_data_in_leaf': 591, 'feature_fraction': 0.9602230054630801, 'bagging_fraction': 0.6910498987802539}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:15:31,931] Trial 222 finished with value: 1227740000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09986610332566073, 'min_data_in_leaf': 511, 'feature_fraction': 0.9151958710106797, 'bagging_fraction': 0.6752273508007952}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:16:05,667] Trial 223 finished with value: 1233340000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09986983638112301, 'min_data_in_leaf': 515, 'feature_fraction': 0.9149379423088048, 'bagging_fraction': 0.7192103721578544}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:16:39,934] Trial 224 finished with value: 1228220000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.0996618052563106, 'min_data_in_leaf': 395, 'feature_fraction': 0.9113908686632354, 'bagging_fraction': 0.7545753845519878}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:17:10,943] Trial 225 finished with value: 1229000000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09950821517283087, 'min_data_in_leaf': 385, 'feature_fraction': 0.9152039532599469, 'bagging_fraction': 0.7569955556362126}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:17:44,954] Trial 226 finished with value: 1228080000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09975932117728809, 'min_data_in_leaf': 370, 'feature_fraction': 0.919510989786378, 'bagging_fraction': 0.7255757829551784}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:18:17,880] Trial 227 finished with value: 1225620000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09991381166038144, 'min_data_in_leaf': 385, 'feature_fraction': 0.9032587075547192, 'bagging_fraction': 0.7597188464399995}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:18:54,297] Trial 228 finished with value: 1230380000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09997797265379865, 'min_data_in_leaf': 410, 'feature_fraction': 0.9199182229860332, 'bagging_fraction': 0.7450349525569301}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:19:26,102] Trial 229 finished with value: 1228000000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09985641544971859, 'min_data_in_leaf': 367, 'feature_fraction': 0.9189801292366783, 'bagging_fraction': 0.745976407024704}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:19:57,477] Trial 230 finished with value: 1226100000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09996031579284122, 'min_data_in_leaf': 357, 'feature_fraction': 0.9209739765585243, 'bagging_fraction': 0.7503365712730155}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:20:31,339] Trial 231 finished with value: 1223040000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09881365686765804, 'min_data_in_leaf': 416, 'feature_fraction': 0.8930328761548849, 'bagging_fraction': 0.7348119793359219}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:21:04,794] Trial 232 finished with value: 1219220000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09745776746689103, 'min_data_in_leaf': 394, 'feature_fraction': 0.9310095924761951, 'bagging_fraction': 0.7562165286570217}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:21:39,262] Trial 233 finished with value: 1229760000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09825296411429336, 'min_data_in_leaf': 367, 'feature_fraction': 0.9173665770996206, 'bagging_fraction': 0.7274490563920891}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:22:13,333] Trial 234 finished with value: 1224640000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09782236007181629, 'min_data_in_leaf': 318, 'feature_fraction': 0.9280804302214223, 'bagging_fraction': 0.7270985753053707}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:22:44,536] Trial 235 finished with value: 1223060000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09639589453199067, 'min_data_in_leaf': 365, 'feature_fraction': 0.8925517561434881, 'bagging_fraction': 0.7445550329437519}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:23:24,486] Trial 236 finished with value: 1224100000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09994824218060445, 'min_data_in_leaf': 379, 'feature_fraction': 0.9109677343914907, 'bagging_fraction': 0.7231295191073314}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:23:57,437] Trial 237 finished with value: 1230860000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.0983887903210899, 'min_data_in_leaf': 329, 'feature_fraction': 0.9163834316767625, 'bagging_fraction': 0.7379158204688286}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:24:28,013] Trial 238 finished with value: 1224920000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09996144544431354, 'min_data_in_leaf': 341, 'feature_fraction': 0.9401920809018252, 'bagging_fraction': 0.757402458492621}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:24:59,752] Trial 239 finished with value: 1228940000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09772707386181505, 'min_data_in_leaf': 411, 'feature_fraction': 0.9205912977450645, 'bagging_fraction': 0.7173875993768222}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:25:32,487] Trial 240 finished with value: 1230080000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.0971581761793277, 'min_data_in_leaf': 410, 'feature_fraction': 0.8913156301654461, 'bagging_fraction': 0.7716574974874901}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:26:07,475] Trial 241 finished with value: 1224020000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09710681637073298, 'min_data_in_leaf': 419, 'feature_fraction': 0.8919887356817174, 'bagging_fraction': 0.7682842548733708}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:26:39,535] Trial 242 finished with value: 1227180000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09813941999691193, 'min_data_in_leaf': 306, 'feature_fraction': 0.8813751564012612, 'bagging_fraction': 0.7230843468767911}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:27:10,813] Trial 243 finished with value: 1229060000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09742113697442147, 'min_data_in_leaf': 413, 'feature_fraction': 0.9023738289499215, 'bagging_fraction': 0.7324492034584785}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:27:44,663] Trial 244 finished with value: 1229360000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09647087828681686, 'min_data_in_leaf': 439, 'feature_fraction': 0.8990828666318766, 'bagging_fraction': 0.7085683324170655}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:28:19,537] Trial 245 finished with value: 1225380000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09487796088415326, 'min_data_in_leaf': 416, 'feature_fraction': 0.8935414525894212, 'bagging_fraction': 0.708966996247311}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:28:50,340] Trial 246 finished with value: 1224580000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09685059304503285, 'min_data_in_leaf': 398, 'feature_fraction': 0.9073078070718511, 'bagging_fraction': 0.7397373017615554}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:29:27,886] Trial 247 finished with value: 1231680000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09756865975313739, 'min_data_in_leaf': 434, 'feature_fraction': 0.8779487571582851, 'bagging_fraction': 0.765751807792326}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:29:59,383] Trial 248 finished with value: 1227300000.0 and parameters: {'num_leaves': 42, 'learning_rate': 0.09676430574772334, 'min_data_in_leaf': 450, 'feature_fraction': 0.8750319046956287, 'bagging_fraction': 0.781973821466841}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:30:37,273] Trial 249 finished with value: 1224600000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.0946226841414726, 'min_data_in_leaf': 427, 'feature_fraction': 0.889816515466205, 'bagging_fraction': 0.768998212649232}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:31:06,978] Trial 250 finished with value: 1213340000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.050846875192251846, 'min_data_in_leaf': 446, 'feature_fraction': 0.9382368765578574, 'bagging_fraction': 0.7030673537805224}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:31:40,387] Trial 251 finished with value: 1227480000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09751669007704693, 'min_data_in_leaf': 448, 'feature_fraction': 0.8700171810288722, 'bagging_fraction': 0.7991966902931616}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:32:12,003] Trial 252 finished with value: 1224760000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.0960136288777846, 'min_data_in_leaf': 397, 'feature_fraction': 0.9031366358056708, 'bagging_fraction': 0.7199770064632899}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:32:45,888] Trial 253 finished with value: 1225940000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09798916049544144, 'min_data_in_leaf': 437, 'feature_fraction': 0.9232698803045991, 'bagging_fraction': 0.7403017413122713}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:33:20,303] Trial 254 finished with value: 1222220000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09401118653983298, 'min_data_in_leaf': 472, 'feature_fraction': 0.8846769601710008, 'bagging_fraction': 0.7017551795805981}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:33:50,203] Trial 255 finished with value: 1223000000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.09799274927657917, 'min_data_in_leaf': 342, 'feature_fraction': 0.9462726392058279, 'bagging_fraction': 0.7185625202038735}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:34:28,011] Trial 256 finished with value: 1221440000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09833852240520925, 'min_data_in_leaf': 402, 'feature_fraction': 0.906957288677551, 'bagging_fraction': 0.7657296574130458}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:35:02,277] Trial 257 finished with value: 1225480000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09802056232245658, 'min_data_in_leaf': 418, 'feature_fraction': 0.9003844019678129, 'bagging_fraction': 0.7451803885303941}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:35:32,917] Trial 258 finished with value: 1228360000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09587778550420208, 'min_data_in_leaf': 378, 'feature_fraction': 0.9298761480327008, 'bagging_fraction': 0.7334278191902251}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:36:05,901] Trial 259 finished with value: 1223100000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.0960684922862998, 'min_data_in_leaf': 372, 'feature_fraction': 0.9338593194812816, 'bagging_fraction': 0.7343600122937399}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:36:36,156] Trial 260 finished with value: 1225300000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09541050035346613, 'min_data_in_leaf': 330, 'feature_fraction': 0.9301768107355205, 'bagging_fraction': 0.6956948856142277}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:37:10,251] Trial 261 finished with value: 1229700000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09647825297246504, 'min_data_in_leaf': 350, 'feature_fraction': 0.9502756712506314, 'bagging_fraction': 0.7153084616368949}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:37:42,113] Trial 262 finished with value: 1221020000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09795477713396303, 'min_data_in_leaf': 354, 'feature_fraction': 0.949283599040406, 'bagging_fraction': 0.7127594527063483}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:38:16,895] Trial 263 finished with value: 1223720000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09372216107059683, 'min_data_in_leaf': 300, 'feature_fraction': 0.8703286603070708, 'bagging_fraction': 0.6887323766811826}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:38:50,944] Trial 264 finished with value: 1234600000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.0968796000484245, 'min_data_in_leaf': 429, 'feature_fraction': 0.9830913675072411, 'bagging_fraction': 0.7121829397806372}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:39:22,427] Trial 265 finished with value: 1224720000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09645929685279962, 'min_data_in_leaf': 430, 'feature_fraction': 0.9863174517898401, 'bagging_fraction': 0.7109408451238358}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:39:54,176] Trial 266 finished with value: 1228040000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.0999929859482897, 'min_data_in_leaf': 426, 'feature_fraction': 0.9823550187022584, 'bagging_fraction': 0.7198683280988571}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:40:24,882] Trial 267 finished with value: 1194680000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.022165859454286802, 'min_data_in_leaf': 406, 'feature_fraction': 0.8923586620172593, 'bagging_fraction': 0.6926105875149862}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:41:03,882] Trial 268 finished with value: 1225600000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.0942358337165057, 'min_data_in_leaf': 336, 'feature_fraction': 0.9169010337453897, 'bagging_fraction': 0.6737841585433559}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:41:35,557] Trial 269 finished with value: 1227980000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.0965436814308619, 'min_data_in_leaf': 477, 'feature_fraction': 0.9693792241177575, 'bagging_fraction': 0.7344800364635427}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:42:11,430] Trial 270 finished with value: 1225700000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09865738491807577, 'min_data_in_leaf': 460, 'feature_fraction': 0.9995809575762773, 'bagging_fraction': 0.7656812251157261}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:42:47,062] Trial 271 finished with value: 1222380000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09999995863855829, 'min_data_in_leaf': 382, 'feature_fraction': 0.8658688383108906, 'bagging_fraction': 0.7042284143881326}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:43:19,357] Trial 272 finished with value: 1224060000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.0947084512006085, 'min_data_in_leaf': 353, 'feature_fraction': 0.8849174164713515, 'bagging_fraction': 0.6852188320928331}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:43:50,229] Trial 273 finished with value: 1223020000.0 and parameters: {'num_leaves': 39, 'learning_rate': 0.09705707243560895, 'min_data_in_leaf': 408, 'feature_fraction': 0.9077290739652879, 'bagging_fraction': 0.7194901248079373}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:44:22,370] Trial 274 finished with value: 1225500000.0 and parameters: {'num_leaves': 43, 'learning_rate': 0.09286174715444791, 'min_data_in_leaf': 446, 'feature_fraction': 0.9495192895053735, 'bagging_fraction': 0.7464428347202904}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:44:57,024] Trial 275 finished with value: 1225080000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09829851550566349, 'min_data_in_leaf': 387, 'feature_fraction': 0.9250298858658859, 'bagging_fraction': 0.6656007132833708}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:45:30,228] Trial 276 finished with value: 1227280000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09604609821973373, 'min_data_in_leaf': 432, 'feature_fraction': 0.898475415488845, 'bagging_fraction': 0.7882456995658256}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:46:02,315] Trial 277 finished with value: 1228980000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09798679386428696, 'min_data_in_leaf': 410, 'feature_fraction': 0.963459500871932, 'bagging_fraction': 0.7010290752490702}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:46:37,480] Trial 278 finished with value: 1230540000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09511973332201344, 'min_data_in_leaf': 353, 'feature_fraction': 0.9712360517353775, 'bagging_fraction': 0.6965067381932839}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:47:05,279] Trial 279 finished with value: 1204900000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09221631921274656, 'min_data_in_leaf': 317, 'feature_fraction': 0.18979794266987715, 'bagging_fraction': 0.6751878010756555}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:47:43,328] Trial 280 finished with value: 1218640000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.0951934237196878, 'min_data_in_leaf': 354, 'feature_fraction': 0.9818708970160568, 'bagging_fraction': 0.6935277471006186}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:48:15,344] Trial 281 finished with value: 1230680000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09381370218476077, 'min_data_in_leaf': 369, 'feature_fraction': 0.9570587756922662, 'bagging_fraction': 0.7293650169184319}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:48:51,059] Trial 282 finished with value: 1225480000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.09348647604518878, 'min_data_in_leaf': 374, 'feature_fraction': 0.9723445693778332, 'bagging_fraction': 0.7310360013998116}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:49:22,320] Trial 283 finished with value: 1220860000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09183897890850357, 'min_data_in_leaf': 327, 'feature_fraction': 0.9540949370640057, 'bagging_fraction': 0.6820564954454248}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:49:54,524] Trial 284 finished with value: 1226640000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.094481459436065, 'min_data_in_leaf': 343, 'feature_fraction': 0.9806775080236636, 'bagging_fraction': 0.7044975727354748}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:50:26,571] Trial 285 finished with value: 1229240000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09595953607995912, 'min_data_in_leaf': 567, 'feature_fraction': 0.942064734133667, 'bagging_fraction': 0.7287049391479126}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:51:03,000] Trial 286 finished with value: 1225820000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.0951521177659581, 'min_data_in_leaf': 576, 'feature_fraction': 0.9539390054392494, 'bagging_fraction': 0.7154824846120013}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:51:38,037] Trial 287 finished with value: 1220100000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09349830394834961, 'min_data_in_leaf': 555, 'feature_fraction': 0.9707331613758, 'bagging_fraction': 0.6695836719076071}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:52:09,792] Trial 288 finished with value: 1226800000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.07289496911812174, 'min_data_in_leaf': 608, 'feature_fraction': 0.9987838550144739, 'bagging_fraction': 0.7053593487057209}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:52:42,505] Trial 289 finished with value: 1232560000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09594455578794407, 'min_data_in_leaf': 555, 'feature_fraction': 0.9424001746356128, 'bagging_fraction': 0.6560836512765315}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:53:15,834] Trial 290 finished with value: 1227640000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09193518725156971, 'min_data_in_leaf': 580, 'feature_fraction': 0.940467072193359, 'bagging_fraction': 0.15881606743173593}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:53:51,236] Trial 291 finished with value: 1225460000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09585967442287285, 'min_data_in_leaf': 551, 'feature_fraction': 0.942407319696951, 'bagging_fraction': 0.6882027729844744}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:54:23,132] Trial 292 finished with value: 1229020000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09562641885106678, 'min_data_in_leaf': 571, 'feature_fraction': 0.9587438439852731, 'bagging_fraction': 0.7453118937562125}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:54:57,863] Trial 293 finished with value: 1212520000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.0930801888953389, 'min_data_in_leaf': 616, 'feature_fraction': 0.274973130881852, 'bagging_fraction': 0.7262480826160451}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:55:29,245] Trial 294 finished with value: 1227420000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.096449894276549, 'min_data_in_leaf': 484, 'feature_fraction': 0.9364660590199175, 'bagging_fraction': 0.6637201749625268}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:56:02,130] Trial 295 finished with value: 1224380000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09990286814724751, 'min_data_in_leaf': 595, 'feature_fraction': 0.9783088756638748, 'bagging_fraction': 0.6935864828390762}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:56:36,631] Trial 296 finished with value: 1227280000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09444727563543481, 'min_data_in_leaf': 365, 'feature_fraction': 0.958635353519742, 'bagging_fraction': 0.7116103570720068}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:57:07,493] Trial 297 finished with value: 1226600000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.09793304440185152, 'min_data_in_leaf': 647, 'feature_fraction': 0.9379208359543952, 'bagging_fraction': 0.7719068633992217}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:57:47,928] Trial 298 finished with value: 1221540000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09652806909499545, 'min_data_in_leaf': 519, 'feature_fraction': 0.6320703693261499, 'bagging_fraction': 0.7491331772957901}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:58:20,107] Trial 299 finished with value: 1223900000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.0908199902488605, 'min_data_in_leaf': 563, 'feature_fraction': 0.9852824065508776, 'bagging_fraction': 0.3235126964054863}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:58:54,456] Trial 300 finished with value: 1227000000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09988309439414897, 'min_data_in_leaf': 988, 'feature_fraction': 0.9274355957903738, 'bagging_fraction': 0.7264942582249087}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 22:59:29,956] Trial 301 finished with value: 1221080000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09820924080594907, 'min_data_in_leaf': 321, 'feature_fraction': 0.9585316053941082, 'bagging_fraction': 0.6913768179840257}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:00:00,461] Trial 302 finished with value: 1222120000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.0940547917211994, 'min_data_in_leaf': 548, 'feature_fraction': 0.9420319729177518, 'bagging_fraction': 0.6784765013602652}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:00:30,252] Trial 303 finished with value: 1208640000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.03690452392303075, 'min_data_in_leaf': 349, 'feature_fraction': 0.9993749511151644, 'bagging_fraction': 0.6476973289372273}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:01:12,733] Trial 304 finished with value: 1227880000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09642193701856376, 'min_data_in_leaf': 461, 'feature_fraction': 0.9156945367711258, 'bagging_fraction': 0.7100187245193492}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:01:50,088] Trial 305 finished with value: 1225400000.0 and parameters: {'num_leaves': 60, 'learning_rate': 0.09777785644319399, 'min_data_in_leaf': 586, 'feature_fraction': 0.974760366567078, 'bagging_fraction': 0.7410095700333943}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:02:23,885] Trial 306 finished with value: 1222180000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09998019241485284, 'min_data_in_leaf': 615, 'feature_fraction': 0.9297304623377103, 'bagging_fraction': 0.7589703219882593}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:02:57,497] Trial 307 finished with value: 1228820000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09542087330468078, 'min_data_in_leaf': 373, 'feature_fraction': 0.9549399364131749, 'bagging_fraction': 0.6668379251537895}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:03:30,246] Trial 308 finished with value: 1228320000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.09824074566138741, 'min_data_in_leaf': 534, 'feature_fraction': 0.8890593317346609, 'bagging_fraction': 0.7329622079376695}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:04:04,723] Trial 309 finished with value: 1225680000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09415360974617486, 'min_data_in_leaf': 500, 'feature_fraction': 0.9236231453730741, 'bagging_fraction': 0.7018535032035952}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:04:41,243] Trial 310 finished with value: 1227240000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.0964719145276122, 'min_data_in_leaf': 559, 'feature_fraction': 0.8506151436747312, 'bagging_fraction': 0.7191753607883564}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:05:17,125] Trial 311 finished with value: 1223080000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.09215720397029681, 'min_data_in_leaf': 443, 'feature_fraction': 0.9067432040257601, 'bagging_fraction': 0.6837911395020688}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:05:54,707] Trial 312 finished with value: 1230560000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09832684634493116, 'min_data_in_leaf': 392, 'feature_fraction': 0.9685484297282692, 'bagging_fraction': 0.6556948756283836}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:06:35,803] Trial 313 finished with value: 1233760000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09803706369204643, 'min_data_in_leaf': 380, 'feature_fraction': 0.9790034773746836, 'bagging_fraction': 0.637771911334558}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:07:17,020] Trial 314 finished with value: 1224560000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09987032854044274, 'min_data_in_leaf': 394, 'feature_fraction': 0.9791976275635, 'bagging_fraction': 0.6293906031014165}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:07:54,102] Trial 315 finished with value: 1229560000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09864181235169506, 'min_data_in_leaf': 355, 'feature_fraction': 0.9663903519982125, 'bagging_fraction': 0.6393538934171468}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:08:40,084] Trial 316 finished with value: 1229220000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.09851227217839076, 'min_data_in_leaf': 351, 'feature_fraction': 0.9834044401119694, 'bagging_fraction': 0.6329374783920669}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:09:20,849] Trial 317 finished with value: 1229860000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09817354204202443, 'min_data_in_leaf': 368, 'feature_fraction': 0.9723559132963917, 'bagging_fraction': 0.6511257030384168}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:09:59,414] Trial 318 finished with value: 1223320000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09848017579755891, 'min_data_in_leaf': 326, 'feature_fraction': 0.9629157808876483, 'bagging_fraction': 0.6038447864666691}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:10:37,163] Trial 319 finished with value: 1219200000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.061855643853043596, 'min_data_in_leaf': 305, 'feature_fraction': 0.9962634450975035, 'bagging_fraction': 0.6256695355305318}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:11:18,428] Trial 320 finished with value: 1222940000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09839004184601745, 'min_data_in_leaf': 360, 'feature_fraction': 0.9715042120211128, 'bagging_fraction': 0.6490159266083371}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:11:59,660] Trial 321 finished with value: 1226820000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.09845001874920375, 'min_data_in_leaf': 382, 'feature_fraction': 0.9677390793565723, 'bagging_fraction': 0.6547873904148556}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:12:36,958] Trial 322 finished with value: 1230160000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09993238259889343, 'min_data_in_leaf': 339, 'feature_fraction': 0.9844488583932716, 'bagging_fraction': 0.6423621021287216}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:13:27,373] Trial 323 finished with value: 1227080000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09968241536114256, 'min_data_in_leaf': 334, 'feature_fraction': 0.9853709465446177, 'bagging_fraction': 0.61589921964258}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:14:06,206] Trial 324 finished with value: 1222940000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.09972118466253767, 'min_data_in_leaf': 361, 'feature_fraction': 0.9981374587066211, 'bagging_fraction': 0.5818989188611999}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:14:45,820] Trial 325 finished with value: 1216460000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.04563438899870608, 'min_data_in_leaf': 336, 'feature_fraction': 0.9712102048681306, 'bagging_fraction': 0.6309810828703933}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:15:25,818] Trial 326 finished with value: 1226960000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09738167430768056, 'min_data_in_leaf': 303, 'feature_fraction': 0.9842926217958895, 'bagging_fraction': 0.6576620949840116}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:16:07,117] Trial 327 finished with value: 1223220000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.09991099667215737, 'min_data_in_leaf': 388, 'feature_fraction': 0.9571409044080091, 'bagging_fraction': 0.6354251328436739}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:16:44,532] Trial 328 finished with value: 1227460000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09720917643075037, 'min_data_in_leaf': 363, 'feature_fraction': 0.9994125491210396, 'bagging_fraction': 0.6411920336519049}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:17:25,373] Trial 329 finished with value: 1223260000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09818508392452349, 'min_data_in_leaf': 345, 'feature_fraction': 0.9671445922361342, 'bagging_fraction': 0.6094115277527371}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:18:05,895] Trial 330 finished with value: 1226200000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09987615240796452, 'min_data_in_leaf': 394, 'feature_fraction': 0.9807558841663432, 'bagging_fraction': 0.6538536727965044}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:18:45,827] Trial 331 finished with value: 1235600000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09560803781650466, 'min_data_in_leaf': 319, 'feature_fraction': 0.9591191149030267, 'bagging_fraction': 0.6667689376055689}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:19:22,326] Trial 332 finished with value: 1225760000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09556364896714593, 'min_data_in_leaf': 322, 'feature_fraction': 0.9598946166046325, 'bagging_fraction': 0.6434749807618244}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:19:59,241] Trial 333 finished with value: 1222100000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09474790635514839, 'min_data_in_leaf': 329, 'feature_fraction': 0.9508299666289982, 'bagging_fraction': 0.6656795526370305}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:20:27,802] Trial 334 finished with value: 1217200000.0 and parameters: {'num_leaves': 30, 'learning_rate': 0.07760334413179729, 'min_data_in_leaf': 352, 'feature_fraction': 0.9843091396878093, 'bagging_fraction': 0.6239180325707905}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:21:09,704] Trial 335 finished with value: 1230800000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09724231702667228, 'min_data_in_leaf': 374, 'feature_fraction': 0.9524267361108142, 'bagging_fraction': 0.6489363227623922}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:21:51,370] Trial 336 finished with value: 1227500000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.09691889811057267, 'min_data_in_leaf': 376, 'feature_fraction': 0.9677902343372798, 'bagging_fraction': 0.6001059829240066}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:22:33,374] Trial 337 finished with value: 1228680000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09768864513586965, 'min_data_in_leaf': 300, 'feature_fraction': 0.9534718786723146, 'bagging_fraction': 0.6484288907236435}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:23:21,816] Trial 338 finished with value: 1222780000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.09649230054017094, 'min_data_in_leaf': 369, 'feature_fraction': 0.982887912687775, 'bagging_fraction': 0.6246415136679307}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:23:58,481] Trial 339 finished with value: 1222760000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09344374500750158, 'min_data_in_leaf': 340, 'feature_fraction': 0.9492749451925204, 'bagging_fraction': 0.7964186316664538}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:24:39,729] Trial 340 finished with value: 1226620000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09826274729819408, 'min_data_in_leaf': 405, 'feature_fraction': 0.9732123915556993, 'bagging_fraction': 0.6683850665305944}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:25:21,611] Trial 341 finished with value: 1217760000.0 and parameters: {'num_leaves': 98, 'learning_rate': 0.056273595193229636, 'min_data_in_leaf': 383, 'feature_fraction': 0.6779474221461101, 'bagging_fraction': 0.6435677564677207}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:26:02,225] Trial 342 finished with value: 1224880000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09615987863579023, 'min_data_in_leaf': 350, 'feature_fraction': 0.9448131888372557, 'bagging_fraction': 0.7820060399102359}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:26:42,391] Trial 343 finished with value: 1227620000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09803093267200982, 'min_data_in_leaf': 324, 'feature_fraction': 0.9954988439387255, 'bagging_fraction': 0.664889770744822}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:27:20,589] Trial 344 finished with value: 1229480000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09436298403269097, 'min_data_in_leaf': 367, 'feature_fraction': 0.9644134701284975, 'bagging_fraction': 0.6151692309005572}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:27:57,221] Trial 345 finished with value: 1225280000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09862833286974335, 'min_data_in_leaf': 406, 'feature_fraction': 0.9378659098125965, 'bagging_fraction': 0.6418776602798251}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:28:37,793] Trial 346 finished with value: 1230980000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09997603791183081, 'min_data_in_leaf': 391, 'feature_fraction': 0.9675764671281629, 'bagging_fraction': 0.6766830343077146}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:29:24,652] Trial 347 finished with value: 1229680000.0 and parameters: {'num_leaves': 94, 'learning_rate': 0.09630979640182444, 'min_data_in_leaf': 393, 'feature_fraction': 0.9859298810315626, 'bagging_fraction': 0.675752331521329}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:30:11,966] Trial 348 finished with value: 1225620000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.09973093344053982, 'min_data_in_leaf': 414, 'feature_fraction': 0.9974874238573247, 'bagging_fraction': 0.6760388113994851}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:30:55,148] Trial 349 finished with value: 1226520000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.09652667782700364, 'min_data_in_leaf': 393, 'feature_fraction': 0.9751191013320142, 'bagging_fraction': 0.6761696805267292}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:31:31,996] Trial 350 finished with value: 1230360000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09454019650653361, 'min_data_in_leaf': 379, 'feature_fraction': 0.9987488282588507, 'bagging_fraction': 0.7569203928646349}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:32:11,044] Trial 351 finished with value: 1230980000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09302332942122517, 'min_data_in_leaf': 375, 'feature_fraction': 0.9980448290108213, 'bagging_fraction': 0.810055986317211}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:32:53,109] Trial 352 finished with value: 1224000000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.08960236871312395, 'min_data_in_leaf': 377, 'feature_fraction': 0.9965046523090333, 'bagging_fraction': 0.7942070743105051}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:33:31,375] Trial 353 finished with value: 1226280000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.09123374491103937, 'min_data_in_leaf': 325, 'feature_fraction': 0.9609295170280111, 'bagging_fraction': 0.8176285605233509}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:34:05,540] Trial 354 finished with value: 1166940000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.005111590213485923, 'min_data_in_leaf': 428, 'feature_fraction': 0.9975316720959383, 'bagging_fraction': 0.7590788500431057}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:34:50,838] Trial 355 finished with value: 1223020000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09305515300930849, 'min_data_in_leaf': 368, 'feature_fraction': 0.9780979450964202, 'bagging_fraction': 0.812490225295438}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:35:30,590] Trial 356 finished with value: 1222040000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09237645058224381, 'min_data_in_leaf': 414, 'feature_fraction': 0.9515664102779094, 'bagging_fraction': 0.771250596368147}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:36:09,321] Trial 357 finished with value: 1224060000.0 and parameters: {'num_leaves': 96, 'learning_rate': 0.0945710955819094, 'min_data_in_leaf': 348, 'feature_fraction': 0.9695631978362944, 'bagging_fraction': 0.7798365032179733}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:36:45,550] Trial 358 finished with value: 1230260000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09488718824053968, 'min_data_in_leaf': 378, 'feature_fraction': 0.9991725871069064, 'bagging_fraction': 0.7491997282556053}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:37:21,648] Trial 359 finished with value: 1228080000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09319935026142868, 'min_data_in_leaf': 397, 'feature_fraction': 0.9976098096479389, 'bagging_fraction': 0.8355543760308263}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:38:03,596] Trial 360 finished with value: 1222160000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.09098011433242409, 'min_data_in_leaf': 384, 'feature_fraction': 0.9827039372169081, 'bagging_fraction': 0.7641893953847094}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:38:40,445] Trial 361 finished with value: 1225380000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09433412240270715, 'min_data_in_leaf': 425, 'feature_fraction': 0.9992305035415545, 'bagging_fraction': 0.7886623006276156}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:39:27,925] Trial 362 finished with value: 1224840000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.0950923317711152, 'min_data_in_leaf': 361, 'feature_fraction': 0.5365446689136324, 'bagging_fraction': 0.7736696393908628}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:40:08,223] Trial 363 finished with value: 1226980000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.0976123174745644, 'min_data_in_leaf': 382, 'feature_fraction': 0.9759649117447016, 'bagging_fraction': 0.7547086824285837}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:40:45,856] Trial 364 finished with value: 1230300000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09536784461918811, 'min_data_in_leaf': 321, 'feature_fraction': 0.9999930032687216, 'bagging_fraction': 0.7455301505296335}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:41:24,171] Trial 365 finished with value: 1227400000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09289694994887167, 'min_data_in_leaf': 310, 'feature_fraction': 0.9835353513076711, 'bagging_fraction': 0.8078480325828991}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:42:02,270] Trial 366 finished with value: 1190700000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.01591793351010634, 'min_data_in_leaf': 300, 'feature_fraction': 0.9969851277279416, 'bagging_fraction': 0.7545817199626679}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:42:38,951] Trial 367 finished with value: 1231120000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.08819456115321259, 'min_data_in_leaf': 343, 'feature_fraction': 0.976050793828162, 'bagging_fraction': 0.7526608466015148}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:43:18,099] Trial 368 finished with value: 1227180000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09005760234201063, 'min_data_in_leaf': 329, 'feature_fraction': 0.9975638580940817, 'bagging_fraction': 0.7506559857524844}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:44:01,431] Trial 369 finished with value: 1227960000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09222287175547356, 'min_data_in_leaf': 335, 'feature_fraction': 0.9642964725583172, 'bagging_fraction': 0.77702694073455}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:44:37,546] Trial 370 finished with value: 1223640000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.08759031032366213, 'min_data_in_leaf': 326, 'feature_fraction': 0.9820721686198157, 'bagging_fraction': 0.7949267648742585}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:45:13,478] Trial 371 finished with value: 1220180000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09477515657833586, 'min_data_in_leaf': 402, 'feature_fraction': 0.32596813320577034, 'bagging_fraction': 0.7389549450008763}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:45:50,010] Trial 372 finished with value: 1225420000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.0913982742796891, 'min_data_in_leaf': 458, 'feature_fraction': 0.9601281992923117, 'bagging_fraction': 0.7435785688251002}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:46:27,256] Trial 373 finished with value: 1230280000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09526768444786816, 'min_data_in_leaf': 345, 'feature_fraction': 0.9832230199273372, 'bagging_fraction': 0.7657181894187489}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:47:08,290] Trial 374 finished with value: 1228460000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.08517548585508615, 'min_data_in_leaf': 347, 'feature_fraction': 0.9982325787719357, 'bagging_fraction': 0.7644197300287162}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:47:45,905] Trial 375 finished with value: 1224160000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.09355132496399989, 'min_data_in_leaf': 315, 'feature_fraction': 0.9790431880574424, 'bagging_fraction': 0.847399980026002}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:48:23,235] Trial 376 finished with value: 1227660000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09082586282083972, 'min_data_in_leaf': 345, 'feature_fraction': 0.9993098834057313, 'bagging_fraction': 0.7839059280553909}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:49:03,551] Trial 377 finished with value: 1222960000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09485901631778326, 'min_data_in_leaf': 424, 'feature_fraction': 0.9762631226714639, 'bagging_fraction': 0.8040573850118158}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:49:39,697] Trial 378 finished with value: 1217880000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.06433812094118048, 'min_data_in_leaf': 379, 'feature_fraction': 0.9544806010168828, 'bagging_fraction': 0.7686107106692235}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:50:21,765] Trial 379 finished with value: 1223320000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09549414378995282, 'min_data_in_leaf': 326, 'feature_fraction': 0.583774289751332, 'bagging_fraction': 0.7502931646374524}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:50:54,463] Trial 380 finished with value: 1223980000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09275841958902405, 'min_data_in_leaf': 1471, 'feature_fraction': 0.9818965907960263, 'bagging_fraction': 0.7726066375893047}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:51:24,422] Trial 381 finished with value: 1220840000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.08904212216638187, 'min_data_in_leaf': 402, 'feature_fraction': 0.9651937459548631, 'bagging_fraction': 0.739704514828479}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:52:01,794] Trial 382 finished with value: 1227720000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09610572058655382, 'min_data_in_leaf': 354, 'feature_fraction': 0.9396908462744662, 'bagging_fraction': 0.759116391066725}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:52:30,736] Trial 383 finished with value: 1222060000.0 and parameters: {'num_leaves': 40, 'learning_rate': 0.09386062963250293, 'min_data_in_leaf': 304, 'feature_fraction': 0.9795883492425761, 'bagging_fraction': 0.5643095490616034}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:53:07,241] Trial 384 finished with value: 1226140000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09621280829376426, 'min_data_in_leaf': 443, 'feature_fraction': 0.9520892833196528, 'bagging_fraction': 0.7378892271448626}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:53:33,820] Trial 385 finished with value: 1217300000.0 and parameters: {'num_leaves': 22, 'learning_rate': 0.09177317698226746, 'min_data_in_leaf': 373, 'feature_fraction': 0.9990062010424221, 'bagging_fraction': 0.7940635925087032}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:54:12,180] Trial 386 finished with value: 1233120000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09687046212227503, 'min_data_in_leaf': 335, 'feature_fraction': 0.9661742218379149, 'bagging_fraction': 0.7496707301048592}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:54:58,352] Trial 387 finished with value: 1229680000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.09511025088633349, 'min_data_in_leaf': 300, 'feature_fraction': 0.9618747174330002, 'bagging_fraction': 0.7280137707976065}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:55:40,113] Trial 388 finished with value: 1226280000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09697863777824885, 'min_data_in_leaf': 337, 'feature_fraction': 0.9773802117850178, 'bagging_fraction': 0.7574663988050463}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:56:18,282] Trial 389 finished with value: 1227240000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.0935567293492401, 'min_data_in_leaf': 343, 'feature_fraction': 0.9457265174351485, 'bagging_fraction': 0.7450424708444809}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:56:55,931] Trial 390 finished with value: 1220320000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.0882800748546863, 'min_data_in_leaf': 323, 'feature_fraction': 0.981279481871921, 'bagging_fraction': 0.5891723925304306}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:57:23,221] Trial 391 finished with value: 1223540000.0 and parameters: {'num_leaves': 32, 'learning_rate': 0.09699780812158966, 'min_data_in_leaf': 361, 'feature_fraction': 0.9629476758116854, 'bagging_fraction': 0.7320660092507013}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:58:01,982] Trial 392 finished with value: 1227300000.0 and parameters: {'num_leaves': 98, 'learning_rate': 0.09505222988763153, 'min_data_in_leaf': 383, 'feature_fraction': 0.9395010631915655, 'bagging_fraction': 0.7209746887614644}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:58:42,698] Trial 393 finished with value: 1221800000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09810703746350928, 'min_data_in_leaf': 341, 'feature_fraction': 0.9676248663292055, 'bagging_fraction': 0.7518367886051208}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:59:19,814] Trial 394 finished with value: 1224120000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.05919094245974938, 'min_data_in_leaf': 361, 'feature_fraction': 0.9855406098400566, 'bagging_fraction': 0.8264966921707734}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-10 23:59:55,656] Trial 395 finished with value: 1229700000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09997622923577343, 'min_data_in_leaf': 322, 'feature_fraction': 0.9982475851885303, 'bagging_fraction': 0.7010644935805327}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:00:32,671] Trial 396 finished with value: 1225040000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.09323258141926086, 'min_data_in_leaf': 394, 'feature_fraction': 0.9459703602564312, 'bagging_fraction': 0.5375270530001718}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:01:08,657] Trial 397 finished with value: 1223740000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09568253492823113, 'min_data_in_leaf': 363, 'feature_fraction': 0.9603201564073779, 'bagging_fraction': 0.7791111677733891}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:01:49,668] Trial 398 finished with value: 1226060000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09810701337546222, 'min_data_in_leaf': 333, 'feature_fraction': 0.9817565834952806, 'bagging_fraction': 0.7305093308752203}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:02:28,733] Trial 399 finished with value: 1223720000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09996694103064165, 'min_data_in_leaf': 383, 'feature_fraction': 0.9336080155323995, 'bagging_fraction': 0.6912308535885104}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:03:05,898] Trial 400 finished with value: 1191900000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.03285227851277138, 'min_data_in_leaf': 1206, 'feature_fraction': 0.9605095037924744, 'bagging_fraction': 0.277183273998016}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:03:43,812] Trial 401 finished with value: 1226200000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09064356404748904, 'min_data_in_leaf': 422, 'feature_fraction': 0.9994049980894136, 'bagging_fraction': 0.7441757786419181}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:04:26,377] Trial 402 finished with value: 1224220000.0 and parameters: {'num_leaves': 96, 'learning_rate': 0.09680238392295362, 'min_data_in_leaf': 350, 'feature_fraction': 0.9764600236645169, 'bagging_fraction': 0.619533440812124}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:05:06,742] Trial 403 finished with value: 1220560000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09469207146618293, 'min_data_in_leaf': 302, 'feature_fraction': 0.9425839823364195, 'bagging_fraction': 0.6590841913152572}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:05:28,728] Trial 404 finished with value: 1206500000.0 and parameters: {'num_leaves': 12, 'learning_rate': 0.09795030653314393, 'min_data_in_leaf': 401, 'feature_fraction': 0.9638162510577426, 'bagging_fraction': 0.7172747702610559}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:06:04,923] Trial 405 finished with value: 1227780000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09211549011080895, 'min_data_in_leaf': 361, 'feature_fraction': 0.9804037624488516, 'bagging_fraction': 0.7609857359779785}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:06:45,155] Trial 406 finished with value: 1227660000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09596137647541605, 'min_data_in_leaf': 324, 'feature_fraction': 0.9300244948993187, 'bagging_fraction': 0.6865668936233479}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:07:21,169] Trial 407 finished with value: 1214320000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.0986410354014372, 'min_data_in_leaf': 1330, 'feature_fraction': 0.9838003076296377, 'bagging_fraction': 0.7358362549288525}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:08:01,485] Trial 408 finished with value: 1221940000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09399522617994148, 'min_data_in_leaf': 380, 'feature_fraction': 0.9517540562793698, 'bagging_fraction': 0.6360058042734135}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:08:39,050] Trial 409 finished with value: 1227340000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.09662651800356542, 'min_data_in_leaf': 473, 'feature_fraction': 0.9720120172573672, 'bagging_fraction': 0.7826154722854015}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:09:18,943] Trial 410 finished with value: 1224680000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09825329740193296, 'min_data_in_leaf': 419, 'feature_fraction': 0.9494884163061673, 'bagging_fraction': 0.7041282732469345}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:09:55,862] Trial 411 finished with value: 1221740000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09470080278849796, 'min_data_in_leaf': 345, 'feature_fraction': 0.9987285864996809, 'bagging_fraction': 0.6555592647313429}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:10:38,134] Trial 412 finished with value: 1226400000.0 and parameters: {'num_leaves': 94, 'learning_rate': 0.09985455685337404, 'min_data_in_leaf': 379, 'feature_fraction': 0.9272395507604868, 'bagging_fraction': 0.7201268487830158}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:11:19,942] Trial 413 finished with value: 1229920000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09677147708270809, 'min_data_in_leaf': 438, 'feature_fraction': 0.9672439959011864, 'bagging_fraction': 0.7577035969384206}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:11:56,158] Trial 414 finished with value: 1226800000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09990496773173402, 'min_data_in_leaf': 322, 'feature_fraction': 0.9992120308852752, 'bagging_fraction': 0.9905408433599077}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:12:27,573] Trial 415 finished with value: 1207520000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.06938235664306155, 'min_data_in_leaf': 401, 'feature_fraction': 0.22416345505265117, 'bagging_fraction': 0.6076996233187556}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:13:05,354] Trial 416 finished with value: 1230400000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09206824901930666, 'min_data_in_leaf': 362, 'feature_fraction': 0.9816344338937562, 'bagging_fraction': 0.8060584946467673}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:13:45,756] Trial 417 finished with value: 1223820000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.09358855162496255, 'min_data_in_leaf': 362, 'feature_fraction': 0.9539588895755915, 'bagging_fraction': 0.8690645459998209}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:14:21,834] Trial 418 finished with value: 1226500000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09016655019610119, 'min_data_in_leaf': 392, 'feature_fraction': 0.9395879492962964, 'bagging_fraction': 0.7978152997003877}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:14:59,815] Trial 419 finished with value: 1221460000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09191123744682798, 'min_data_in_leaf': 451, 'feature_fraction': 0.9674257917487297, 'bagging_fraction': 0.8162322162208511}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:15:35,481] Trial 420 finished with value: 1223740000.0 and parameters: {'num_leaves': 79, 'learning_rate': 0.0881401902554818, 'min_data_in_leaf': 365, 'feature_fraction': 0.9171923686250207, 'bagging_fraction': 0.8428285205809534}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:16:08,838] Trial 421 finished with value: 1226140000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.08981855758169385, 'min_data_in_leaf': 427, 'feature_fraction': 0.9997559944981395, 'bagging_fraction': 0.808488724403098}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:16:49,366] Trial 422 finished with value: 1226100000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09258837080493358, 'min_data_in_leaf': 405, 'feature_fraction': 0.9791910879879256, 'bagging_fraction': 0.7815725873756175}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:17:20,617] Trial 423 finished with value: 1228280000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09161688032375725, 'min_data_in_leaf': 300, 'feature_fraction': 0.9334548421877298, 'bagging_fraction': 0.7730296275557134}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:17:59,790] Trial 424 finished with value: 1232680000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09440992179502912, 'min_data_in_leaf': 379, 'feature_fraction': 0.9539388294011147, 'bagging_fraction': 0.7469817728174062}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:18:35,372] Trial 425 finished with value: 1233220000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09304180796815605, 'min_data_in_leaf': 342, 'feature_fraction': 0.9511414920264567, 'bagging_fraction': 0.8177323532171348}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:19:11,087] Trial 426 finished with value: 1224640000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09042135993121588, 'min_data_in_leaf': 328, 'feature_fraction': 0.9244359083828959, 'bagging_fraction': 0.8123324285083182}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:19:56,802] Trial 427 finished with value: 1224620000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.08642579369241911, 'min_data_in_leaf': 478, 'feature_fraction': 0.9468156668055575, 'bagging_fraction': 0.7942954629820206}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:20:35,190] Trial 428 finished with value: 1222420000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.0934218600596036, 'min_data_in_leaf': 373, 'feature_fraction': 0.9083164357915283, 'bagging_fraction': 0.8527613840184696}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:21:10,457] Trial 429 finished with value: 1223920000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09232848469427893, 'min_data_in_leaf': 354, 'feature_fraction': 0.9408046802540994, 'bagging_fraction': 0.8328619112628926}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:21:46,397] Trial 430 finished with value: 1229100000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.09641210884657135, 'min_data_in_leaf': 408, 'feature_fraction': 0.9284636123275873, 'bagging_fraction': 0.6984285570026109}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:22:18,746] Trial 431 finished with value: 1220280000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.09395764686769384, 'min_data_in_leaf': 391, 'feature_fraction': 0.9558871398083918, 'bagging_fraction': 0.8232869956642652}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:22:58,510] Trial 432 finished with value: 1218820000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.08961097389261775, 'min_data_in_leaf': 433, 'feature_fraction': 0.9576380370105367, 'bagging_fraction': 0.7226728314236668}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:23:31,099] Trial 433 finished with value: 1224040000.0 and parameters: {'num_leaves': 58, 'learning_rate': 0.0970210586974712, 'min_data_in_leaf': 340, 'feature_fraction': 0.9166408803323179, 'bagging_fraction': 0.8114817993215014}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:24:03,050] Trial 434 finished with value: 1221780000.0 and parameters: {'num_leaves': 36, 'learning_rate': 0.09526319761684234, 'min_data_in_leaf': 319, 'feature_fraction': 0.9357754032208769, 'bagging_fraction': 0.6863758502728167}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:24:23,725] Trial 435 finished with value: 1191560000.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.0917223349263453, 'min_data_in_leaf': 371, 'feature_fraction': 0.9637572919054181, 'bagging_fraction': 0.8390871871371417}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:24:59,171] Trial 436 finished with value: 1230900000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09799367929086727, 'min_data_in_leaf': 412, 'feature_fraction': 0.9060563854759637, 'bagging_fraction': 0.7371391888672786}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:25:33,220] Trial 437 finished with value: 1222900000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09800044232114732, 'min_data_in_leaf': 461, 'feature_fraction': 0.9010460386891082, 'bagging_fraction': 0.7114288958935605}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:26:12,951] Trial 438 finished with value: 1223900000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09778335209342526, 'min_data_in_leaf': 417, 'feature_fraction': 0.8772546426024029, 'bagging_fraction': 0.6694488016002894}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:26:47,772] Trial 439 finished with value: 1228100000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09848459632650368, 'min_data_in_leaf': 502, 'feature_fraction': 0.9105026220762799, 'bagging_fraction': 0.7209831234280539}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:27:19,836] Trial 440 finished with value: 1227500000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09661525862591423, 'min_data_in_leaf': 402, 'feature_fraction': 0.9244082544674902, 'bagging_fraction': 0.7308929168233964}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:27:50,612] Trial 441 finished with value: 1228660000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09382221717953029, 'min_data_in_leaf': 421, 'feature_fraction': 0.8974603800884965, 'bagging_fraction': 0.6921014761869443}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:28:28,328] Trial 442 finished with value: 1198840000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.029860231308296403, 'min_data_in_leaf': 437, 'feature_fraction': 0.9385634317114155, 'bagging_fraction': 0.7901818093292045}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:29:00,016] Trial 443 finished with value: 1218840000.0 and parameters: {'num_leaves': 42, 'learning_rate': 0.09791952578761608, 'min_data_in_leaf': 385, 'feature_fraction': 0.9147325405210815, 'bagging_fraction': 0.7428065798860252}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:29:35,042] Trial 444 finished with value: 1229500000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09992030253445118, 'min_data_in_leaf': 446, 'feature_fraction': 0.8808855167054586, 'bagging_fraction': 0.6766299493931638}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:30:12,885] Trial 445 finished with value: 1223540000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.09625836357572276, 'min_data_in_leaf': 394, 'feature_fraction': 0.9479009053260874, 'bagging_fraction': 0.7050569857041835}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:30:45,405] Trial 446 finished with value: 1227520000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09502361416915878, 'min_data_in_leaf': 364, 'feature_fraction': 0.9257866279266801, 'bagging_fraction': 0.7612516578569546}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:31:20,054] Trial 447 finished with value: 1225220000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09808030760370351, 'min_data_in_leaf': 414, 'feature_fraction': 0.9532495279815613, 'bagging_fraction': 0.658839974335853}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:31:57,019] Trial 448 finished with value: 1226200000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09291525400197109, 'min_data_in_leaf': 462, 'feature_fraction': 0.9010526238811675, 'bagging_fraction': 0.7325347847311474}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:32:24,728] Trial 449 finished with value: 1219640000.0 and parameters: {'num_leaves': 26, 'learning_rate': 0.09660147513008772, 'min_data_in_leaf': 387, 'feature_fraction': 0.9352268708689304, 'bagging_fraction': 0.8023578991944471}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:32:55,266] Trial 450 finished with value: 1226060000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09985596732380342, 'min_data_in_leaf': 350, 'feature_fraction': 0.9689590304494116, 'bagging_fraction': 0.8580736145349954}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:33:27,164] Trial 451 finished with value: 1216580000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.08093375232322049, 'min_data_in_leaf': 373, 'feature_fraction': 0.6971506356395277, 'bagging_fraction': 0.7098926625503795}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:34:13,979] Trial 452 finished with value: 1224520000.0 and parameters: {'num_leaves': 97, 'learning_rate': 0.09482790484990626, 'min_data_in_leaf': 522, 'feature_fraction': 0.8667719124023583, 'bagging_fraction': 0.8306825542521717}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:34:46,446] Trial 453 finished with value: 1197900000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.024399110855856457, 'min_data_in_leaf': 396, 'feature_fraction': 0.9533744303569571, 'bagging_fraction': 0.7453275065207462}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:35:22,141] Trial 454 finished with value: 1223380000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.08891994454513293, 'min_data_in_leaf': 353, 'feature_fraction': 0.9124206304486477, 'bagging_fraction': 0.6810011330999969}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:36:04,524] Trial 455 finished with value: 1223620000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09997729802501831, 'min_data_in_leaf': 437, 'feature_fraction': 0.9687906882809956, 'bagging_fraction': 0.6299602702763671}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:36:30,573] Trial 456 finished with value: 1208980000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09790923409573432, 'min_data_in_leaf': 478, 'feature_fraction': 0.12374434166880455, 'bagging_fraction': 0.7718529773927506}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:37:12,721] Trial 457 finished with value: 1220700000.0 and parameters: {'num_leaves': 94, 'learning_rate': 0.09135007644940023, 'min_data_in_leaf': 415, 'feature_fraction': 0.9370289228410397, 'bagging_fraction': 0.7235246947681616}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:38:03,556] Trial 458 finished with value: 1221240000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.09624674119669858, 'min_data_in_leaf': 370, 'feature_fraction': 0.49127476760073535, 'bagging_fraction': 0.6969300288465794}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:38:35,242] Trial 459 finished with value: 1229440000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09311683503094258, 'min_data_in_leaf': 342, 'feature_fraction': 0.9508449909668928, 'bagging_fraction': 0.6509541393213112}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:39:12,619] Trial 460 finished with value: 1219080000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.0729954685587728, 'min_data_in_leaf': 387, 'feature_fraction': 0.8884830814354144, 'bagging_fraction': 0.7518789133949464}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:39:45,397] Trial 461 finished with value: 1228720000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09719103859769114, 'min_data_in_leaf': 494, 'feature_fraction': 0.9211838783867681, 'bagging_fraction': 0.665388604420701}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:40:22,463] Trial 462 finished with value: 1215960000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09471043767719735, 'min_data_in_leaf': 1154, 'feature_fraction': 0.3854071166860016, 'bagging_fraction': 0.7159460245546022}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:40:58,743] Trial 463 finished with value: 1223460000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09795314235874109, 'min_data_in_leaf': 411, 'feature_fraction': 0.9680403919958207, 'bagging_fraction': 0.7786192977208185}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:41:22,397] Trial 464 finished with value: 1214120000.0 and parameters: {'num_leaves': 16, 'learning_rate': 0.09545431998424705, 'min_data_in_leaf': 632, 'feature_fraction': 0.9744245804670476, 'bagging_fraction': 0.6810787145056246}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:41:55,899] Trial 465 finished with value: 1228720000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09857166498797094, 'min_data_in_leaf': 359, 'feature_fraction': 0.9491762478903913, 'bagging_fraction': 0.732402332296386}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:42:29,074] Trial 466 finished with value: 1222660000.0 and parameters: {'num_leaves': 59, 'learning_rate': 0.09274073145596384, 'min_data_in_leaf': 599, 'feature_fraction': 0.9288189843231995, 'bagging_fraction': 0.3589754129161552}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:43:12,107] Trial 467 finished with value: 1222340000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.099996110803948, 'min_data_in_leaf': 331, 'feature_fraction': 0.6457071244852197, 'bagging_fraction': 0.7626334675368397}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:43:50,509] Trial 468 finished with value: 1221940000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09630283271630001, 'min_data_in_leaf': 440, 'feature_fraction': 0.8588211418387197, 'bagging_fraction': 0.472900756910851}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:44:25,184] Trial 469 finished with value: 1228360000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.09396726033042474, 'min_data_in_leaf': 533, 'feature_fraction': 0.9005924245011797, 'bagging_fraction': 0.5893051278224974}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:44:56,899] Trial 470 finished with value: 1225920000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09812917355058703, 'min_data_in_leaf': 378, 'feature_fraction': 0.9674910067710532, 'bagging_fraction': 0.7019279999297833}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:45:36,914] Trial 471 finished with value: 1231040000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09075678854324797, 'min_data_in_leaf': 345, 'feature_fraction': 0.9785739576257256, 'bagging_fraction': 0.8024278876044173}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:46:13,379] Trial 472 finished with value: 1229980000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.08708084107965731, 'min_data_in_leaf': 300, 'feature_fraction': 0.9414151529940911, 'bagging_fraction': 0.8208661789940637}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:46:53,627] Trial 473 finished with value: 1219380000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09104777118732767, 'min_data_in_leaf': 326, 'feature_fraction': 0.9152994049857545, 'bagging_fraction': 0.8046398209250225}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:47:31,655] Trial 474 finished with value: 1221480000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.08915639173036041, 'min_data_in_leaf': 344, 'feature_fraction': 0.9577168865250995, 'bagging_fraction': 0.8266933273128317}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:48:07,245] Trial 475 finished with value: 1233360000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.0924437582919567, 'min_data_in_leaf': 345, 'feature_fraction': 0.9337093616022327, 'bagging_fraction': 0.7994324802158879}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:48:38,289] Trial 476 finished with value: 1222860000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.08892874533148216, 'min_data_in_leaf': 326, 'feature_fraction': 0.94152802645212, 'bagging_fraction': 0.7921394979355917}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:49:08,510] Trial 477 finished with value: 1221860000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.08678101384294262, 'min_data_in_leaf': 345, 'feature_fraction': 0.9756720730567424, 'bagging_fraction': 0.8189662928120404}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:49:40,742] Trial 478 finished with value: 1221680000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.09053763003746926, 'min_data_in_leaf': 317, 'feature_fraction': 0.9517884464511677, 'bagging_fraction': 0.8007419804374996}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:50:23,501] Trial 479 finished with value: 1225980000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.09096976164205728, 'min_data_in_leaf': 356, 'feature_fraction': 0.7376030485833558, 'bagging_fraction': 0.8375283978520186}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:51:00,099] Trial 480 finished with value: 1226160000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09138546153738983, 'min_data_in_leaf': 300, 'feature_fraction': 0.9664051777528835, 'bagging_fraction': 0.8176584452539084}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:51:30,803] Trial 481 finished with value: 1228080000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09225116312173608, 'min_data_in_leaf': 341, 'feature_fraction': 0.9306920215634894, 'bagging_fraction': 0.7946006783757628}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:52:04,121] Trial 482 finished with value: 1228540000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09258439388037254, 'min_data_in_leaf': 363, 'feature_fraction': 0.9833174393786952, 'bagging_fraction': 0.49748256814537883}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:52:46,061] Trial 483 finished with value: 1222440000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.08412983533870622, 'min_data_in_leaf': 322, 'feature_fraction': 0.9533839557872531, 'bagging_fraction': 0.8523587697909629}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:53:27,192] Trial 484 finished with value: 1219540000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.08856926170453425, 'min_data_in_leaf': 364, 'feature_fraction': 0.6193698917708467, 'bagging_fraction': 0.784321986151819}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:54:06,191] Trial 485 finished with value: 1214840000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.052784673301093696, 'min_data_in_leaf': 674, 'feature_fraction': 0.8908735581093492, 'bagging_fraction': 0.6202754407808103}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:54:48,172] Trial 486 finished with value: 1227960000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.0932418945689622, 'min_data_in_leaf': 341, 'feature_fraction': 0.9806074300733161, 'bagging_fraction': 0.8066554282829966}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:55:22,170] Trial 487 finished with value: 1228040000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09510953221718904, 'min_data_in_leaf': 391, 'feature_fraction': 0.932759892473164, 'bagging_fraction': 0.6523461374497207}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:55:55,267] Trial 488 finished with value: 1228000000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09378228158903837, 'min_data_in_leaf': 583, 'feature_fraction': 0.961552896655928, 'bagging_fraction': 0.6670948412605366}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:56:33,415] Trial 489 finished with value: 1207980000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.03626955707487142, 'min_data_in_leaf': 544, 'feature_fraction': 0.9112065863979627, 'bagging_fraction': 0.7829971500971825}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:57:08,167] Trial 490 finished with value: 1229040000.0 and parameters: {'num_leaves': 43, 'learning_rate': 0.09615279244550798, 'min_data_in_leaf': 378, 'feature_fraction': 0.9784864379766278, 'bagging_fraction': 0.6378008524423318}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:57:46,366] Trial 491 finished with value: 1222780000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09003618030159026, 'min_data_in_leaf': 718, 'feature_fraction': 0.9442052518939174, 'bagging_fraction': 0.6903624903998979}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:58:22,812] Trial 492 finished with value: 1217820000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.0967084143353112, 'min_data_in_leaf': 1259, 'feature_fraction': 0.9688056136273041, 'bagging_fraction': 0.6697205991221415}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:58:55,274] Trial 493 finished with value: 1227000000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09405276117774879, 'min_data_in_leaf': 354, 'feature_fraction': 0.8723032023657192, 'bagging_fraction': 0.8369818370895081}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 00:59:34,108] Trial 494 finished with value: 1228340000.0 and parameters: {'num_leaves': 75, 'learning_rate': 0.09741267066751082, 'min_data_in_leaf': 513, 'feature_fraction': 0.9262599821808155, 'bagging_fraction': 0.8018648023093089}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:00:07,714] Trial 495 finished with value: 1230840000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09545792582965144, 'min_data_in_leaf': 320, 'feature_fraction': 0.9531897960767993, 'bagging_fraction': 0.6309869514567047}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:00:38,222] Trial 496 finished with value: 1223340000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09558077234020712, 'min_data_in_leaf': 315, 'feature_fraction': 0.9072631444398404, 'bagging_fraction': 0.5977685441915916}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:01:09,507] Trial 497 finished with value: 1219740000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09851272692582994, 'min_data_in_leaf': 300, 'feature_fraction': 0.9352027355161866, 'bagging_fraction': 0.6160001555866986}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:01:42,995] Trial 498 finished with value: 1224180000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.0964367015261658, 'min_data_in_leaf': 324, 'feature_fraction': 0.9517845702156466, 'bagging_fraction': 0.5787888147618889}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:02:19,621] Trial 499 finished with value: 1227100000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.09818343786418005, 'min_data_in_leaf': 336, 'feature_fraction': 0.8898825972391528, 'bagging_fraction': 0.6391437897056402}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:02:51,219] Trial 500 finished with value: 1220480000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.0949579627509265, 'min_data_in_leaf': 319, 'feature_fraction': 0.9236106447731952, 'bagging_fraction': 0.6163775822968584}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:03:25,505] Trial 501 finished with value: 1208240000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.04757529297222121, 'min_data_in_leaf': 340, 'feature_fraction': 0.8445724999057279, 'bagging_fraction': 0.6464991253577619}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:04:02,401] Trial 502 finished with value: 1224640000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09808209570352171, 'min_data_in_leaf': 398, 'feature_fraction': 0.9507264987143662, 'bagging_fraction': 0.6368546888260308}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:04:38,637] Trial 503 finished with value: 1226260000.0 and parameters: {'num_leaves': 54, 'learning_rate': 0.096022145475195, 'min_data_in_leaf': 300, 'feature_fraction': 0.9093581996861381, 'bagging_fraction': 0.6578625221085815}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:05:16,975] Trial 504 finished with value: 1223780000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.09991779509416553, 'min_data_in_leaf': 621, 'feature_fraction': 0.9638618333873, 'bagging_fraction': 0.6269505266745665}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:05:46,699] Trial 505 finished with value: 1220840000.0 and parameters: {'num_leaves': 41, 'learning_rate': 0.09315753211451573, 'min_data_in_leaf': 366, 'feature_fraction': 0.9391616243472063, 'bagging_fraction': 0.6850789268370715}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:06:19,026] Trial 506 finished with value: 1226320000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09686213728658649, 'min_data_in_leaf': 339, 'feature_fraction': 0.9621388669918831, 'bagging_fraction': 0.6708973653308425}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:06:54,788] Trial 507 finished with value: 1210100000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.055880699679706644, 'min_data_in_leaf': 1106, 'feature_fraction': 0.9228199272414751, 'bagging_fraction': 0.697592847496972}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:07:32,386] Trial 508 finished with value: 1233360000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09449406865251535, 'min_data_in_leaf': 383, 'feature_fraction': 0.981085319822815, 'bagging_fraction': 0.7124629635644427}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:08:13,467] Trial 509 finished with value: 1221140000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.09363511493375767, 'min_data_in_leaf': 417, 'feature_fraction': 0.9437836144242313, 'bagging_fraction': 0.7146705499214315}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:08:54,620] Trial 510 finished with value: 1224220000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.09149337614674379, 'min_data_in_leaf': 378, 'feature_fraction': 0.898610644278792, 'bagging_fraction': 0.7295326449946583}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:09:32,404] Trial 511 finished with value: 1222180000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09440272288941716, 'min_data_in_leaf': 399, 'feature_fraction': 0.9507447274018498, 'bagging_fraction': 0.7044506247842532}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:10:20,861] Trial 512 finished with value: 1230220000.0 and parameters: {'num_leaves': 96, 'learning_rate': 0.09488033136507788, 'min_data_in_leaf': 355, 'feature_fraction': 0.8741020035710856, 'bagging_fraction': 0.717484753188032}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:10:59,393] Trial 513 finished with value: 1228820000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.0928520242701621, 'min_data_in_leaf': 452, 'feature_fraction': 0.9684662448243995, 'bagging_fraction': 0.12677406534307095}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:11:38,124] Trial 514 finished with value: 1222020000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.08990801844505422, 'min_data_in_leaf': 393, 'feature_fraction': 0.9380552939106168, 'bagging_fraction': 0.7395587014081095}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:12:15,322] Trial 515 finished with value: 1225220000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.09621747280052327, 'min_data_in_leaf': 428, 'feature_fraction': 0.9824096456164589, 'bagging_fraction': 0.6826513651046254}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:12:57,654] Trial 516 finished with value: 1226980000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.09484576534317853, 'min_data_in_leaf': 367, 'feature_fraction': 0.9160819410100322, 'bagging_fraction': 0.7004294085973523}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:13:45,146] Trial 517 finished with value: 1224560000.0 and parameters: {'num_leaves': 99, 'learning_rate': 0.0930738911672239, 'min_data_in_leaf': 324, 'feature_fraction': 0.9601995961280426, 'bagging_fraction': 0.7661032850978524}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:14:23,355] Trial 518 finished with value: 1230840000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09124496472970937, 'min_data_in_leaf': 382, 'feature_fraction': 0.9344343642298282, 'bagging_fraction': 0.7261827308922234}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:14:54,087] Trial 519 finished with value: 1226460000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.08859845412245462, 'min_data_in_leaf': 441, 'feature_fraction': 0.8984777434402308, 'bagging_fraction': 0.7351734834781991}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:15:25,184] Trial 520 finished with value: 1225160000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09102594122935832, 'min_data_in_leaf': 403, 'feature_fraction': 0.9253782075819085, 'bagging_fraction': 0.7506955353562526}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:15:57,404] Trial 521 finished with value: 1226160000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.08701873410408704, 'min_data_in_leaf': 382, 'feature_fraction': 0.914208706930786, 'bagging_fraction': 0.723171899661266}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:16:42,575] Trial 522 finished with value: 1224880000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.09018330919613371, 'min_data_in_leaf': 470, 'feature_fraction': 0.8804394829935361, 'bagging_fraction': 0.7653959358508414}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:17:11,024] Trial 523 finished with value: 1180720000.0 and parameters: {'num_leaves': 38, 'learning_rate': 0.011643230142009568, 'min_data_in_leaf': 416, 'feature_fraction': 0.9347351481947597, 'bagging_fraction': 0.7390066191558092}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:17:44,189] Trial 524 finished with value: 1228140000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09179789594674964, 'min_data_in_leaf': 381, 'feature_fraction': 0.9314385036384685, 'bagging_fraction': 0.7172768462075533}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:18:17,263] Trial 525 finished with value: 1223900000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09760607332355087, 'min_data_in_leaf': 341, 'feature_fraction': 0.9012478815333679, 'bagging_fraction': 0.7679835015204954}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:18:51,170] Trial 526 finished with value: 1222840000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.08845291016553904, 'min_data_in_leaf': 419, 'feature_fraction': 0.940743358140474, 'bagging_fraction': 0.7444921433945294}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:19:36,101] Trial 527 finished with value: 1224720000.0 and parameters: {'num_leaves': 89, 'learning_rate': 0.08593536482372552, 'min_data_in_leaf': 362, 'feature_fraction': 0.9528190483405355, 'bagging_fraction': 0.7252294820250571}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:20:09,528] Trial 528 finished with value: 1225040000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09243734212939043, 'min_data_in_leaf': 397, 'feature_fraction': 0.9140415031433051, 'bagging_fraction': 0.7838083519352096}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:20:46,365] Trial 529 finished with value: 1226200000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.09799599393454915, 'min_data_in_leaf': 319, 'feature_fraction': 0.8871090752232595, 'bagging_fraction': 0.7049825744105346}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:21:16,803] Trial 530 finished with value: 1227800000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09525843962641353, 'min_data_in_leaf': 380, 'feature_fraction': 0.9547238713779578, 'bagging_fraction': 0.7563019808320054}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:22:06,901] Trial 531 finished with value: 1223200000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.0935902362667619, 'min_data_in_leaf': 344, 'feature_fraction': 0.9788338333083036, 'bagging_fraction': 0.4254415807771744}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:22:53,169] Trial 532 finished with value: 1216920000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09999361749554972, 'min_data_in_leaf': 489, 'feature_fraction': 0.7843027738777396, 'bagging_fraction': 0.6795783706989373}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:23:37,607] Trial 533 finished with value: 1224400000.0 and parameters: {'num_leaves': 94, 'learning_rate': 0.09689066805041259, 'min_data_in_leaf': 430, 'feature_fraction': 0.8634214293892818, 'bagging_fraction': 0.6563415689256841}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:24:11,205] Trial 534 finished with value: 1229500000.0 and parameters: {'num_leaves': 51, 'learning_rate': 0.09641618250159614, 'min_data_in_leaf': 366, 'feature_fraction': 0.9221336685200715, 'bagging_fraction': 0.17434738756966855}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:24:40,745] Trial 535 finished with value: 1219460000.0 and parameters: {'num_leaves': 33, 'learning_rate': 0.09009579258828426, 'min_data_in_leaf': 402, 'feature_fraction': 0.7548644907843589, 'bagging_fraction': 0.7338559631258957}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:25:10,575] Trial 536 finished with value: 1223840000.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.09435621846719085, 'min_data_in_leaf': 455, 'feature_fraction': 0.9431768163437468, 'bagging_fraction': 0.7092163890557088}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:25:42,300] Trial 537 finished with value: 1219440000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09833582440134889, 'min_data_in_leaf': 344, 'feature_fraction': 0.9657447276851069, 'bagging_fraction': 0.7704247866505407}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:26:19,884] Trial 538 finished with value: 1222340000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09144472661630774, 'min_data_in_leaf': 301, 'feature_fraction': 0.9848626540629255, 'bagging_fraction': 0.6864101797208892}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:27:01,030] Trial 539 finished with value: 1228080000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.09840006300070371, 'min_data_in_leaf': 380, 'feature_fraction': 0.9332585438997951, 'bagging_fraction': 0.7441553014113262}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:27:34,285] Trial 540 finished with value: 1228720000.0 and parameters: {'num_leaves': 61, 'learning_rate': 0.09609413997336416, 'min_data_in_leaf': 327, 'feature_fraction': 0.9594831704348962, 'bagging_fraction': 0.7227346341028213}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:28:03,477] Trial 541 finished with value: 1205140000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.038778013369849276, 'min_data_in_leaf': 360, 'feature_fraction': 0.9078850300393231, 'bagging_fraction': 0.6630879049655073}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:28:40,391] Trial 542 finished with value: 1224220000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09384656600660961, 'min_data_in_leaf': 409, 'feature_fraction': 0.9829028726809051, 'bagging_fraction': 0.6962006301255179}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:29:20,023] Trial 543 finished with value: 1220400000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.09994806903147495, 'min_data_in_leaf': 386, 'feature_fraction': 0.8896103120622291, 'bagging_fraction': 0.7833988389479852}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:29:54,059] Trial 544 finished with value: 1227820000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.09673678559545582, 'min_data_in_leaf': 345, 'feature_fraction': 0.946103485866804, 'bagging_fraction': 0.7543836626157835}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:30:25,824] Trial 545 finished with value: 1229420000.0 and parameters: {'num_leaves': 43, 'learning_rate': 0.09225398557272455, 'min_data_in_leaf': 432, 'feature_fraction': 0.9256052403639107, 'bagging_fraction': 0.7182406444872396}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:30:59,552] Trial 546 finished with value: 1226560000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09528553036113238, 'min_data_in_leaf': 320, 'feature_fraction': 0.9671620472335416, 'bagging_fraction': 0.673918830352892}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:31:38,904] Trial 547 finished with value: 1228440000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09826559555633589, 'min_data_in_leaf': 371, 'feature_fraction': 0.8556276573979662, 'bagging_fraction': 0.451135038469906}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:32:22,548] Trial 548 finished with value: 1223280000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09380586747484786, 'min_data_in_leaf': 400, 'feature_fraction': 0.9504576854128545, 'bagging_fraction': 0.6471141483829126}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:32:59,552] Trial 549 finished with value: 1225640000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.08286833509394026, 'min_data_in_leaf': 515, 'feature_fraction': 0.8214885328339068, 'bagging_fraction': 0.7431419578158727}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:33:33,903] Trial 550 finished with value: 1226420000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.0967990173381913, 'min_data_in_leaf': 343, 'feature_fraction': 0.9821865545955994, 'bagging_fraction': 0.8712295776758051}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:34:21,743] Trial 551 finished with value: 1190880000.0 and parameters: {'num_leaves': 97, 'learning_rate': 0.020159872792177985, 'min_data_in_leaf': 363, 'feature_fraction': 0.5234929385475133, 'bagging_fraction': 0.7081502467066778}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:35:08,632] Trial 552 finished with value: 1227880000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.09815479398246747, 'min_data_in_leaf': 323, 'feature_fraction': 0.4452956275961937, 'bagging_fraction': 0.7749824505831641}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:35:51,921] Trial 553 finished with value: 1231760000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09037940201904344, 'min_data_in_leaf': 417, 'feature_fraction': 0.9112362500159317, 'bagging_fraction': 0.7296887726316201}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:36:27,320] Trial 554 finished with value: 1221840000.0 and parameters: {'num_leaves': 72, 'learning_rate': 0.0875278314821014, 'min_data_in_leaf': 475, 'feature_fraction': 0.8809269771511897, 'bagging_fraction': 0.7338302266838442}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:37:07,068] Trial 555 finished with value: 1226200000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.0896821853880796, 'min_data_in_leaf': 457, 'feature_fraction': 0.9006882659455396, 'bagging_fraction': 0.7546929348470407}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:37:35,416] Trial 556 finished with value: 1218840000.0 and parameters: {'num_leaves': 25, 'learning_rate': 0.09045940525056881, 'min_data_in_leaf': 427, 'feature_fraction': 0.9091615527938532, 'bagging_fraction': 0.7282759559337164}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:38:13,711] Trial 557 finished with value: 1228340000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.08753423104714773, 'min_data_in_leaf': 546, 'feature_fraction': 0.9200335637712416, 'bagging_fraction': 0.7130781534486557}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:38:46,669] Trial 558 finished with value: 1227540000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.09170802150653332, 'min_data_in_leaf': 448, 'feature_fraction': 0.8922736092732027, 'bagging_fraction': 0.7595758976142418}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:39:28,561] Trial 559 finished with value: 1220560000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.08930883492334801, 'min_data_in_leaf': 416, 'feature_fraction': 0.9289234423661753, 'bagging_fraction': 0.7367563683954803}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:40:07,778] Trial 560 finished with value: 1223660000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.09269819313446766, 'min_data_in_leaf': 496, 'feature_fraction': 0.872501808779447, 'bagging_fraction': 0.7900347103053638}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:40:40,391] Trial 561 finished with value: 1213740000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.08417228881880019, 'min_data_in_leaf': 1416, 'feature_fraction': 0.9118945695856936, 'bagging_fraction': 0.8156885758835928}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:41:14,754] Trial 562 finished with value: 1223480000.0 and parameters: {'num_leaves': 55, 'learning_rate': 0.08538163165437596, 'min_data_in_leaf': 300, 'feature_fraction': 0.9344601798343594, 'bagging_fraction': 0.697484954877359}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:41:46,590] Trial 563 finished with value: 1220460000.0 and parameters: {'num_leaves': 46, 'learning_rate': 0.09163350751588477, 'min_data_in_leaf': 385, 'feature_fraction': 0.6605841965689833, 'bagging_fraction': 0.7245257302377203}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:42:21,246] Trial 564 finished with value: 1225740000.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.08877057883183696, 'min_data_in_leaf': 356, 'feature_fraction': 0.8412434589785265, 'bagging_fraction': 0.7528082783391966}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:43:00,701] Trial 565 finished with value: 1224180000.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.09446828783176489, 'min_data_in_leaf': 331, 'feature_fraction': 0.8904285437822961, 'bagging_fraction': 0.7750888813385778}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:43:36,899] Trial 566 finished with value: 1229340000.0 and parameters: {'num_leaves': 76, 'learning_rate': 0.09327505942382704, 'min_data_in_leaf': 405, 'feature_fraction': 0.9439986760532226, 'bagging_fraction': 0.7174771413394897}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:44:19,396] Trial 567 finished with value: 1223840000.0 and parameters: {'num_leaves': 80, 'learning_rate': 0.09095714467982338, 'min_data_in_leaf': 368, 'feature_fraction': 0.9043736628586575, 'bagging_fraction': 0.2612323030451778}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:44:52,096] Trial 568 finished with value: 1217980000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.05920751284865686, 'min_data_in_leaf': 430, 'feature_fraction': 0.9293399346474641, 'bagging_fraction': 0.7413640998998241}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:45:32,514] Trial 569 finished with value: 1223440000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.09510397849172958, 'min_data_in_leaf': 346, 'feature_fraction': 0.9501596685662629, 'bagging_fraction': 0.7988798989284445}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:46:17,045] Trial 570 finished with value: 1226840000.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.09558598717453956, 'min_data_in_leaf': 385, 'feature_fraction': 0.9190517500241419, 'bagging_fraction': 0.6924977966592762}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:46:51,013] Trial 571 finished with value: 1220760000.0 and parameters: {'num_leaves': 53, 'learning_rate': 0.09297907621250485, 'min_data_in_leaf': 320, 'feature_fraction': 0.9634410839589715, 'bagging_fraction': 0.7095710649766863}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:47:28,316] Trial 572 finished with value: 1218860000.0 and parameters: {'num_leaves': 50, 'learning_rate': 0.07923066292675175, 'min_data_in_leaf': 412, 'feature_fraction': 0.8722808440484643, 'bagging_fraction': 0.765398696718646}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:48:11,259] Trial 573 finished with value: 1226840000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.09653581564905542, 'min_data_in_leaf': 356, 'feature_fraction': 0.938450198507481, 'bagging_fraction': 0.8320217099160355}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:48:54,851] Trial 574 finished with value: 1224300000.0 and parameters: {'num_leaves': 86, 'learning_rate': 0.09049573799693725, 'min_data_in_leaf': 458, 'feature_fraction': 0.9025327853174502, 'bagging_fraction': 0.7308045230818032}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:49:31,449] Trial 575 finished with value: 1215200000.0 and parameters: {'num_leaves': 45, 'learning_rate': 0.09444601440016744, 'min_data_in_leaf': 532, 'feature_fraction': 0.3291637890217666, 'bagging_fraction': 0.7465832524849351}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:50:04,983] Trial 576 finished with value: 1223460000.0 and parameters: {'num_leaves': 48, 'learning_rate': 0.09858112370817979, 'min_data_in_leaf': 565, 'feature_fraction': 0.9820616924848065, 'bagging_fraction': 0.6867713107524944}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:50:43,104] Trial 577 finished with value: 1225200000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.096823648681428, 'min_data_in_leaf': 380, 'feature_fraction': 0.9616241852824596, 'bagging_fraction': 0.9150317192279215}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:51:21,394] Trial 578 finished with value: 1223480000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.08814609990942274, 'min_data_in_leaf': 605, 'feature_fraction': 0.9237732133598431, 'bagging_fraction': 0.7790401261216708}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:52:03,109] Trial 579 finished with value: 1231260000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.09988590133106967, 'min_data_in_leaf': 300, 'feature_fraction': 0.9861881174534344, 'bagging_fraction': 0.7056069181334209}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:52:43,623] Trial 580 finished with value: 1226300000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09244263255895212, 'min_data_in_leaf': 317, 'feature_fraction': 0.9778281576666312, 'bagging_fraction': 0.6787551923452649}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:53:21,105] Trial 581 finished with value: 1232140000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.0950426083964024, 'min_data_in_leaf': 317, 'feature_fraction': 0.9878915047921838, 'bagging_fraction': 0.7093128229053722}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:54:01,420] Trial 582 finished with value: 1221360000.0 and parameters: {'num_leaves': 84, 'learning_rate': 0.06724916196456363, 'min_data_in_leaf': 314, 'feature_fraction': 0.9997357823177235, 'bagging_fraction': 0.5470882163146646}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:54:40,720] Trial 583 finished with value: 1225620000.0 and parameters: {'num_leaves': 83, 'learning_rate': 0.09997153366854225, 'min_data_in_leaf': 306, 'feature_fraction': 0.9879356066179189, 'bagging_fraction': 0.6985677457024161}. Best is trial 218 with value: 1235980000.0.\n",
      "[I 2025-10-11 01:55:23,067] Trial 584 finished with value: 1231080000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.09649113414209298, 'min_data_in_leaf': 329, 'feature_fraction': 0.9855487925856261, 'bagging_fraction': 0.6708383410527378}. Best is trial 218 with value: 1235980000.0.\n",
      "[W 2025-10-11 01:55:54,992] Trial 585 failed with parameters: {'num_leaves': 86, 'learning_rate': 0.04397918351722509, 'min_data_in_leaf': 308, 'feature_fraction': 0.9901886276963208, 'bagging_fraction': 0.6806374614765772} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Flor\\AppData\\Local\\Temp\\ipykernel_15988\\489090308.py\", line 29, in objective\n",
      "    cv_results = lgb.cv(\n",
      "                 ^^^^^^^\n",
      "  File \"c:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 829, in cv\n",
      "    cvbooster.update(fobj=fobj)  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\engine.py\", line 417, in handler_function\n",
      "    ret.append(getattr(booster, name)(*args, **kwargs))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-11 01:55:55,047] Trial 585 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# subir subir\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    350\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    357\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    358\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    360\u001b[39m \n\u001b[32m    361\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     75\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    243\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    244\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    246\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    199\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      9\u001b[39m params = {\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcustom\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m: -\u001b[32m1\u001b[39m\n\u001b[32m     24\u001b[39m }\n\u001b[32m     25\u001b[39m train_data = lgb.Dataset(X_train,\n\u001b[32m     26\u001b[39m                           label=y_train, \u001b[38;5;66;03m# eligir la clase\u001b[39;00m\n\u001b[32m     27\u001b[39m                           weight=pesos_train\n\u001b[32m     28\u001b[39m                           )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m cv_results = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# modificar, subit y subir... y descomentar la línea inferior\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# early_stopping_rounds= int(50 + 5 / learning_rate),\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mganancia_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstratified\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnfold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEMILLAS\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m/\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m max_gan = \u001b[38;5;28mmax\u001b[39m(cv_results[\u001b[33m'\u001b[39m\u001b[33mvalid gan_eval-mean\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     44\u001b[39m best_iter = cv_results[\u001b[33m'\u001b[39m\u001b[33mvalid gan_eval-mean\u001b[39m\u001b[33m'\u001b[39m].index(max_gan) + \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\engine.py:829\u001b[39m, in \u001b[36mcv\u001b[39m\u001b[34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, feval, init_model, fpreproc, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    819\u001b[39m     cb(\n\u001b[32m    820\u001b[39m         callback.CallbackEnv(\n\u001b[32m    821\u001b[39m             model=cvbooster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    827\u001b[39m         )\n\u001b[32m    828\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[43mcvbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    830\u001b[39m res = _agg_cv_result(cvbooster.eval_valid(feval))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, metric_name, metric_mean, _, metric_std_dev \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\engine.py:417\u001b[39m, in \u001b[36mCVBooster.__getattr__.<locals>.handler_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m ret = []\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m booster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.boosters:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     ret.append(\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=1000) # subir subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9a72c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGANDO ESTUDIO DE OPTUNA\n",
      "============================================================\n",
      "Estudio cargado: exp_301_lgbm\n",
      "Número de trials: 586\n",
      "Mejor valor: $1,235,980,000\n",
      "Mejores parámetros: {'num_leaves': 51, 'learning_rate': 0.0982712435048071, 'min_data_in_leaf': 573, 'feature_fraction': 0.8936142331074993, 'bagging_fraction': 0.6498337910529549}\n",
      "\n",
      "============================================================\n",
      "GENERANDO GRÁFICOS INTERACTIVOS (PLOTLY)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 1. Historia de optimización\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m fig = \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m fig.write_html(\u001b[33m\"\u001b[39m\u001b[33mdata/graficos/optimization_history.html\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Guardado: data/graficos/optimization_history.html\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\visualization\\_optimization_history.py:222\u001b[39m, in \u001b[36mplot_optimization_history\u001b[39m\u001b[34m(study, target, target_name, error_bar)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_optimization_history\u001b[39m(\n\u001b[32m    173\u001b[39m     study: Study | Sequence[Study],\n\u001b[32m    174\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m     error_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    178\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mgo.Figure\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[32m    180\u001b[39m \n\u001b[32m    181\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m \u001b[33;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43m_imports\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m     info_list = _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Flor\\Documents\\UBA\\DMEyF\\venv\\Lib\\site-packages\\optuna\\_imports.py:89\u001b[39m, in \u001b[36m_DeferredImportExceptionContextManager.check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     88\u001b[39m     exc_value, message = \u001b[38;5;28mself\u001b[39m._deferred\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_value\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================\n",
    "# CARGAR ESTUDIO DE OPTUNA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CARGANDO ESTUDIO DE OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "storage_name = \"sqlite:///data/optimization_lgbm.db\"\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "study = optuna.load_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name\n",
    ")\n",
    "\n",
    "print(f\"Estudio cargado: {study_name}\")\n",
    "print(f\"Número de trials: {len(study.trials)}\")\n",
    "print(f\"Mejor valor: ${study.best_value:,.0f}\")\n",
    "print(f\"Mejores parámetros: {study.best_params}\")\n",
    "\n",
    "# ============================================================\n",
    "# OPCIÓN 1: GRÁFICOS INTERACTIVOS CON PLOTLY (OPTUNA)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERANDO GRÁFICOS INTERACTIVOS (PLOTLY)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Historia de optimización\n",
    "fig = plot_optimization_history(study)\n",
    "fig.write_html(\"data/graficos/optimization_history.html\")\n",
    "print(\"✅ Guardado: data/graficos/optimization_history.html\")\n",
    "\n",
    "# 2. Importancia de parámetros\n",
    "fig = plot_param_importances(study)\n",
    "fig.write_html(\"data/graficos/param_importances.html\")\n",
    "print(\"✅ Guardado: data/graficos/param_importances.html\")\n",
    "\n",
    "# 3. Gráfico de contorno (relaciones entre pares de parámetros)\n",
    "from optuna.visualization import plot_contour\n",
    "fig = plot_contour(study, params=['num_leaves', 'learning_rate'])\n",
    "fig.write_html(\"data/graficos/contour_leaves_lr.html\")\n",
    "print(\"✅ Guardado: data/graficos/contour_leaves_lr.html\")\n",
    "\n",
    "# 4. Slice plot (cada hiperparámetro vs ganancia)\n",
    "from optuna.visualization import plot_slice\n",
    "fig = plot_slice(study)\n",
    "fig.write_html(\"data/graficos/slice_plot.html\")\n",
    "print(\"✅ Guardado: data/graficos/slice_plot.html\")\n",
    "\n",
    "# 5. Parallel coordinate plot\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.write_html(\"data/graficos/parallel_coordinate.html\")\n",
    "print(\"✅ Guardado: data/graficos/parallel_coordinate.html\")\n",
    "\n",
    "# ============================================================\n",
    "# OPCIÓN 2: GRÁFICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b7d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Obtener los mejores 10 trials\n",
    "best_trials = study.trials_dataframe().sort_values('value', ascending=False).head(10)\n",
    "\n",
    "# Opción 1: Guardar como lista de diccionarios (más completo)\n",
    "mejores_params = []\n",
    "for i, trial in enumerate(study.best_trials[:10] if len(study.best_trials) >= 10 else study.best_trials):\n",
    "    mejores_params.append({\n",
    "        'rank': i + 1,\n",
    "        'trial_number': trial.number,\n",
    "        'value': trial.value,\n",
    "        'params': trial.params,\n",
    "        'best_iter': trial.user_attrs.get('best_iter', None)\n",
    "    })\n",
    "\n",
    "# Guardar en JSON\n",
    "with open('data/mejores_hiperparametros2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mejores_params, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f180540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARANDO DATOS TRAIN\n",
      "============================================================\n",
      "Creando pesos...\n",
      "Convirtiendo a numpy (float32)...\n",
      "X_train: (166406, 802), dtype: float32\n",
      "y_train_binaria: (166406,), dtype: int8\n",
      "Clase positiva: 5,284\n",
      "Clase negativa: 161,122\n",
      "Liberando df_train de memoria...\n",
      "✅ Datos TRAIN preparados y df_train liberado\n",
      "\n",
      "============================================================\n",
      "PREPARANDO DATOS TEST\n",
      "============================================================\n",
      "X_test: (163418, 802), dtype: float32\n",
      "y_test: (163418,)\n",
      "Liberando df_test de memoria...\n",
      "✅ Datos TEST preparados\n",
      "\n",
      "============================================================\n",
      "ENTRENAMIENTO CON TRAIN\n",
      "============================================================\n",
      "\n",
      "Cargando hiperparámetros desde data/mejores_hiperparametros.json...\n",
      "Trial 39\n",
      "Ganancia esperada en CV: $1,058,480,000\n",
      "\n",
      "Parámetros del modelo:\n",
      "  objective: binary\n",
      "  metric: custom\n",
      "  boosting_type: gbdt\n",
      "  first_metric_only: True\n",
      "  boost_from_average: True\n",
      "  feature_pre_filter: False\n",
      "  max_bin: 31\n",
      "  num_leaves: 91\n",
      "  learning_rate: 0.09904281706673441\n",
      "  min_data_in_leaf: 370\n",
      "  feature_fraction: 0.9029799021041279\n",
      "  bagging_fraction: 0.5198907300236562\n",
      "  seed: 550007\n",
      "  verbose: 1\n",
      "\n",
      "Creando dataset con X_train: (166406, 802)\n",
      "Entrenando modelo con 100 iteraciones...\n",
      "[LightGBM] [Info] Number of positive: 5284, number of negative: 161122\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.210480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20569\n",
      "[LightGBM] [Info] Number of data points in the train set: 166406, number of used features: 802\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031754 -> initscore=-3.417463\n",
      "[LightGBM] [Info] Start training from score -3.417463\n",
      "✅ Modelo entrenado exitosamente\n",
      "\n",
      "============================================================\n",
      "EVALUANDO EN TEST\n",
      "============================================================\n",
      "Generando predicciones en X_test: (163418, 802)\n",
      "Calculando ganancia acumulada...\n",
      "\n",
      "📊 RESULTADOS EN TEST:\n",
      "  Ganancia máxima: $406,560,000\n",
      "  N° de envíos óptimo: 10,712\n",
      "  Threshold óptimo: 0.013498\n",
      "  % de la base: 6.55%\n",
      "\n",
      "📈 GANANCIA POR CANTIDAD DE ENVÍOS:\n",
      "  Top 1.0% (1,634 envíos): $220,120,000\n",
      "  Top 2.5% (4,085 envíos): $346,300,000\n",
      "  Top 5.0% (8,170 envíos): $395,800,000\n",
      "  Top 10.0% (16,341 envíos): $363,580,000\n",
      "\n",
      "🎯 CAPTURA DE BAJA+2:\n",
      "  Total BAJA+2: 1,131\n",
      "  Capturados: 776\n",
      "  Tasa: 68.61%\n",
      "\n",
      "✅ Resultados guardados\n",
      "✅ Modelo guardado\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS DE TRAIN - OPTIMIZADO PARA MEMORIA\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DATOS TRAIN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear pesos en df_train\n",
    "print(\"Creando pesos...\")\n",
    "df_train['clase_peso'] = 1.0\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 2. Convertir a numpy inmediatamente (más eficiente en memoria)\n",
    "print(\"Convirtiendo a numpy (float32)...\")\n",
    "X_train = df_train.drop([\"clase_ternaria\", \"clase_peso\"], axis=1).to_numpy().astype('float32')\n",
    "y_train = df_train[\"clase_ternaria\"].to_numpy()\n",
    "pesos_train = df_train[\"clase_peso\"].to_numpy().astype('float32')\n",
    "\n",
    "# Binarizar\n",
    "y_train_binaria = (y_train != \"CONTINUA\").astype('int8')\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train_binaria: {y_train_binaria.shape}, dtype: {y_train_binaria.dtype}\")\n",
    "print(f\"Clase positiva: {y_train_binaria.sum():,}\")\n",
    "print(f\"Clase negativa: {(y_train_binaria == 0).sum():,}\")\n",
    "\n",
    "# Liberar df_train de la memoria\n",
    "print(\"Liberando df_train de memoria...\")\n",
    "del df_train, y_train\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Datos TRAIN preparados y df_train liberado\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS DE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARANDO DATOS TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_test = df_test.drop(\"clase_ternaria\", axis=1).to_numpy().astype('float32')\n",
    "y_test = df_test[\"clase_ternaria\"].to_numpy()\n",
    "\n",
    "print(f\"X_test: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Liberar df_test si no lo necesitás más\n",
    "print(\"Liberando df_test de memoria...\")\n",
    "del df_test\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Datos TEST preparados\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR MÉTRICA PERSONALIZADA DE GANANCIA\n",
    "# ============================================================\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "def ganancia_lgb(y_pred, data):\n",
    "    \"\"\"Métrica personalizada de ganancia para LightGBM.\"\"\"\n",
    "    weight = data.get_weight()\n",
    "    \n",
    "    # Calcular ganancia para cada predicción\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - costo_estimulo\n",
    "    \n",
    "    # Ordenar por predicción descendente\n",
    "    indices = np.argsort(-y_pred)\n",
    "    ganancia_ordenada = ganancia[indices]\n",
    "    \n",
    "    # Calcular ganancia acumulada máxima\n",
    "    ganancia_acum = np.cumsum(ganancia_ordenada)\n",
    "    max_ganancia = np.max(ganancia_acum)\n",
    "    \n",
    "    return 'ganancia', max_ganancia, True\n",
    "\n",
    "# ============================================================\n",
    "# ENTRENAR CON TRAIN Y EVALUAR EN TEST\n",
    "# ============================================================\n",
    "\n",
    "def entrenar_modelo_test(mejores_params_path='data/mejores_hiperparametros2.json'):\n",
    "    \"\"\"Entrena el modelo con df_train usando la métrica de ganancia.\"\"\"\n",
    "    \n",
    "    print(f\"\\nCargando hiperparámetros desde {mejores_params_path}...\")\n",
    "    with open(mejores_params_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    config = data[0] if isinstance(data, list) else data\n",
    "    \n",
    "    print(f\"Trial {config['trial_number']}\")\n",
    "    print(f\"Ganancia esperada en CV: ${config['value']:,.0f}\")\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': config['params']['num_leaves'],\n",
    "        'learning_rate': config['params']['learning_rate'],\n",
    "        'min_data_in_leaf': config['params']['min_data_in_leaf'],\n",
    "        'feature_fraction': config['params']['feature_fraction'],\n",
    "        'bagging_fraction': config['params']['bagging_fraction'],\n",
    "        'seed': SEMILLAS[0],\n",
    "        'verbose': 1\n",
    "    }\n",
    "    \n",
    "    print(\"\\nParámetros del modelo:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Crear dataset (free_raw_data=True para ahorrar memoria)\n",
    "    print(f\"\\nCreando dataset con X_train: {X_train.shape}\")\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                             label=y_train_binaria,\n",
    "                             weight=pesos_train,\n",
    "                             free_raw_data=False)  # Cambiar a True si sigue fallando\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(f\"Entrenando modelo con {config['best_iter']} iteraciones...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=config['best_iter'],\n",
    "        feval=ganancia_lgb,\n",
    "        callbacks=[lgb.log_evaluation(period=50)]\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Modelo entrenado exitosamente\")\n",
    "    \n",
    "    # Liberar train_data\n",
    "    del train_data\n",
    "    gc.collect()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "\n",
    "def calcular_ganancia_test(model, X_test, y_test):\n",
    "    \"\"\"Calcula la ganancia en TEST y encuentra el umbral óptimo.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUANDO EN TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Generando predicciones en X_test: {X_test.shape}\")\n",
    "    y_test_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    indices_ordenados = np.argsort(-y_test_pred_prob)\n",
    "    y_test_sorted = y_test[indices_ordenados]\n",
    "    \n",
    "    print(\"Calculando ganancia acumulada...\")\n",
    "    ganancia_cum = np.cumsum([\n",
    "        (ganancia_acierto if y == \"BAJA+2\" else -costo_estimulo)\n",
    "        for y in y_test_sorted\n",
    "    ])\n",
    "    \n",
    "    max_ganancia_idx = np.argmax(ganancia_cum)\n",
    "    max_ganancia = ganancia_cum[max_ganancia_idx]\n",
    "    n_envios_optimo = max_ganancia_idx + 1\n",
    "    threshold_optimo = y_test_pred_prob[indices_ordenados[max_ganancia_idx]]\n",
    "    \n",
    "    print(f\"\\n📊 RESULTADOS EN TEST:\")\n",
    "    print(f\"  Ganancia máxima: ${max_ganancia:,.0f}\")\n",
    "    print(f\"  N° de envíos óptimo: {n_envios_optimo:,}\")\n",
    "    print(f\"  Threshold óptimo: {threshold_optimo:.6f}\")\n",
    "    print(f\"  % de la base: {n_envios_optimo / len(y_test) * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n📈 GANANCIA POR CANTIDAD DE ENVÍOS:\")\n",
    "    for percentil in [0.01, 0.025, 0.05, 0.10]:\n",
    "        n = int(len(y_test) * percentil)\n",
    "        ganancia_n = ganancia_cum[n-1] if n > 0 else 0\n",
    "        print(f\"  Top {percentil*100:.1f}% ({n:,} envíos): ${ganancia_n:,.0f}\")\n",
    "    \n",
    "    n_baja2_total = (y_test == \"BAJA+2\").sum()\n",
    "    n_baja2_capturados = (y_test_sorted[:n_envios_optimo] == \"BAJA+2\").sum()\n",
    "    print(f\"\\n🎯 CAPTURA DE BAJA+2:\")\n",
    "    print(f\"  Total BAJA+2: {n_baja2_total:,}\")\n",
    "    print(f\"  Capturados: {n_baja2_capturados:,}\")\n",
    "    print(f\"  Tasa: {n_baja2_capturados / n_baja2_total * 100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'ganancia_maxima': max_ganancia,\n",
    "        'n_envios_optimo': n_envios_optimo,\n",
    "        'threshold_optimo': threshold_optimo,\n",
    "        'ganancia_acumulada': ganancia_cum,\n",
    "        'probabilidades_ordenadas': y_test_pred_prob[indices_ordenados],\n",
    "        'y_test_sorted': y_test_sorted,\n",
    "        'n_baja2_capturados': n_baja2_capturados,\n",
    "        'n_baja2_total': n_baja2_total\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FLUJO COMPLETO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO CON TRAIN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_test, config = entrenar_modelo_test('data/mejores_hiperparametros.json')\n",
    "\n",
    "resultados_test = calcular_ganancia_test(model_test, X_test, y_test)\n",
    "\n",
    "with open('data/resultados_test.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'ganancia_maxima': float(resultados_test['ganancia_maxima']),\n",
    "        'n_envios_optimo': int(resultados_test['n_envios_optimo']),\n",
    "        'threshold_optimo': float(resultados_test['threshold_optimo']),\n",
    "        'n_baja2_capturados': int(resultados_test['n_baja2_capturados']),\n",
    "        'n_baja2_total': int(resultados_test['n_baja2_total'])\n",
    "    }, f, indent=4)\n",
    "\n",
    "print(\"\\n✅ Resultados guardados\")\n",
    "\n",
    "model_test.save_model('data/modelo_train_test2.txt')\n",
    "print(\"✅ Modelo guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73bd47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Feature  Importance\n",
      "107                          ctrx_quarter    0.048973\n",
      "365                      ctrx_quarter_max    0.045724\n",
      "364                      ctrx_quarter_min    0.034558\n",
      "252                      cpayroll_trx_min    0.033572\n",
      "18                           mcaja_ahorro    0.032253\n",
      "173                   mpasivos_margen_max    0.032014\n",
      "52                               mpayroll    0.031691\n",
      "254                          mpayroll_min    0.028546\n",
      "11                        mpasivos_margen    0.027750\n",
      "51                           cpayroll_trx    0.027207\n",
      "253                      cpayroll_trx_max    0.019877\n",
      "28                  mtarjeta_visa_consumo    0.019612\n",
      "186                      mcaja_ahorro_min    0.018973\n",
      "172                   mpasivos_margen_min    0.018673\n",
      "187                      mcaja_ahorro_max    0.017311\n",
      "255                          mpayroll_max    0.017055\n",
      "195                    mcuentas_saldo_max    0.015716\n",
      "22                         mcuentas_saldo    0.015674\n",
      "25                          mautoservicio    0.015595\n",
      "199     ctarjeta_debito_transacciones_max    0.015442\n",
      "206             mtarjeta_visa_consumo_min    0.014418\n",
      "24          ctarjeta_debito_transacciones    0.014350\n",
      "138                      Visa_msaldopesos    0.013054\n",
      "137                      Visa_msaldototal    0.013000\n",
      "201                     mautoservicio_max    0.012123\n",
      "27            ctarjeta_visa_transacciones    0.010852\n",
      "147                      Visa_mpagospesos    0.010591\n",
      "421                  Visa_msaldototal_max    0.008991\n",
      "200                     mautoservicio_min    0.008690\n",
      "595  mcomisiones_mantenimiento_diff_prev2    0.008158\n",
      "204       ctarjeta_visa_transacciones_min    0.008073\n",
      "423                  Visa_msaldopesos_max    0.007895\n",
      "198     ctarjeta_debito_transacciones_min    0.007839\n",
      "205       ctarjeta_visa_transacciones_max    0.007837\n",
      "594   mcomisiones_mantenimiento_diff_prev    0.007496\n",
      "216             mprestamos_personales_min    0.007437\n",
      "440                  Visa_mpagospesos_min    0.007399\n",
      "73                      ccomisiones_otras    0.007130\n",
      "207             mtarjeta_visa_consumo_max    0.007008\n",
      "194                    mcuentas_saldo_min    0.006986\n",
      "319          cextraccion_autoservicio_max    0.006977\n",
      "593  ccomisiones_mantenimiento_diff_prev2    0.005807\n",
      "33                  mprestamos_personales    0.005749\n",
      "453                  Visa_mpagominimo_max    0.005447\n",
      "321          mextraccion_autoservicio_max    0.005405\n",
      "422                  Visa_msaldopesos_min    0.005121\n",
      "750     Visa_cadelantosefectivo_diff_prev    0.004944\n",
      "32                  cprestamos_personales    0.004810\n",
      "153                      Visa_mpagominimo    0.004774\n",
      "415                       Visa_status_max    0.004755\n",
      "420                  Visa_msaldototal_min    0.004738\n",
      "143                   Visa_madelantopesos    0.004650\n",
      "217             mprestamos_personales_max    0.004388\n",
      "728       Visa_mconsumosdolares_diff_prev    0.004314\n",
      "293         ccomisiones_mantenimiento_max    0.004271\n",
      "554                    mpayroll_diff_prev    0.004228\n",
      "214             cprestamos_personales_min    0.004015\n",
      "296                 ccomisiones_otras_min    0.004013\n",
      "81              mtransferencias_recibidas    0.003983\n",
      "592   ccomisiones_mantenimiento_diff_prev    0.003917\n"
     ]
    }
   ],
   "source": [
    "#lista de feature importances y porcentajes \n",
    "\n",
    "importances = model_opt.feature_importances_\n",
    "feature_names = X.columns   \n",
    "# Crear un DataFrame para visualizar las importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "print(importance_df.sort_values(by='Importance', ascending=False).head(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b860e",
   "metadata": {},
   "source": [
    "## Canaritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de0fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326527, 955)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Canaritos rf en mes train\n",
    "#uso esta semilla para los canaritos\n",
    "# np.random.seed(102191)\n",
    "\n",
    "# # Agregar 200 columnas aleatorias uniformes entre 0 y 1\n",
    "# for i in range(1, 201):\n",
    "#     df_filtrado = df_filtrado.with_columns(\n",
    "#         pl.Series(f\"canarito_{i}\", np.random.rand(df_filtrado.height))\n",
    "#     )\n",
    "\n",
    "# df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtrar train\n",
    "# X = df_filtrado.filter(pl.col(\"foto_mes\") == mes_train)\n",
    "# y = X[\"clase_ternaria\"]\n",
    "# X = X.drop(\"clase_ternaria\")\n",
    "\n",
    "# # Filtrar validación/futuro\n",
    "# X_futuro = df_filtrado.filter(pl.col(\"foto_mes\") == mes_test)\n",
    "# y_futuro = X_futuro[\"clase_ternaria\"]\n",
    "# X_futuro = X_futuro.drop(\"clase_ternaria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancia de modelo Opt: 294620000.0\n"
     ]
    }
   ],
   "source": [
    "# #Parametros optimizados\n",
    "# param_opt = {'criterion': 'entropy',\n",
    "#              'n_estimators': 100,\n",
    "#              'max_depth': 20,\n",
    "#              'min_samples_split': 80,\n",
    "#              'min_samples_leaf': 40,\n",
    "#              'max_leaf_nodes': 13}\n",
    "\n",
    "# model_opt = RandomForestClassifier(random_state=SEMILLAS[0], **param_opt)\n",
    "\n",
    "# model_opt.fit(X, y)\n",
    "# y_pred_opt = model_opt.predict_proba(X_futuro)\n",
    "# print(f\"Ganancia de modelo Opt: {ganancia_prob(y_pred_opt, y_futuro)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Feature  Importance\n",
      "187                  mcaja_ahorro_max    0.049571\n",
      "107                      ctrx_quarter    0.041316\n",
      "364                  ctrx_quarter_min    0.036957\n",
      "18                       mcaja_ahorro    0.032666\n",
      "52                           mpayroll    0.031583\n",
      "..                                ...         ...\n",
      "516   mprestamos_personales_diff_prev    0.000556\n",
      "465          mrentabilidad_diff_prev2    0.000524\n",
      "732     Visa_madelantopesos_diff_prev    0.000523\n",
      "507  mtarjeta_visa_consumo_diff_prev2    0.000517\n",
      "715            Visa_status_diff_prev2    0.000507\n",
      "\n",
      "[160 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# #lista de feature importances y porcentajes \n",
    "\n",
    "# importances = model_opt.feature_importances_\n",
    "# feature_names = X.columns   \n",
    "# # Crear un DataFrame para visualizar las importancias\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Importance': importances\n",
    "# })\n",
    "# print(importance_df.sort_values(by='Importance', ascending=False).head(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec84b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de variables 'canarito' en el Top 160: 13\n"
     ]
    }
   ],
   "source": [
    "# # Tomamos las 160 variables más importantes\n",
    "# top_features = importance_df.head(400)\n",
    "\n",
    "# # Contar cuántas tienen el prefijo 'canarito'\n",
    "# canarito_count = top_features['Feature'].str.startswith(\"canarito\").sum()\n",
    "\n",
    "# print(f\"Cantidad de variables 'canarito' en el Top 160: {canarito_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición media de los canaritos: 816.92\n"
     ]
    }
   ],
   "source": [
    "# # Asegurar que está ordenado por importancia descendente\n",
    "# importance_df = importance_df.sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# # Agregar columna con la posición\n",
    "# importance_df[\"Rank\"] = importance_df.index + 1\n",
    "\n",
    "# # Filtrar solo las variables 'canarito'\n",
    "# canaritos = importance_df[importance_df[\"Feature\"].str.startswith(\"canarito\")]\n",
    "\n",
    "# # Calcular posición media\n",
    "# pos_media_canaritos = canaritos[\"Rank\"].mean()\n",
    "\n",
    "# print(f\"Posición media de los canaritos: {pos_media_canaritos:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ad455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición media de las variables 'canarito': 816.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Gráfico\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(canaritos[\"Rank\"], bins=20)\n",
    "# plt.axvline(pos_media_canaritos, color='red', linestyle='--', label=f\"Media: {pos_media_canaritos:.1f}\")\n",
    "# plt.title(\"Distribución de las posiciones de variables 'canarito' en el ranking de importancia\")\n",
    "# plt.xlabel(\"Posición (1 = más importante)\")\n",
    "# plt.ylabel(\"Cantidad de canaritos\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Posición media de las variables 'canarito': {pos_media_canaritos:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138f472",
   "metadata": {},
   "source": [
    "#Ganancia modelo clase 211 MARS sin nada\n",
    "Ganancia modelo optimizaod acá, 331 mars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a435b72",
   "metadata": {},
   "source": [
    "## Entrenar Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo entrenado sólo con 1 2 y 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa252171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo guardado...\n",
      "✅ Modelo cargado exitosamente\n",
      "\n",
      "============================================================\n",
      "PREDICCIONES PARA KAGGLE\n",
      "============================================================\n",
      "Cargando número óptimo de envíos...\n",
      "Número óptimo de envíos: 10,712\n",
      "\n",
      "Preparando datos de Kaggle...\n",
      "Datos de Kaggle: (164313, 802)\n",
      "Generando predicciones...\n",
      "Seleccionando top 10,712 clientes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json \n",
    "# ============================================================\n",
    "# CARGAR MODELO GUARDADO\n",
    "# ============================================================\n",
    "\n",
    "print(\"Cargando modelo guardado...\")\n",
    "model_test = lgb.Booster(model_file='data/modelo_train_test.txt')\n",
    "print(\"✅ Modelo cargado exitosamente\")\n",
    "\n",
    "# ============================================================\n",
    "# PREDECIR EN KAGGLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICCIONES PARA KAGGLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar el número óptimo de envíos\n",
    "print(\"Cargando número óptimo de envíos...\")\n",
    "with open('data/resultados_test.json', 'r') as f:\n",
    "    resultados_test = json.load(f)\n",
    "\n",
    "n_envios_optimo = resultados_test['n_envios_optimo']\n",
    "print(f\"Número óptimo de envíos: {n_envios_optimo:,}\")\n",
    "\n",
    "# Preparar datos de Kaggle\n",
    "print(\"\\nPreparando datos de Kaggle...\")\n",
    "X_kaggle = df_kaggle.drop(\"clase_ternaria\", axis=1).to_numpy().astype('float32')\n",
    "clientes_kaggle = df_kaggle[\"numero_de_cliente\"].to_numpy()\n",
    "\n",
    "print(f\"Datos de Kaggle: {X_kaggle.shape}\")\n",
    "\n",
    "# Predicciones probabilísticas\n",
    "print(\"Generando predicciones...\")\n",
    "y_pred_prob = model_test.predict(X_kaggle)\n",
    "\n",
    "# Seleccionar top N clientes\n",
    "print(f\"Seleccionando top {n_envios_optimo:,} clientes...\")\n",
    "indices_top = np.argsort(-y_pred_prob)[:n_envios_optimo]\n",
    "\n",
    "# Crear predicción binaria\n",
    "y_pred_bin = np.zeros(len(y_pred_prob), dtype=int)\n",
    "y_pred_bin[indices_top] = 1\n",
    "\n",
    "# Crear submission\n",
    "submission = pd.DataFrame({\n",
    "    \"numero_de_cliente\": clientes_kaggle,\n",
    "    \"Predicted\": y_pred_bin\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eafd001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Archivo guardado: 'data/predicciones_kaggle.csv'\n",
      "Total registros: 164,313\n",
      "Predicciones positivas (1): 10,712\n",
      "Predicciones negativas (0): 153,601\n",
      "\n",
      "📄 Primeras filas:\n",
      "   numero_de_cliente  Predicted\n",
      "0          433987585          0\n",
      "1          434200463          0\n",
      "2          434285203          0\n",
      "3          434436672          0\n",
      "4          434468833          0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar\n",
    "submission.to_csv(\"data/predicciones_kaggle.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ Archivo guardado: 'data/predicciones_kaggle.csv'\")\n",
    "print(f\"Total registros: {len(submission):,}\")\n",
    "print(f\"Predicciones positivas (1): {y_pred_bin.sum():,}\")\n",
    "print(f\"Predicciones negativas (0): {(y_pred_bin == 0).sum():,}\")\n",
    "\n",
    "print(\"\\n📄 Primeras filas:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e2cad",
   "metadata": {},
   "source": [
    "## Modelo entrenado con 01..04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARANDO DATOS: TRAIN + TEST COMBINADOS\n",
      "============================================================\n",
      "Creando pesos en df_train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flor\\AppData\\Local\\Temp\\ipykernel_2764\\1124868333.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train['clase_peso'] = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando pesos en df_test...\n",
      "Concatenando df_train y df_test...\n",
      "df_train: (166406, 804)\n",
      "df_test: (163418, 804)\n",
      "df_full: (329824, 804)\n",
      "\n",
      "Convirtiendo a numpy (float32)...\n",
      "X_full: (329824, 801), dtype: float32\n",
      "y_full_binaria: (329824,), dtype: int8\n",
      "Clase positiva: 7,369\n",
      "Clase negativa: 322,455\n",
      "\n",
      "Liberando df_train, df_test, df_full de memoria...\n",
      "✅ Datos preparados\n",
      "\n",
      "============================================================\n",
      "ENTRENAMIENTO MODELO FINAL (TRAIN + TEST)\n",
      "============================================================\n",
      "Cargando hiperparámetros...\n",
      "Trial 39\n",
      "Ganancia esperada: $1,058,480,000\n",
      "Iteraciones: 100\n",
      "\n",
      "Parámetros del modelo:\n",
      "  objective: binary\n",
      "  metric: custom\n",
      "  boosting_type: gbdt\n",
      "  first_metric_only: True\n",
      "  boost_from_average: True\n",
      "  feature_pre_filter: False\n",
      "  max_bin: 31\n",
      "  num_leaves: 91\n",
      "  learning_rate: 0.09904281706673441\n",
      "  min_data_in_leaf: 370\n",
      "  feature_fraction: 0.9029799021041279\n",
      "  bagging_fraction: 0.5198907300236562\n",
      "  seed: 550007\n",
      "  verbose: 1\n",
      "\n",
      "Creando dataset con X_full: (329824, 801)\n",
      "Entrenando modelo final con 100 iteraciones...\n",
      "[LightGBM] [Info] Number of positive: 7369, number of negative: 322455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.517689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20661\n",
      "[LightGBM] [Info] Number of data points in the train set: 329824, number of used features: 801\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.022343 -> initscore=-3.778666\n",
      "[LightGBM] [Info] Start training from score -3.778666\n",
      "✅ Modelo final entrenado exitosamente\n",
      "✅ Modelo guardado en 'data/modelo_final_train_test.txt'\n",
      "\n",
      "============================================================\n",
      "PREDICCIONES PARA KAGGLE\n",
      "============================================================\n",
      "\n",
      "Leyendo df_kaggle...\n",
      "df_kaggle: (164313, 803)\n",
      "Tipo de numero_de_cliente: int64\n",
      "clientes_kaggle: dtype=int64\n",
      "X_kaggle: (164313, 801), dtype=float32\n",
      "\n",
      "Generando predicciones...\n",
      "Predicciones generadas: 164,313\n",
      "Seleccionando top 12,000 clientes...\n",
      "\n",
      "Tipos en submission:\n",
      "  numero_de_cliente: int64\n",
      "  Predicted: int8\n",
      "\n",
      "✅ Archivo guardado: 'data/predicciones_kaggle_final.csv'\n",
      "\n",
      "📊 RESUMEN:\n",
      "  Total registros: 164,313\n",
      "  Predicciones positivas (1): 12,000\n",
      "  Predicciones negativas (0): 152,313\n",
      "  % positivos: 7.30%\n",
      "\n",
      "📄 Primeras filas:\n",
      "   numero_de_cliente  Predicted\n",
      "0          433987585          0\n",
      "1          434200463          1\n",
      "2          434285203          0\n",
      "3          434436672          0\n",
      "4          434468833          0\n",
      "5          434500404          0\n",
      "6          434626792          0\n",
      "7          434672369          0\n",
      "8          434687467          0\n",
      "9          434694905          0\n",
      "\n",
      "Verificación de IDs (primeros 5):\n",
      "0    433987585\n",
      "1    434200463\n",
      "2    434285203\n",
      "3    434436672\n",
      "4    434468833\n",
      "Name: numero_de_cliente, dtype: int64\n",
      "\n",
      "🎉 Modelo final entrenado y predicciones listas para Kaggle!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS: TRAIN + TEST COMBINADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DATOS: TRAIN + TEST COMBINADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear pesos en df_train\n",
    "print(\"Creando pesos en df_train...\")\n",
    "df_train['clase_peso'] = 1.0\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 2. Crear pesos en df_test\n",
    "print(\"Creando pesos en df_test...\")\n",
    "df_test['clase_peso'] = 1.0\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 3. Concatenar df_train y df_test\n",
    "print(\"Concatenando df_train y df_test...\")\n",
    "df_full = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")\n",
    "print(f\"df_full: {df_full.shape}\")\n",
    "\n",
    "# 4. Convertir a numpy (optimizado) - SIN numero_de_cliente\n",
    "print(\"\\nConvirtiendo a numpy (float32)...\")\n",
    "X_full = df_full.drop([\"clase_ternaria\", \"clase_peso\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "y_full = df_full[\"clase_ternaria\"].to_numpy()\n",
    "pesos_full = df_full[\"clase_peso\"].to_numpy().astype('float32')\n",
    "\n",
    "# Binarizar\n",
    "y_full_binaria = (y_full != \"CONTINUA\").astype('int8')\n",
    "\n",
    "print(f\"X_full: {X_full.shape}, dtype: {X_full.dtype}\")\n",
    "print(f\"y_full_binaria: {y_full_binaria.shape}, dtype: {y_full_binaria.dtype}\")\n",
    "print(f\"Clase positiva: {y_full_binaria.sum():,}\")\n",
    "print(f\"Clase negativa: {(y_full_binaria == 0).sum():,}\")\n",
    "\n",
    "# Liberar memoria\n",
    "print(\"\\nLiberando df_train, df_test, df_full de memoria...\")\n",
    "del df_train, df_test, df_full, y_full\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Datos preparados\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR MÉTRICA PERSONALIZADA DE GANANCIA\n",
    "# ============================================================\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "def ganancia_lgb(y_pred, data):\n",
    "    \"\"\"Métrica personalizada de ganancia para LightGBM.\"\"\"\n",
    "    weight = data.get_weight()\n",
    "    \n",
    "    # Calcular ganancia para cada predicción\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - costo_estimulo\n",
    "    \n",
    "    # Ordenar por predicción descendente\n",
    "    indices = np.argsort(-y_pred)\n",
    "    ganancia_ordenada = ganancia[indices]\n",
    "    \n",
    "    # Calcular ganancia acumulada máxima\n",
    "    ganancia_acum = np.cumsum(ganancia_ordenada)\n",
    "    max_ganancia = np.max(ganancia_acum)\n",
    "    \n",
    "    return 'ganancia', max_ganancia, True\n",
    "\n",
    "# ============================================================\n",
    "# ENTRENAR MODELO FINAL CON TRAIN + TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO MODELO FINAL (TRAIN + TEST)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar mejores hiperparámetros\n",
    "print(\"Cargando hiperparámetros...\")\n",
    "with open('data/mejores_hiperparametros.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "config = data[0] if isinstance(data, list) else data\n",
    "\n",
    "print(f\"Trial {config['trial_number']}\")\n",
    "print(f\"Ganancia esperada: ${config['value']:,.0f}\")\n",
    "print(f\"Iteraciones: {config['best_iter']}\")\n",
    "\n",
    "# Configurar parámetros\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'custom',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': config['params']['num_leaves'],\n",
    "    'learning_rate': config['params']['learning_rate'],\n",
    "    'min_data_in_leaf': config['params']['min_data_in_leaf'],\n",
    "    'feature_fraction': config['params']['feature_fraction'],\n",
    "    'bagging_fraction': config['params']['bagging_fraction'],\n",
    "    'seed': SEMILLAS[0],\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "print(\"\\nParámetros del modelo:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Crear dataset completo\n",
    "print(f\"\\nCreando dataset con X_full: {X_full.shape}\")\n",
    "full_data = lgb.Dataset(X_full,\n",
    "                        label=y_full_binaria,\n",
    "                        weight=pesos_full)\n",
    "\n",
    "# Entrenar modelo final\n",
    "print(f\"Entrenando modelo final con {config['best_iter']} iteraciones...\")\n",
    "model_final = lgb.train(\n",
    "    params,\n",
    "    full_data,\n",
    "    num_boost_round=config['best_iter'],\n",
    "    feval=ganancia,\n",
    "    callbacks=[lgb.log_evaluation(period=50)]\n",
    ")\n",
    "\n",
    "print(\"✅ Modelo final entrenado exitosamente\")\n",
    "\n",
    "# Guardar modelo final\n",
    "model_final.save_model('data/predicciones/modelo_final_train_test.txt')\n",
    "print(\"✅ Modelo guardado en 'data/modelo_final_train_test.txt'\")\n",
    "\n",
    "# Liberar memoria\n",
    "del full_data, X_full, y_full_binaria, pesos_full\n",
    "gc.collect()\n",
    "\n",
    "# ============================================================\n",
    "# PREDECIR EN KAGGLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICCIONES PARA KAGGLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cargar número óptimo de envíos\n",
    "# with open('data/resultados_test.json', 'r') as f:\n",
    "#     resultados_test = json.load(f)\n",
    "\n",
    "# n_envios_optimo = resultados_test['n_envios_optimo']\n",
    "n_envios_optimo = 12000  # Valor fijo \n",
    "# print(f\"Número óptimo de envíos: {n_envios_optimo:,}\")\n",
    "\n",
    "\n",
    "# Leer df_kaggle con tipos optimizados\n",
    "print(\"\\nLeyendo df_kaggle...\")\n",
    "# Primero identificar las columnas\n",
    "columnas = pd.read_csv(\"data/df_kaggle.csv\", nrows=0).columns.tolist()\n",
    "\n",
    "# Crear diccionario de tipos: float32 para todas EXCEPTO numero_de_cliente\n",
    "dtypes = {col: 'float32' for col in columnas if col not in ['numero_de_cliente', 'clase_ternaria']}\n",
    "# numero_de_cliente se mantiene como int64/float64 por defecto\n",
    "\n",
    "df_kaggle = pd.read_csv(\n",
    "    \"data/df_kaggle.csv\",\n",
    "    dtype=dtypes,\n",
    "    low_memory=True\n",
    ")\n",
    "\n",
    "print(f\"df_kaggle: {df_kaggle.shape}\")\n",
    "print(f\"Tipo de numero_de_cliente: {df_kaggle['numero_de_cliente'].dtype}\")\n",
    "\n",
    "# Preparar datos - GUARDAMOS numero_de_cliente SIN convertir\n",
    "clientes_kaggle = df_kaggle[\"numero_de_cliente\"].values  # Mantiene tipo original\n",
    "X_kaggle = df_kaggle.drop([\"clase_ternaria\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "\n",
    "print(f\"clientes_kaggle: dtype={clientes_kaggle.dtype}\")\n",
    "print(f\"X_kaggle: {X_kaggle.shape}, dtype={X_kaggle.dtype}\")\n",
    "\n",
    "del df_kaggle\n",
    "gc.collect()\n",
    "\n",
    "# Predecir\n",
    "print(\"\\nGenerando predicciones...\")\n",
    "y_pred_prob = model_final.predict(X_kaggle)\n",
    "\n",
    "print(f\"Predicciones generadas: {len(y_pred_prob):,}\")\n",
    "\n",
    "# Seleccionar top N clientes\n",
    "print(f\"Seleccionando top {n_envios_optimo:,} clientes...\")\n",
    "indices_top = np.argsort(-y_pred_prob)[:n_envios_optimo]\n",
    "\n",
    "# Crear predicción binaria\n",
    "y_pred_bin = np.zeros(len(y_pred_prob), dtype='int8')\n",
    "y_pred_bin[indices_top] = 1\n",
    "\n",
    "# Crear submission - numero_de_cliente mantiene su tipo original\n",
    "submission = pd.DataFrame({\n",
    "    \"numero_de_cliente\": clientes_kaggle,  # Tipo original preservado\n",
    "    \"Predicted\": y_pred_bin\n",
    "})\n",
    "\n",
    "# Verificar tipos\n",
    "print(f\"\\nTipos en submission:\")\n",
    "print(f\"  numero_de_cliente: {submission['numero_de_cliente'].dtype}\")\n",
    "print(f\"  Predicted: {submission['Predicted'].dtype}\")\n",
    "\n",
    "# Guardar\n",
    "submission.to_csv(\"data/predicciones_kaggle_final.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✅ Archivo guardado: 'data/predicciones_kaggle_final.csv'\")\n",
    "print(f\"\\n📊 RESUMEN:\")\n",
    "print(f\"  Total registros: {len(submission):,}\")\n",
    "print(f\"  Predicciones positivas (1): {y_pred_bin.sum():,}\")\n",
    "print(f\"  Predicciones negativas (0): {(y_pred_bin == 0).sum():,}\")\n",
    "print(f\"  % positivos: {y_pred_bin.sum() / len(submission) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n📄 Primeras filas:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Verificar que los IDs se mantienen correctos\n",
    "print(\"\\nVerificación de IDs (primeros 5):\")\n",
    "print(submission['numero_de_cliente'].head())\n",
    "\n",
    "print(\"\\n🎉 Modelo final entrenado y predicciones listas para Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899a612",
   "metadata": {},
   "source": [
    "Modelo multiples semillas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e168b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARANDO DATOS: TRAIN + TEST COMBINADOS\n",
      "============================================================\n",
      "Creando pesos en df_train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando pesos en df_test...\n",
      "Concatenando df_train y df_test...\n",
      "df_train: (5284, 804)\n",
      "df_test: (163418, 804)\n",
      "df_full: (168702, 804)\n",
      "\n",
      "Convirtiendo a numpy (float32)...\n",
      "X_full: (168702, 801), dtype: float32\n",
      "y_full_binaria: (168702,), dtype: int8\n",
      "Clase positiva: 7,369\n",
      "Clase negativa: 161,333\n",
      "\n",
      "Liberando df_train, df_test, df_full de memoria...\n",
      "✅ Datos preparados\n",
      "\n",
      "============================================================\n",
      "CARGANDO HIPERPARÁMETROS\n",
      "============================================================\n",
      "Trial 218\n",
      "Ganancia esperada: $1,235,980,000\n",
      "Iteraciones: 98\n",
      "\n",
      "============================================================\n",
      "ENTRENANDO 5 MODELOS (UNO POR SEMILLA)\n",
      "============================================================\n",
      "\n",
      "--- Modelo 1/5 - Semilla: 550007 ---\n",
      "Entrenando con 98 iteraciones...\n",
      "✅ Modelo guardado: 'data/predicciones/modelo_semilla_550007.txt'\n",
      "\n",
      "--- Modelo 2/5 - Semilla: 550019 ---\n",
      "Entrenando con 98 iteraciones...\n",
      "✅ Modelo guardado: 'data/predicciones/modelo_semilla_550019.txt'\n",
      "\n",
      "--- Modelo 3/5 - Semilla: 550031 ---\n",
      "Entrenando con 98 iteraciones...\n",
      "✅ Modelo guardado: 'data/predicciones/modelo_semilla_550031.txt'\n",
      "\n",
      "--- Modelo 4/5 - Semilla: 550033 ---\n",
      "Entrenando con 98 iteraciones...\n",
      "✅ Modelo guardado: 'data/predicciones/modelo_semilla_550033.txt'\n",
      "\n",
      "--- Modelo 5/5 - Semilla: 550047 ---\n",
      "Entrenando con 98 iteraciones...\n",
      "✅ Modelo guardado: 'data/predicciones/modelo_semilla_550047.txt'\n",
      "\n",
      "✅ 5 modelos entrenados exitosamente\n",
      "\n",
      "============================================================\n",
      "CARGANDO DF_KAGGLE Y PREDICIENDO\n",
      "============================================================\n",
      "Leyendo df_kaggle...\n",
      "df_kaggle: (164313, 803)\n",
      "Tipo de numero_de_cliente: int64\n",
      "X_kaggle: (164313, 801), dtype=float32\n",
      "\n",
      "============================================================\n",
      "GENERANDO PREDICCIONES CON CADA MODELO\n",
      "============================================================\n",
      "\n",
      "Modelo 1/5 - Semilla 550007\n",
      "Prediciendo...\n",
      "  Prob min: 0.000030\n",
      "  Prob max: 0.960012\n",
      "  Prob media: 0.012543\n",
      "\n",
      "Modelo 2/5 - Semilla 550019\n",
      "Prediciendo...\n",
      "  Prob min: 0.000043\n",
      "  Prob max: 0.947503\n",
      "  Prob media: 0.012301\n",
      "\n",
      "Modelo 3/5 - Semilla 550031\n",
      "Prediciendo...\n",
      "  Prob min: 0.000042\n",
      "  Prob max: 0.953945\n",
      "  Prob media: 0.013411\n",
      "\n",
      "Modelo 4/5 - Semilla 550033\n",
      "Prediciendo...\n",
      "  Prob min: 0.000036\n",
      "  Prob max: 0.946402\n",
      "  Prob media: 0.012876\n",
      "\n",
      "Modelo 5/5 - Semilla 550047\n",
      "Prediciendo...\n",
      "  Prob min: 0.000031\n",
      "  Prob max: 0.962155\n",
      "  Prob media: 0.013658\n",
      "\n",
      "============================================================\n",
      "PROMEDIANDO PROBABILIDADES\n",
      "============================================================\n",
      "Probabilidades promediadas:\n",
      "  Prob min: 0.000054\n",
      "  Prob max: 0.936881\n",
      "  Prob media: 0.012958\n",
      "\n",
      "✅ Probabilidades guardadas en 'data/predicciones/probabilidades_promedio.npy'\n",
      "\n",
      "============================================================\n",
      "BINARIZANDO PREDICCIONES\n",
      "============================================================\n",
      "Número de envíos: 12,300\n",
      "\n",
      "============================================================\n",
      "CREANDO SUBMISSION\n",
      "============================================================\n",
      "Tipos en submission:\n",
      "  numero_de_cliente: int64\n",
      "  Predicted: int8\n",
      "\n",
      "✅ Archivo guardado: 'data/predicciones_kaggle_ensemble_5semillas_12300_20251011_0946.csv'\n",
      "\n",
      "📊 RESUMEN:\n",
      "  Modelos entrenados: 5\n",
      "  Total registros: 164,313\n",
      "  Predicciones positivas (1): 12,300\n",
      "  Predicciones negativas (0): 152,013\n",
      "  % positivos: 7.49%\n",
      "\n",
      "📄 Primeras 10 filas:\n",
      "   numero_de_cliente  Predicted\n",
      "0          433987585          0\n",
      "1          434200463          1\n",
      "2          434285203          0\n",
      "3          434436672          0\n",
      "4          434468833          1\n",
      "5          434500404          0\n",
      "6          434626792          0\n",
      "7          434672369          0\n",
      "8          434687467          0\n",
      "9          434694905          0\n",
      "\n",
      "Verificación de IDs:\n",
      "  Primer ID: 433987585\n",
      "  Último ID: 951048415\n",
      "\n",
      "🎉 Ensemble de modelos completado - Predicciones listas para Kaggle!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================\n",
    "# PREPARAR DATOS: TRAIN + TEST COMBINADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARANDO DATOS: TRAIN + TEST COMBINADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Crear pesos en df_train\n",
    "print(\"Creando pesos en df_train...\")\n",
    "df_train['clase_peso'] = 1.0\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 2. Crear pesos en df_test\n",
    "print(\"Creando pesos en df_test...\")\n",
    "df_test['clase_peso'] = 1.0\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_test.loc[df_test['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "# 3. Concatenar df_train y df_test\n",
    "print(\"Concatenando df_train y df_test...\")\n",
    "df_full = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_test: {df_test.shape}\")\n",
    "print(f\"df_full: {df_full.shape}\")\n",
    "\n",
    "# 4. Convertir a numpy (optimizado) - SIN numero_de_cliente\n",
    "print(\"\\nConvirtiendo a numpy (float32)...\")\n",
    "X_full = df_full.drop([\"clase_ternaria\", \"clase_peso\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "y_full = df_full[\"clase_ternaria\"].to_numpy()\n",
    "pesos_full = df_full[\"clase_peso\"].to_numpy().astype('float32')\n",
    "\n",
    "# Binarizar\n",
    "y_full_binaria = (y_full != \"CONTINUA\").astype('int8')\n",
    "\n",
    "print(f\"X_full: {X_full.shape}, dtype: {X_full.dtype}\")\n",
    "print(f\"y_full_binaria: {y_full_binaria.shape}, dtype: {y_full_binaria.dtype}\")\n",
    "print(f\"Clase positiva: {y_full_binaria.sum():,}\")\n",
    "print(f\"Clase negativa: {(y_full_binaria == 0).sum():,}\")\n",
    "\n",
    "# Liberar memoria\n",
    "print(\"\\nLiberando df_train, df_test, df_full de memoria...\")\n",
    "del df_train, df_test, df_full, y_full\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Datos preparados\")\n",
    "\n",
    "# ============================================================\n",
    "# DEFINIR MÉTRICA PERSONALIZADA DE GANANCIA\n",
    "# ============================================================\n",
    "\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "\n",
    "def ganancia_lgb(y_pred, data):\n",
    "    \"\"\"Métrica personalizada de ganancia para LightGBM.\"\"\"\n",
    "    weight = data.get_weight()\n",
    "    \n",
    "    # Calcular ganancia para cada predicción\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - costo_estimulo\n",
    "    \n",
    "    # Ordenar por predicción descendente\n",
    "    indices = np.argsort(-y_pred)\n",
    "    ganancia_ordenada = ganancia[indices]\n",
    "    \n",
    "    # Calcular ganancia acumulada máxima\n",
    "    ganancia_acum = np.cumsum(ganancia_ordenada)\n",
    "    max_ganancia = np.max(ganancia_acum)\n",
    "    \n",
    "    return 'ganancia', max_ganancia, True\n",
    "\n",
    "# ============================================================\n",
    "# CARGAR HIPERPARÁMETROS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CARGANDO HIPERPARÁMETROS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('data/mejores_hiperparametros2.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "config = data[0] if isinstance(data, list) else data\n",
    "\n",
    "print(f\"Trial {config['trial_number']}\")\n",
    "print(f\"Ganancia esperada: ${config['value']:,.0f}\")\n",
    "print(f\"Iteraciones: {config['best_iter']}\")\n",
    "\n",
    "# ============================================================\n",
    "# ENTRENAR UN MODELO POR SEMILLA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ENTRENANDO {len(SEMILLAS)} MODELOS (UNO POR SEMILLA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "modelos = []\n",
    "\n",
    "for i, semilla in enumerate(SEMILLAS):\n",
    "    print(f\"\\n--- Modelo {i+1}/{len(SEMILLAS)} - Semilla: {semilla} ---\")\n",
    "    \n",
    "    # Configurar parámetros con la semilla correspondiente\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': config['params']['num_leaves'],\n",
    "        'learning_rate': config['params']['learning_rate'],\n",
    "        'min_data_in_leaf': config['params']['min_data_in_leaf'],\n",
    "        'feature_fraction': config['params']['feature_fraction'],\n",
    "        'bagging_fraction': config['params']['bagging_fraction'],\n",
    "        'seed': semilla,  # ✅ Cambiar semilla\n",
    "        'verbose': -1  # Silencioso para no saturar output\n",
    "    }\n",
    "    \n",
    "    # Crear dataset\n",
    "    full_data = lgb.Dataset(X_full,\n",
    "                            label=y_full_binaria,\n",
    "                            weight=pesos_full)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(f\"Entrenando con {config['best_iter']} iteraciones...\")\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        full_data,\n",
    "        num_boost_round=config['best_iter'],\n",
    "        feval=ganancia_lgb,\n",
    "        callbacks=[lgb.log_evaluation(period=0)]  # Sin logs\n",
    "    )\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model.save_model(f'data/predicciones/modelo_semilla_{semilla}.txt')\n",
    "    print(f\"✅ Modelo guardado: 'data/predicciones/modelo_semilla_{semilla}.txt'\")\n",
    "    \n",
    "    # Agregar a la lista\n",
    "    modelos.append(model)\n",
    "    \n",
    "    # Liberar memoria\n",
    "    del full_data\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n✅ {len(modelos)} modelos entrenados exitosamente\")\n",
    "\n",
    "# Liberar X_full de memoria\n",
    "del X_full, y_full_binaria, pesos_full\n",
    "gc.collect()\n",
    "\n",
    "# ============================================================\n",
    "# CARGAR DF_KAGGLE Y PREDECIR CON CADA MODELO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CARGANDO DF_KAGGLE Y PREDICIENDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leer df_kaggle con tipos optimizados\n",
    "print(\"Leyendo df_kaggle...\")\n",
    "columnas = pd.read_csv(\"data/df_kaggle.csv\", nrows=0).columns.tolist()\n",
    "\n",
    "# Crear diccionario de tipos: float32 para todas EXCEPTO numero_de_cliente\n",
    "dtypes = {col: 'float32' for col in columnas if col not in ['numero_de_cliente', 'clase_ternaria']}\n",
    "\n",
    "df_kaggle = pd.read_csv(\n",
    "    \"data/df_kaggle.csv\",\n",
    "    dtype=dtypes,\n",
    "    low_memory=True\n",
    ")\n",
    "\n",
    "print(f\"df_kaggle: {df_kaggle.shape}\")\n",
    "print(f\"Tipo de numero_de_cliente: {df_kaggle['numero_de_cliente'].dtype}\")\n",
    "\n",
    "# Preparar datos\n",
    "clientes_kaggle = df_kaggle[\"numero_de_cliente\"].values\n",
    "X_kaggle = df_kaggle.drop([\"clase_ternaria\", \"numero_de_cliente\"], axis=1).to_numpy().astype('float32')\n",
    "\n",
    "print(f\"X_kaggle: {X_kaggle.shape}, dtype={X_kaggle.dtype}\")\n",
    "\n",
    "del df_kaggle\n",
    "gc.collect()\n",
    "\n",
    "# ============================================================\n",
    "# PREDECIR CON CADA MODELO Y PROMEDIAR\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERANDO PREDICCIONES CON CADA MODELO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Inicializar array para acumular probabilidades\n",
    "probabilidades_acumuladas = np.zeros(len(X_kaggle), dtype='float64')\n",
    "\n",
    "for i, (model, semilla) in enumerate(zip(modelos, SEMILLAS)):\n",
    "    print(f\"\\nModelo {i+1}/{len(modelos)} - Semilla {semilla}\")\n",
    "    print(\"Prediciendo...\")\n",
    "    \n",
    "    y_pred_prob = model.predict(X_kaggle)\n",
    "    \n",
    "    print(f\"  Prob min: {y_pred_prob.min():.6f}\")\n",
    "    print(f\"  Prob max: {y_pred_prob.max():.6f}\")\n",
    "    print(f\"  Prob media: {y_pred_prob.mean():.6f}\")\n",
    "    \n",
    "    # Acumular probabilidades\n",
    "    probabilidades_acumuladas += y_pred_prob\n",
    "    \n",
    "    # Liberar modelo de memoria\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "# Promediar probabilidades\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROMEDIANDO PROBABILIDADES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_prob_promedio = probabilidades_acumuladas / len(SEMILLAS)\n",
    "\n",
    "print(f\"Probabilidades promediadas:\")\n",
    "print(f\"  Prob min: {y_pred_prob_promedio.min():.6f}\")\n",
    "print(f\"  Prob max: {y_pred_prob_promedio.max():.6f}\")\n",
    "print(f\"  Prob media: {y_pred_prob_promedio.mean():.6f}\")\n",
    "\n",
    "# Guardar probabilidades promediadas (opcional)\n",
    "np.save('data/predicciones/probabilidades_promedio.npy', y_pred_prob_promedio)\n",
    "print(\"\\n✅ Probabilidades guardadas en 'data/predicciones/probabilidades_promedio.npy'\")\n",
    "\n",
    "# ============================================================\n",
    "# BINARIZAR CON NÚMERO ÓPTIMO DE ENVÍOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARIZANDO PREDICCIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_envios_optimo = 12300\n",
    "print(f\"Número de envíos: {n_envios_optimo:,}\")\n",
    "\n",
    "# Seleccionar top N clientes\n",
    "indices_top = np.argsort(-y_pred_prob_promedio)[:n_envios_optimo]\n",
    "\n",
    "# Crear predicción binaria\n",
    "y_pred_bin = np.zeros(len(y_pred_prob_promedio), dtype='int8')\n",
    "y_pred_bin[indices_top] = 1\n",
    "\n",
    "# ============================================================\n",
    "# CREAR SUBMISSION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREANDO SUBMISSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"numero_de_cliente\": clientes_kaggle,\n",
    "    \"Predicted\": y_pred_bin\n",
    "})\n",
    "\n",
    "# Verificar tipos\n",
    "print(f\"Tipos en submission:\")\n",
    "print(f\"  numero_de_cliente: {submission['numero_de_cliente'].dtype}\")\n",
    "print(f\"  Predicted: {submission['Predicted'].dtype}\")\n",
    "# Obtener fecha y hora actual en formato YYYYMMDD_HHMM\n",
    "fecha = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Crear el nombre del archivo con fecha incluida\n",
    "filename = f\"data/predicciones_kaggle_ensemble_{len(SEMILLAS)}semillas_{n_envios_optimo}_{fecha}.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n✅ Archivo guardado: '{filename}'\")\n",
    "print(f\"\\n📊 RESUMEN:\")\n",
    "print(f\"  Modelos entrenados: {len(SEMILLAS)}\")\n",
    "print(f\"  Total registros: {len(submission):,}\")\n",
    "print(f\"  Predicciones positivas (1): {y_pred_bin.sum():,}\")\n",
    "print(f\"  Predicciones negativas (0): {(y_pred_bin == 0).sum():,}\")\n",
    "print(f\"  % positivos: {y_pred_bin.sum() / len(submission) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n📄 Primeras 10 filas:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\nVerificación de IDs:\")\n",
    "print(f\"  Primer ID: {submission['numero_de_cliente'].iloc[0]}\")\n",
    "print(f\"  Último ID: {submission['numero_de_cliente'].iloc[-1]}\")\n",
    "\n",
    "print(\"\\n🎉 Ensemble de modelos completado - Predicciones listas para Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831d497",
   "metadata": {},
   "source": [
    "## -4k era entrenado con 01..03 y predecir 06 con los mejores hiperparametros de mi primer corrida (30) con metric ganancia\n",
    "## -3k simil anterior pero modelo reentrenado con 01..04 con metric AUC \n",
    "## -3 K simil anterior pero modelo reentrenado con 01..04 con metric custom\n",
    "## -2 umbral fijo de 12k \n",
    "## 0 de 01 02 y 03 sólo los baja+1/2. \n",
    "\n",
    "## voy a probar con slopes. no me sirvió. solo con dl tampoco (aunque no optimicé hip para esto)\n",
    "\n",
    "## 2 con ensamble de semillas\n",
    "1 si dejo los continua de marzo\n",
    "4 con hiperparametros optimizados 500. hip2\n",
    "5 con num fijo de 12300. esto es con fe todo sin slopes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
