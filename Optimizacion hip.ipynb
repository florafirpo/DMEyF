{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330051ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,  _tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8028c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5967229744419456 GB\n"
     ]
    }
   ],
   "source": [
    "# print(os.path.getsize(\"data/df_confe.csv\") / (1024**3), \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897d6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer CSV completo\n",
    "data = pl.read_csv(\"data/competencia_01_fe_sinslope.csv\")\n",
    "\n",
    "#print(data.shape)        # filas, columnas\n",
    "#print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1171f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los meses deseados\n",
    "#df_filtrado = data.filter(\n",
    "#    (data[\"foto_mes\"] == 202103) | (data[\"foto_mes\"] == 202104)\n",
    "#)\n",
    "\n",
    "# Guardar en CSV\n",
    "#df_filtrado.write_csv(\"df_confe_ma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e652414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMILLAS = [550007, 550019, 550031, 550033, 550047]\n",
    "\n",
    "mes_train = 202103, 202102, 202101\n",
    "mes_test = 202104\n",
    "mes_kaggle = 202106\n",
    "ganancia_acierto = 780000\n",
    "costo_estimulo = 20000\n",
    "# ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe17535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo el mes de kaggle\n",
    "df_kaggle = data.filter(pl.col(\"foto_mes\") == mes_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f59165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164313, 803)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144184eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guRDAR csv kaggle\n",
    "df_kaggle.write_csv(\"data/df_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo el mes de train\n",
    "#df_train = data.filter(pl.col(\"foto_mes\").is_in(mes_train))\n",
    "\n",
    "# Filtrar solo el mes de test\n",
    "#df_test = data.filter(pl.col(\"foto_mes\") == mes_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39165b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar df_train en csv\n",
    "#df_train.write_csv(\"data/df_train_01_02_03.csv\")\n",
    "#df_test.write_csv(\"data/df_test_04.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a3b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/df_train_01_02_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36daa60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#tiene mi df_train la columna \"clase_ternaria\"?\n",
    "print(\"clase_ternaria\" in df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38450efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clase_peso'] = 1.0\n",
    "\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "df_train.loc[df_train['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a08b7d",
   "metadata": {},
   "source": [
    "#Optimización con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cc7fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (340753, 802) (340753,) (340753,)\n",
      "Validation: (146038, 802) (146038,) (146038,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar X e y\n",
    "X = df_train.drop([\"clase_ternaria\", \"clase_peso\"], axis=1)  # ✅ Sacamos también clase_peso\n",
    "y = df_train[\"clase_ternaria\"]\n",
    "pesos = df_train[\"clase_peso\"]  # ✅ Guardamos los pesos\n",
    "\n",
    "# Binarizar y\n",
    "y_binaria = (y != \"CONTINUA\").astype(int)\n",
    "\n",
    "# Split 70/30 (ahora incluimos los pesos)\n",
    "X_train, X_val, y_train, y_val, pesos_train, pesos_val = train_test_split(\n",
    "    X, y_binaria, pesos,  # ✅ Separamos X, y Y pesos\n",
    "    train_size=0.7,\n",
    "    random_state=42,\n",
    "    stratify=y_binaria\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape, pesos_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape, pesos_val.shape)\n",
    "\n",
    "# Ahora en el Dataset:\n",
    "train_data = lgb.Dataset(X_train,\n",
    "                          label=y_train,\n",
    "                          weight=pesos_train  # ✅ Usamos los pesos del train\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f3d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganancia_prob(y_pred, data):\n",
    "  weight = data.get_weight()\n",
    "  ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "  ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "  ganancia = np.cumsum(ganancia)  # ✅ Bien\n",
    "  return 'gan_eval', np.max(ganancia), True\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7157293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:41:37,005] Using an existing study with name 'exp_301_lgbm' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.1) # mas bajo, más iteraciones necesita\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 300, 1000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'max_bin': 31,\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': learning_rate,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'seed': SEMILLAS[0],\n",
    "        'verbose': -1\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train,\n",
    "                              label=y_train, # eligir la clase\n",
    "                              weight=pesos_train\n",
    "                              )\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=100, # modificar, subit y subir... y descomentar la línea inferior\n",
    "        # early_stopping_rounds= int(50 + 5 / learning_rate),\n",
    "        feval=ganancia_prob,\n",
    "        stratified=True,\n",
    "        nfold=3,\n",
    "        seed=SEMILLAS[0],\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=int(50 + 5/learning_rate), verbose=False),\n",
    "                lgb.log_evaluation(period=200),\n",
    "                ]\n",
    "    )\n",
    "    max_gan = max(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    # Guardamos cual es la mejor iteración del modelo\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan * 3\n",
    "# Al final de objective()\n",
    "gc.collect()\n",
    "\n",
    "#guardar el archivo en mi carpeta data\n",
    "storage_name = \"sqlite:///data/optimization_lgbm.db\"\n",
    "\n",
    "study_name = \"exp_301_lgbm\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1bddf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-09 16:43:25,676] Trial 15 finished with value: 824520000.0 and parameters: {'num_leaves': 13, 'learning_rate': 0.032922995753811045, 'min_data_in_leaf': 964, 'feature_fraction': 0.2632501067072054, 'bagging_fraction': 0.28635017212034686}. Best is trial 15 with value: 824520000.0.\n",
      "[I 2025-10-09 16:45:32,227] Trial 16 finished with value: 1027440000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.07720399027065392, 'min_data_in_leaf': 658, 'feature_fraction': 0.39718138159387195, 'bagging_fraction': 0.3601895736680899}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:47:35,837] Trial 17 finished with value: 791800000.0 and parameters: {'num_leaves': 49, 'learning_rate': 0.007962520110203843, 'min_data_in_leaf': 895, 'feature_fraction': 0.4706483103904118, 'bagging_fraction': 0.4298206201719591}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:49:25,185] Trial 18 finished with value: 834300000.0 and parameters: {'num_leaves': 12, 'learning_rate': 0.03261502081092614, 'min_data_in_leaf': 774, 'feature_fraction': 0.36228252699876873, 'bagging_fraction': 0.825135708172798}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:51:26,330] Trial 19 finished with value: 928600000.0 and parameters: {'num_leaves': 85, 'learning_rate': 0.028124073101017433, 'min_data_in_leaf': 814, 'feature_fraction': 0.9765401489774953, 'bagging_fraction': 0.4846954588315372}. Best is trial 16 with value: 1027440000.0.\n",
      "[I 2025-10-09 16:54:54,050] Trial 20 finished with value: 1045140000.0 and parameters: {'num_leaves': 99, 'learning_rate': 0.09456799616712813, 'min_data_in_leaf': 786, 'feature_fraction': 0.8505712193448408, 'bagging_fraction': 0.8614072845471961}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 16:57:34,715] Trial 21 finished with value: 775520000.0 and parameters: {'num_leaves': 71, 'learning_rate': 0.007609236921035897, 'min_data_in_leaf': 889, 'feature_fraction': 0.7305930553144344, 'bagging_fraction': 0.9836295817863161}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:01:10,065] Trial 22 finished with value: 954580000.0 and parameters: {'num_leaves': 87, 'learning_rate': 0.03551299900057091, 'min_data_in_leaf': 776, 'feature_fraction': 0.4412506615972879, 'bagging_fraction': 0.8249568481060399}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:04:17,342] Trial 23 finished with value: 1021120000.0 and parameters: {'num_leaves': 73, 'learning_rate': 0.07102526431761932, 'min_data_in_leaf': 627, 'feature_fraction': 0.6362852893242957, 'bagging_fraction': 0.5861891002072817}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:07:59,799] Trial 24 finished with value: 948820000.0 and parameters: {'num_leaves': 95, 'learning_rate': 0.03213507857167837, 'min_data_in_leaf': 593, 'feature_fraction': 0.4209847747251586, 'bagging_fraction': 0.8759373701900635}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:10:24,713] Trial 25 finished with value: 1020900000.0 and parameters: {'num_leaves': 41, 'learning_rate': 0.09837336279295872, 'min_data_in_leaf': 415, 'feature_fraction': 0.919985830000466, 'bagging_fraction': 0.6011415449734407}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:13:15,576] Trial 26 finished with value: 1042800000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.08971976862027427, 'min_data_in_leaf': 452, 'feature_fraction': 0.8004895206314104, 'bagging_fraction': 0.157399876107364}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:16:05,448] Trial 27 finished with value: 1041060000.0 and parameters: {'num_leaves': 70, 'learning_rate': 0.09870571178017513, 'min_data_in_leaf': 304, 'feature_fraction': 0.7863358253073632, 'bagging_fraction': 0.143315819961042}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:18:44,054] Trial 28 finished with value: 988340000.0 and parameters: {'num_leaves': 35, 'learning_rate': 0.07967321744531922, 'min_data_in_leaf': 496, 'feature_fraction': 0.8331819030261377, 'bagging_fraction': 0.10049671000519919}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:21:55,902] Trial 29 finished with value: 1009480000.0 and parameters: {'num_leaves': 82, 'learning_rate': 0.059718706457130004, 'min_data_in_leaf': 473, 'feature_fraction': 0.6533961039909946, 'bagging_fraction': 0.6984548668779926}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:23:54,589] Trial 30 finished with value: 1038200000.0 and parameters: {'num_leaves': 57, 'learning_rate': 0.08644030887259865, 'min_data_in_leaf': 692, 'feature_fraction': 0.836083790915367, 'bagging_fraction': 0.23667657929031638}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:25:40,690] Trial 31 finished with value: 1008940000.0 and parameters: {'num_leaves': 100, 'learning_rate': 0.061646110241254506, 'min_data_in_leaf': 307, 'feature_fraction': 0.5863285753747938, 'bagging_fraction': 0.6550701621302726}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:27:04,579] Trial 32 finished with value: 987940000.0 and parameters: {'num_leaves': 88, 'learning_rate': 0.08586284689560453, 'min_data_in_leaf': 546, 'feature_fraction': 0.15114689197161174, 'bagging_fraction': 0.7505533727463403}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:29:31,762] Trial 33 finished with value: 1025200000.0 and parameters: {'num_leaves': 56, 'learning_rate': 0.08959332026481266, 'min_data_in_leaf': 399, 'feature_fraction': 0.9956552869925159, 'bagging_fraction': 0.9974691830589215}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:32:11,459] Trial 34 finished with value: 978580000.0 and parameters: {'num_leaves': 27, 'learning_rate': 0.06817794197927785, 'min_data_in_leaf': 733, 'feature_fraction': 0.7198370209233466, 'bagging_fraction': 0.44295744885045657}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:34:49,166] Trial 35 finished with value: 976720000.0 and parameters: {'num_leaves': 78, 'learning_rate': 0.042933801441912944, 'min_data_in_leaf': 835, 'feature_fraction': 0.891006619841911, 'bagging_fraction': 0.32299584653205415}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:36:25,181] Trial 36 finished with value: 1044240000.0 and parameters: {'num_leaves': 64, 'learning_rate': 0.09846796120949375, 'min_data_in_leaf': 323, 'feature_fraction': 0.7638527968919089, 'bagging_fraction': 0.12449291434137111}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:38:04,491] Trial 37 finished with value: 1031280000.0 and parameters: {'num_leaves': 63, 'learning_rate': 0.09294504641854785, 'min_data_in_leaf': 349, 'feature_fraction': 0.743768290949119, 'bagging_fraction': 0.1934407976564106}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:39:33,464] Trial 38 finished with value: 1043220000.0 and parameters: {'num_leaves': 93, 'learning_rate': 0.09962439914117481, 'min_data_in_leaf': 379, 'feature_fraction': 0.874385258914073, 'bagging_fraction': 0.20343112783227624}. Best is trial 20 with value: 1045140000.0.\n",
      "[I 2025-10-09 17:41:52,148] Trial 39 finished with value: 1058480000.0 and parameters: {'num_leaves': 91, 'learning_rate': 0.09904281706673441, 'min_data_in_leaf': 370, 'feature_fraction': 0.9029799021041279, 'bagging_fraction': 0.5198907300236562}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:44:49,323] Trial 40 finished with value: 1030960000.0 and parameters: {'num_leaves': 77, 'learning_rate': 0.08107008652265753, 'min_data_in_leaf': 524, 'feature_fraction': 0.9383670803546833, 'bagging_fraction': 0.4830700758107635}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:47:17,770] Trial 41 finished with value: 1020620000.0 and parameters: {'num_leaves': 67, 'learning_rate': 0.07266488061473086, 'min_data_in_leaf': 586, 'feature_fraction': 0.5215037690611719, 'bagging_fraction': 0.9050163759026926}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:48:59,114] Trial 42 finished with value: 992500000.0 and parameters: {'num_leaves': 92, 'learning_rate': 0.0528325423839046, 'min_data_in_leaf': 353, 'feature_fraction': 0.7129192006043963, 'bagging_fraction': 0.7455389623682458}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:50:30,355] Trial 43 finished with value: 1025340000.0 and parameters: {'num_leaves': 47, 'learning_rate': 0.09310169546870133, 'min_data_in_leaf': 447, 'feature_fraction': 0.6425588211916933, 'bagging_fraction': 0.3912379704690329}. Best is trial 39 with value: 1058480000.0.\n",
      "[I 2025-10-09 17:53:27,143] Trial 44 finished with value: 1033920000.0 and parameters: {'num_leaves': 81, 'learning_rate': 0.08349184716726239, 'min_data_in_leaf': 985, 'feature_fraction': 0.8662105529858758, 'bagging_fraction': 0.2779711201466693}. Best is trial 39 with value: 1058480000.0.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=30) # subir subir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b7d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Obtener los mejores 10 trials\n",
    "best_trials = study.trials_dataframe().sort_values('value', ascending=False).head(10)\n",
    "\n",
    "# Opción 1: Guardar como lista de diccionarios (más completo)\n",
    "mejores_params = []\n",
    "for i, trial in enumerate(study.best_trials[:10] if len(study.best_trials) >= 10 else study.best_trials):\n",
    "    mejores_params.append({\n",
    "        'rank': i + 1,\n",
    "        'trial_number': trial.number,\n",
    "        'value': trial.value,\n",
    "        'params': trial.params,\n",
    "        'best_iter': trial.user_attrs.get('best_iter', None)\n",
    "    })\n",
    "\n",
    "# Guardar en JSON\n",
    "with open('data/mejores_hiperparametros.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mejores_params, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
